{
    "cells": [
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "**Important:** Before running this notebook, ensure you have installed spark-cloudant 1.6.4 by running the notebook: **Step 05 - Install Spark Cloudant**"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "Next, add your cloudant credentials below, delete the hash before the 'echo' command and run the cell to save your credentials"
        }, 
        {
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": false
            }, 
            "source": "! # echo '{ \"username\": \"changeme\", \"password\": \"changeme\", \"host\": \"changeme\", \"port\": 443, \"url\": \"changeme\" }' > cloudant_credentials.json", 
            "execution_count": 1
        }, 
        {
            "cell_type": "code", 
            "outputs": [
                {
                    "text": "Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nImportError: No module named cloudant\nCollecting cloudant\n  Downloading cloudant-2.4.0-py2-none-any.whl (66kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 71kB 3.8MB/s \n\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): requests<3.0.0,>=2.7.0 in /usr/local/src/bluemix_jupyter_bundle.v33/notebook/lib/python2.7/site-packages (from cloudant)\nInstalling collected packages: cloudant\nSuccessfully installed cloudant-2.4.0\n", 
                    "output_type": "stream", 
                    "name": "stdout"
                }
            ], 
            "metadata": {
                "collapsed": false
            }, 
            "source": "! python -c 'import cloudant' || pip install cloudant --user\n", 
            "execution_count": 2
        }, 
        {
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# utility method for timestamps\nimport time\ndef ts():\n    return time.strftime(\"%Y-%m-%d %H:%M:%S %Z\")", 
            "execution_count": 3
        }, 
        {
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": false
            }, 
            "source": "# utility method for logging\nlog4jLogger = sc._jvm.org.apache.log4j\nLOGGER = log4jLogger.LogManager.getLogger(\"CloudantRecommender\")\n\ndef info(*args):\n    \n    # sends output to notebook\n    print(args)\n    \n    # sends output to kernel log file\n    LOGGER.info(args)\n    \ndef error(*args):\n    \n    # sends output to notebook\n    print(args)\n    \n    # sends output to kernel log file\n    LOGGER.error(args)", 
            "execution_count": 4
        }, 
        {
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": false
            }, 
            "source": "# utility class for holding cloudant connection details\nimport json\n\ndef set_attr_if_exists(obj, data, k):\n    try:\n        setattr(obj, k, data[k])\n    except AttributeError:\n        pass\n\nclass CloudantConfig:\n    def __init__(self, database, json_file=None, host=None, username=None, password=None):\n       \n        self.database = database\n        self.host = None\n        self.username = None\n        self.password = None\n\n        with open(json_file) as data_file:    \n            data = json.load(data_file)\n            \n            set_attr_if_exists(self, data, 'host')\n            set_attr_if_exists(self, data, 'username')\n            set_attr_if_exists(self, data, 'password')\n        \n        # override json attributes if provided\n        if host:     self.host = host\n        if username: self.username = username\n        if password: self.password = password", 
            "execution_count": 5
        }, 
        {
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": false
            }, 
            "source": "sourceDB = CloudantConfig(\n                    json_file='cloudant_credentials.json', \n                    database=\"ratingdb\"\n                    )", 
            "execution_count": 6
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": " - We generate recommendations, create a new Cloudant database for the recommendations and save them into the new Cloudant database.\n - When we have finished writing the recommendations to Cloudant, we save a metadata record into the recommendation_meta database with the name of the new database.\n - Client applications use the metadata record to determine which database to retrieve the recommendations from.\n - We delete older databases after writing the metadata, but keep the five latest ones.\n - We need to keep at least one database because if a client reads the meta pointing to the previous database it will try to read from that database.\n - We don't have just one database and continually update the recommendation records in Cloudant because lots of changes can be considered an anti-pattern.\n - The recommendation_meta database is created for us by the web application setup scripts.\n - The spark-cloudant package is used to read the data from Cloudant but not to write the data to Cloudant because of this issue: https://github.com/cloudant-labs/spark-cloudant/issues/82\n - The python-cloudant package is used to write the data."
        }, 
        {
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": false
            }, 
            "source": "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n\nimport json\nimport numpy as np\n\n# we use the cloudant python library to save the recommendations\nfrom cloudant.client import Cloudant\nfrom cloudant.adapters import Replay429Adapter\n\nclass CloudantMovieRecommender:\n    \n    def __init__(self, sc):\n        self.sc = sc\n    \n    def train(self, sourceDB):\n                      \n        info(\"Starting load from Cloudant: \", ts())\n\n        dfReader = sqlContext.read.format(\"com.cloudant.spark\")\n        dfReader.option(\"cloudant.host\", sourceDB.host)\n        \n        if sourceDB.username:\n            dfReader.option(\"cloudant.username\", sourceDB.username)\n            \n        if sourceDB.password:\n            dfReader.option(\"cloudant.password\", sourceDB.password)\n            \n        df = dfReader.load(sourceDB.database).cache()\n\n        info(\"Finished load from Cloudant: \", ts())\n        info(\"Found\", df.count(), \"records in Cloudant\")\n        \n        # convert cloudant docs into Rating objects\n        def make_rating(row):\n            (user_id, prod_id) = row[0].split('/')\n            user_id = int(user_id.replace('user_', ''))\n            prod_id = int(prod_id.replace('movie_', ''))\n\n            rating = float(row[2])\n            return Rating(user_id, prod_id, rating)\n        \n        ratings = df.map(make_rating)\n\n        rank = 50\n        numIterations = 20\n        lambdaParam = 0.1\n\n        info(\"Starting train model: \", ts())\n        self.model = ALS.train(ratings, rank, numIterations, lambdaParam)\n        info(\"Finished train model: \", ts())\n        \n    def get_top_recommendations(self):\n        info(\"Starting __get_top_recommendations: \", ts())\n        df = self.model.recommendProductsForUsers(10).toDF()\n        df.cache()\n        info(\"Finished __get_top_recommendations: \", ts())\n        return df\n        \n    def del_old_recommendationdbs(self, cloudant_client, db_name_prefix):\n        dbs_to_del = cloudant_client.all_dbs()\n\n        # only delete dbs we are using for recommendations\n        dbs_to_del = [db for db in dbs_to_del if db.startswith(db_name_prefix + '_') ]\n\n        # ensure the list is in timestamp order\n        dbs_to_del.sort()\n\n        # keeping the last 5 dbs and delete the rest\n        for db in dbs_to_del[:-5]:\n            cloudant_client.delete_database(db)\n            info(\"Deleted old recommendations db\", db)\n            \n    def update_meta_document(self, cloudant_client, meta_db_name, latest_db_name):\n        \n        meta_db = cloudant_client[meta_db_name]\n        \n        from datetime import datetime\n        ts = datetime.utcnow().isoformat()\n\n        try:\n            # update doc if exists\n            meta_doc = meta_db['recommendation_metadata']\n            meta_doc['latest_db'] = latest_db_name\n            meta_doc['timestamp_utc'] = ts\n            meta_doc.save()\n            info(\"Updated recommendationdb metadata record with latest_db\", latest_db_name, meta_doc)\n        except KeyError:\n            # create a new doc\n            data = {\n                '_id': 'recommendation_metadata',\n                'latest_db': latest_db_name,\n                'timestamp_utc': ts,\n                }\n            meta_doc = meta_db.create_document(data)\n            meta_doc.save()\n            \n            if meta_doc.exists():\n                info(\"Saved recommendationdb metadata record\", str(data))\n                \n        # save product features to enable later generationg of Vt\n        # see: http://stackoverflow.com/questions/41537470/als-model-how-to-generate-full-u-vt-v\n        pf = self.model.productFeatures().sortByKey()\n\n        pf_keys = json.dumps(pf.sortByKey().keys().collect())\n        pf_vals = json.dumps(pf.sortByKey().map(lambda x: list(x[1])).collect())               \n        \n        # the pf_keys/pf_vals are too big and exceed the >1mb document size limit\n        # so we save them as attachments\n        \n        meta_doc.put_attachment(\n            attachment='product_feature_keys', \n            content_type='application/json', \n            data=pf_keys\n        )\n\n        meta_doc.put_attachment(\n            attachment='product_feature_vals', \n            content_type='application/json', \n            data=pf_vals\n        )\n    \n    def create_recommendationdb(self, cloudant_client):\n        # create a database for recommendations\n        import time\n        db_name = destDB.database + '_' + str(int(time.time()))\n        \n        db = cloudant_client.create_database(db_name)\n        info(\"Created new recommendations db\", db_name)\n        return db\n        \n    def save_recommendations(self, destDB):\n        df = movieRecommender.get_top_recommendations()\n        \n        cloudant_client = Cloudant(\n                                destDB.username,\n                                destDB.password,\n                                account=destDB.username, \n                                adapter=Replay429Adapter(retries=10, initialBackoff=1)\n                                )\n        cloudant_client.connect()\n        self.del_old_recommendationdbs(cloudant_client, destDB.database)\n        recommendations_db = self.create_recommendationdb(cloudant_client)\n\n        # reformat data for saving\n        docs = df.map(lambda x: {'_id':str(x[0]), 'recommendations':x[1]}).collect()\n        \n        # we could hit cloudant resource limits if trying to save entire doc\n        # so we save it in smaller sized chunks\n        \n        for i in range(0, len(docs), 100):\n            chunk = docs[i:i + 100]\n            recommendations_db.bulk_docs(chunk) # TODO check for errors saving the chunk\n            info(\"Saved recommendations chunk\", i, ts())\n        \n        self.update_meta_document(cloudant_client, destDB.database, recommendations_db.database_name)\n        \n        info(\"Saved recommendations to: \", recommendations_db.database_name, ts())\n\n        cloudant_client.disconnect()", 
            "execution_count": 7
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "Now the code to start the recommender ..."
        }, 
        {
            "cell_type": "code", 
            "outputs": [
                {
                    "text": "('Starting load from Cloudant: ', '2017-02-16 09:00:51 CST')\n('Finished load from Cloudant: ', '2017-02-16 09:01:51 CST')\n('Found', 1000002, 'records in Cloudant')\n('Starting train model: ', '2017-02-16 09:02:33 CST')\n('Finished train model: ', '2017-02-16 09:03:12 CST')\n('Starting __get_top_recommendations: ', '2017-02-16 09:03:12 CST')\n('Finished __get_top_recommendations: ', '2017-02-16 09:03:17 CST')\n('Created new recommendations db', 'recommendationdb_1487257397')\n('Saved recommendations chunk', 0, '2017-02-16 09:03:19 CST')\n('Saved recommendations chunk', 100, '2017-02-16 09:03:19 CST')\n('Saved recommendations chunk', 200, '2017-02-16 09:03:19 CST')\n('Saved recommendations chunk', 300, '2017-02-16 09:03:19 CST')\n('Saved recommendations chunk', 400, '2017-02-16 09:03:19 CST')\n('Saved recommendations chunk', 500, '2017-02-16 09:03:19 CST')\n('Saved recommendations chunk', 600, '2017-02-16 09:03:19 CST')\n('Saved recommendations chunk', 700, '2017-02-16 09:03:19 CST')\n('Saved recommendations chunk', 800, '2017-02-16 09:03:19 CST')\n('Saved recommendations chunk', 900, '2017-02-16 09:03:19 CST')\n('Saved recommendations chunk', 1000, '2017-02-16 09:03:19 CST')\n('Saved recommendations chunk', 1100, '2017-02-16 09:03:19 CST')\n('Saved recommendations chunk', 1200, '2017-02-16 09:03:22 CST')\n('Saved recommendations chunk', 1300, '2017-02-16 09:03:22 CST')\n('Saved recommendations chunk', 1400, '2017-02-16 09:03:22 CST')\n('Saved recommendations chunk', 1500, '2017-02-16 09:03:22 CST')\n('Saved recommendations chunk', 1600, '2017-02-16 09:03:22 CST')\n('Saved recommendations chunk', 1700, '2017-02-16 09:03:22 CST')\n('Saved recommendations chunk', 1800, '2017-02-16 09:03:22 CST')\n('Saved recommendations chunk', 1900, '2017-02-16 09:03:22 CST')\n('Saved recommendations chunk', 2000, '2017-02-16 09:03:22 CST')\n('Saved recommendations chunk', 2100, '2017-02-16 09:03:22 CST')\n('Saved recommendations chunk', 2200, '2017-02-16 09:03:22 CST')\n('Saved recommendations chunk', 2300, '2017-02-16 09:03:24 CST')\n('Saved recommendations chunk', 2400, '2017-02-16 09:03:24 CST')\n('Saved recommendations chunk', 2500, '2017-02-16 09:03:24 CST')\n('Saved recommendations chunk', 2600, '2017-02-16 09:03:24 CST')\n('Saved recommendations chunk', 2700, '2017-02-16 09:03:24 CST')\n('Saved recommendations chunk', 2800, '2017-02-16 09:03:25 CST')\n('Saved recommendations chunk', 2900, '2017-02-16 09:03:25 CST')\n('Saved recommendations chunk', 3000, '2017-02-16 09:03:25 CST')\n('Saved recommendations chunk', 3100, '2017-02-16 09:03:25 CST')\n('Saved recommendations chunk', 3200, '2017-02-16 09:03:25 CST')\n('Saved recommendations chunk', 3300, '2017-02-16 09:03:25 CST')\n('Saved recommendations chunk', 3400, '2017-02-16 09:03:27 CST')\n('Saved recommendations chunk', 3500, '2017-02-16 09:03:27 CST')\n('Saved recommendations chunk', 3600, '2017-02-16 09:03:27 CST')\n('Saved recommendations chunk', 3700, '2017-02-16 09:03:27 CST')\n('Saved recommendations chunk', 3800, '2017-02-16 09:03:27 CST')\n('Saved recommendations chunk', 3900, '2017-02-16 09:03:27 CST')\n('Saved recommendations chunk', 4000, '2017-02-16 09:03:27 CST')\n('Saved recommendations chunk', 4100, '2017-02-16 09:03:27 CST')\n('Saved recommendations chunk', 4200, '2017-02-16 09:03:27 CST')\n('Saved recommendations chunk', 4300, '2017-02-16 09:03:27 CST')\n('Saved recommendations chunk', 4400, '2017-02-16 09:03:27 CST')\n('Saved recommendations chunk', 4500, '2017-02-16 09:03:30 CST')\n('Saved recommendations chunk', 4600, '2017-02-16 09:03:30 CST')\n('Saved recommendations chunk', 4700, '2017-02-16 09:03:30 CST')\n('Saved recommendations chunk', 4800, '2017-02-16 09:03:30 CST')\n('Saved recommendations chunk', 4900, '2017-02-16 09:03:30 CST')\n('Saved recommendations chunk', 5000, '2017-02-16 09:03:30 CST')\n('Saved recommendations chunk', 5100, '2017-02-16 09:03:30 CST')\n('Saved recommendations chunk', 5200, '2017-02-16 09:03:30 CST')\n('Saved recommendations chunk', 5300, '2017-02-16 09:03:30 CST')\n('Saved recommendations chunk', 5400, '2017-02-16 09:03:30 CST')\n('Saved recommendations chunk', 5500, '2017-02-16 09:03:30 CST')\n('Saved recommendations chunk', 5600, '2017-02-16 09:03:32 CST')\n('Saved recommendations chunk', 5700, '2017-02-16 09:03:32 CST')\n('Saved recommendations chunk', 5800, '2017-02-16 09:03:32 CST')\n('Saved recommendations chunk', 5900, '2017-02-16 09:03:32 CST')\n('Saved recommendations chunk', 6000, '2017-02-16 09:03:32 CST')\n('Saved recommendationdb metadata record', \"{'timestamp_utc': '2017-02-16T15:03:32.780720', '_id': 'recommendation_metadata', 'latest_db': 'recommendationdb_1487257397'}\")\n('Saved recommendations to: ', 'recommendationdb_1487257397', '2017-02-16 09:03:35 CST')\n", 
                    "output_type": "stream", 
                    "name": "stdout"
                }
            ], 
            "metadata": {
                "collapsed": false
            }, 
            "source": "sourceDB = CloudantConfig(\n                    json_file='cloudant_credentials.json', \n                    database=\"ratingdb\"\n                    )\n\ndestDB = CloudantConfig(\n                    json_file='cloudant_credentials.json', \n                    database=\"recommendationdb\", \n                    )\n\nimport traceback\ntry:\n    movieRecommender = CloudantMovieRecommender(sc)\n    movieRecommender.train(sourceDB)\n    movieRecommender.save_recommendations(destDB)\nexcept Exception as e:\n    error(str(e), traceback.format_exc(), ts())\n    raise e", 
            "execution_count": 8
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## Scheduling"
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "After you have successfully run the notebook interactively you can schedule your notebook to run on a timer, for example hourly.\n\nTimer jobs work again a specific saved version of a notebook.  If you haven't saved a version when you first create the schedule a version will be saved for you.  \n\nNote that if you make changes to your notebook, you need to save a new version and re-schedule the notebook with the new version of the notebook selected in the schedule configuration form."
        }, 
        {
            "cell_type": "markdown", 
            "metadata": {}, 
            "source": "## For debugging issues"
        }, 
        {
            "cell_type": "code", 
            "outputs": [
                {
                    "text": "========================== 20170216_145840 ==========================\n/usr/local/src/bluemix_jupyter_bundle.v33/provision/pyspark_kernel_wrapper.sh /gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/jupyter-rt/kernel-36bfe046-ea31-4555-b30c-13c4e5f5c0cf.json spark160master\nno extra config\nload default config from : /gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/spark-config/spark160master\n-------- Environment for PySpark --------\nAPP_ENV_BM_DOMAIN=ng.bluemix.net\nAPP_ENV_CDSX_NOTEBOOKS_API=cdsx-notebooks-api.ng.bluemix.net\nAPP_ENV_ENVIRONMENT=prod\nAPP_ENV_IBM_ONLY_AUTH=false\nAPP_ENV_JUPYTER_TENANTS_API=cdsx-tenants-api.ng.bluemix.net\nAPP_ENV_NOTEBOOKS_JOB_MANAGER=cdsx-notebooks-job-manager.ng.bluemix.net\nATLAS_VERSION=3.10.2\n_=/bin/printenv\nBLUEMIX_RES_PLAN=s\nBRUNEL_CONFIG=locjavascript=/data/jupyter2/c718818f-304e-4786-bde1-92e9626d40d0/nbextensions/brunel_ext\nCC_DISABLE_BIG_BUFFER_API=true\nCDSX_APP_ENV_NOTEBOOKS_API_URL=https://cdsx-notebooks-api.ng.bluemix.net/v1/notebooks/\nC_INCLUDE_PATH=/usr/local/src/bluemix_jupyter_bundle.v33/notebook/include:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/system/include:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/freetype/include:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/include:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/system/include:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/freetype/include:\nDEPLOY_HOME=/usr/local/src/bluemix_jupyter_bundle.v33\nDS_RESOURCE_LOCATION=/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/res\nDW_CONN_HOME=/usr/local/src/dataconnector-dw/spark-1.6.0/Server\nEGO_ACTIVITY_PID=-1\nEGO_CONFDIR=/disk1/ego/kernel/conf\nEGO_CONTAINER_ID=95790\nEGO_EXPORT_OS_USER_ENV=N\nEGO_KD_PORT=7870\nEGO_LIBDIR=/disk1/ego/3.4/linux-x86_64/lib\nEGO_LOAD_BASHRC_SRC=N\nEGO_MASTER_LIST_PEM=yp-spark-dal09-env5-0001.bluemix.net yp-spark-dal09-env5-0003\nEGOSC_INSTANCE_HOST=yp-spark-dal09-env5-0044\nEGOSC_INSTANCE_INDEX_PER_HOST=1\nEGOSC_INSTANCE_RESOURCE_GROUP=ComputeHosts\nEGOSC_INSTANCE_SEQNO=1\nEGOSC_INSTANCE_START_REASON=FirstStart\nEGOSC_SERVICE_NAME=sde1-92e9626d40d0f3-dcc0c4613008\nHOME=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008\nIBM_JAVA_OPTIONS=-Dderby.system.home=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/jupyter-rt/kernel-36bfe046-ea31-4555-b30c-13c4e5f5c0cf-20170216_145840\nJAR_DIR=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/downloads\nJAVA_HOME=/usr/local/src/spark160master/ibm-java-x86_64-80\nJPY_PARENT_PID=15139\nJUPYTER_CONFIG_DIR=/usr/local/src/bluemix_jupyter_bundle.v33/provision/jupyter-ax-ext\nJUPYTER_DATA_DIR=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/jupyter-data\nJUPYTER_RUNTIME_DIR=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/jupyter-rt\nKERNEL_ACTIVITY_LOG=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/process-info/kernel_activity.status\nLANG=en_US.UTF-8\nLD_LIBRARY_PATH=/usr/local/lib:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/lib:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/lib/daapi-sca:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/lib/C/icc/icclib:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/lib/C/icc/osslib:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/lib/N/icc/icclib:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/lib/N/icc/osslib:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/lib/daapi-xml:/usr/local/src/spark160master/ibm-java-x86_64-80/jre/lib/amd64/compressedrefs:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/lib:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/system/lib:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/freetype/lib:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/lib:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/system/lib:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/freetype/lib:\nLIBRARY_PATH=/usr/local/src/bluemix_jupyter_bundle.v33/notebook/lib:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/system/lib:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/freetype/lib:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/lib:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/system/lib:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/freetype/lib:\nLOG_FILE=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/logs/kernel-pyspark-20170216_145840.log\nMASTER=spark://yp-spark-dal09-env5-0044:7082\nNGWB_TAM_FILE_LOCATION=/usr/local/src/analytic-libs/spark-1.6.0/tam\nNOTEBOOK_HOME=/usr/local/src/bluemix_jupyter_bundle.v33/notebook\nNOTEBOOK_KERNEL=python2\nNOTEBOOK_TENANT_ID=c718818f-304e-4786-bde1-92e9626d40d0\nPATH=/usr/local/src/scala/2.10/bin:/usr/local/src/spark160master/ibm-java-x86_64-80/bin:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/bin:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/system/bin:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/freetype/bin:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/bin:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/system/bin:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/freetype/bin:/bin\nPIP_DISABLE_PIP_VERSION_CHECK=true\nPIP_USER=true\nPWD=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/work\n_py_cads_dir=/usr/local/src/cognitive-assistant/cads_packages\n_py_dir_=/usr/local/src/analytic-libs/python\n_py_spark_dir_=/usr/local/src/analytic-libs/spark-1.6.0/python\nPYSPARK_DRIVER_PYTHON_OPTS=-m ipykernel -f \"/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/jupyter-rt/kernel-36bfe046-ea31-4555-b30c-13c4e5f5c0cf.json\"\nPYSPARK_PYTHON=/usr/local/src/bluemix_jupyter_bundle.v33/notebook/bin/python\nPYSPARK_SUBMIT_ARGS=--master \"spark://yp-spark-dal09-env5-0044:7082\" --jar-dir \"/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/downloads\"\nPYTHONPATH=/usr/local/src/bluemix_jupyter_bundle.v33/provision/jupyter-ax-ext/cdsax_jupyter_extensions.egg:/usr/local/src/bluemix_jupyter_bundle.v33/provision/site-python::/usr/local/src/analytic-libs/python-2.7:/usr/local/src/analytic-libs/python:/usr/local/src/cognitive-assistant/cads_packages:/usr/local/src/analytic-libs/spark-1.6.0/python-2.7:/usr/local/src/analytic-libs/spark-1.6.0/python\n_py_version_=2.7\nR_HOME_PREFIX=/usr/local/src/bluemix_jupyter_bundle.v33\nR_LIBS_USER=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/R/libs\nRUNTIME_ENV_NOTEBOOK=prod\nRUNTIME_ENV_PAAS=sl\nRUNTIME_ENV_SPARK=prod\nRUNTIME_ENV_STOREFRONT=bluemix/prod\nSCALA_HOME=/usr/local/src/scala/2.10\nSERVICE_CALLER=AX\nSERVICE_HOME=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook\nSHLVL=2\nSPARK_CONF_DIR=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/spark-config/spark160master\nSPARK_CONFIG_HOME=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/spark-config\nSPARK_DEPLOY_RESOURCE_SCHEDULER=ego\nSPARK_DIST_CLASSPATH=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/data/libs/scala-2.10/*:/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/data/libs:/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/data/libs/*:/usr/local/src/dataconnector-s3/spark-1.6.0/libs/*:/usr/local/src/dataconnector-stocator-1.6/spark-1.6.0/libs/*:/usr/local/src/dataconnector-cloudant/*:/usr/local/src/analytic-libs/spark-1.6.0/*:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/jars/*:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/jdbc/lib/*:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/thirdparty/*:/usr/local/src/dataconnector-dw/spark-1.6.0/libs/*:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/thirdparty/aws/*:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/config:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/FaspStreamSDK/lib/*:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/jars/JISPlugins/*:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/branded_jdbc/lib/*:/usr/local/src/dataconnector-dw/spark-1.6.0/ASBServer/apps/lib/iis/*/*:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/connectors/*/*:/usr/local/src/event-stream/spark-1.6.0/libs/*:/usr/local/src/dataconnector-db2/*\nSPARK_DRIVER_MEMORY=1512M\nSPARK_EGO_APP_SCHEDULE_POLICY=hierarchy\nSPARK_EGO_CACHED_EXECUTOR_IDLE_TIMEOUT=1200\nSPARK_EGO_CLASSPATH=/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/thirdparty/avro-1.8.0.jar:\nSPARK_EGO_CLIENT_TIMEOUT=1200\nSPARK_EGO_CONSUMER=/SparkOnBluemix/sde1-92e9626d40d0f3-dcc0c4613008\nSPARK_EGO_DRIVER_CONSUMER=/SparkDrivers\nSPARK_EGO_DRIVER_PLAN=ComputeHosts\nSPARK_EGO_EXECUTOR_CONSUMER=/SparkOnBluemix/Spark160MasterLow/*\nSPARK_EGO_EXECUTOR_IDLE_TIMEOUT=300\nSPARK_EGO_EXECUTOR_PLAN=ComputeHosts\nSPARK_EGO_EXECUTOR_SLOTS_MAX=3\nSPARK_EGO_HIERARCHY_CONF_FILE=/usr/local/src/spark160master/spark/profile/notebook/tag.json\nSPARK_EGO_IPYTHON=true\nSPARK_EGO_JARS=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/spark-config/spark160master:/usr/local/src/spark160master/spark/ego/spark-launcher_2.10-1.6.0.jar:/usr/local/src/spark160master/spark/ego/spark-network-shuffle_2.10-1.6.0.jar:/usr/local/src/spark160master/spark/ego/gson-2.2.4.jar:/usr/local/src/spark160master/spark/ego/guava-14.0.1.jar:/usr/local/src/spark160master/spark/ego/Java-WebSocket-1.3.0.jar:/usr/local/src/spark160master/spark/ego/spark-ego_2.10-1.6.0.jar\nSPARK_EGO_LOG_DIR=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/spark/executor\nSPARK_EGO_NATIVE_LIBRARY=/usr/local/src/spark160master/spark/ego/libSparkVEMApi.so\nSPARK_EGO_RUN_AS_SERVICE=true\nSPARK_EGO_STAGING_DIR=/tmp/spark-160-ego-master/staging\nSPARK_EGO_TAG_PATH=/root/s/sde1-92e9626d40d0f3-dcc0c4613008\nSPARK_ENV_LOADED=1\nSPARK_EXECUTOR_MEMORY=6G\nSPARK_EXECUTOR_OPTS=-Dspark.shuffle.service.port=7340\nSPARK_HISTORY_DATA=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/events\nSPARK_HISTORY_LOG=/gpfs/fs01/spark-ego-master\nSPARK_HISTORY_OPTS= -Dspark.eventLog.enabled=true -Dspark.eventLog.dir=/gpfs/fs01/spark-ego-master -Dspark.history.fs.logDirectory=/gpfs/fs01/spark-ego-master\nSPARK_HOME=/usr/local/src/spark160master/spark\nSPARK_LOCAL_DIRS=/tmp/spark-160-ego-master/work\nSPARK_LOG_DIR=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/logs\nSPARK_MASTER_IP=yp-spark-dal09-env5-0044\nSPARK_MASTER_PORT=7082\nSPARK_MASTER_WEBUI_PORT=12024\nSPARK_PACKAGE=spark160master\nSPARK_PID_DIR=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/process-ids\nSPARK_SCALA_VERSION=2.10\nSPARK_SERVICE_NAME=Apache Spark-bs\nSPARK_SUBMIT_CLASSPATH=/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/thirdparty/avro-1.8.0.jar:\nSPARK_SUBMIT_LIBRARY_PATH=/usr/local/lib:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/lib:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/lib/daapi-sca:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/lib/C/icc/icclib:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/lib/C/icc/osslib:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/lib/N/icc/icclib:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/lib/N/icc/osslib:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/lib/daapi-xml:/usr/local/src/spark160master/ibm-java-x86_64-80/jre/lib/amd64/compressedrefs:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/lib:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/system/lib:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/freetype/lib:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/lib:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/system/lib:/usr/local/src/bluemix_jupyter_bundle.v33/notebook/freetype/lib:\nSPARK_TENANT_ID=sde1-92e9626d40d0f3-dcc0c4613008\nSPARK_WORK_DIR=/tmp/spark-160-ego-master/work\nTEMP=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/tmp\nTMPDIR=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/tmp\nTMP=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/tmp\nUSER=sde1-92e9626d40d0f3-dcc0c4613008\nVCAP_SERVICES={}\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/local/src/spark160master/spark-1.6.0-bin-2.6.0/lib/spark-assembly-1.6.0-hadoop2.6.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/local/src/dataconnector-stocator-1.6/spark-1.6.0/libs/slf4j-log4j12-1.7.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/local/src/analytic-libs/spark-1.6.0/tika-app-1.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/local/src/dataconnector-dw/spark-1.6.0/Server/connectivity/thirdparty/slf4j-simple-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n17/02/16 08:58:42 INFO apache.spark.SparkContext: Running Spark version 1.6.0\n17/02/16 08:58:43 WARN hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n17/02/16 08:58:43 INFO apache.spark.SparkContext: Spark configuration:\nspark.app.name=PySparkShell\nspark.deploy.resourceScheduler.factory=org.apache.spark.deploy.master.EGOResourceSchedulerFactory\nspark.driver.maxResultSize=1210M\nspark.driver.memory=1512M\nspark.eventLog.dir=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/events\nspark.eventLog.enabled=true\nspark.executor.extraJavaOptions=-Djava.security.egd=file:/dev/./urandom\nspark.executor.memory=6G\nspark.extraListeners=com.ibm.spaas.listeners.DB2DialectRegistrar\nspark.history.fs.logDirectory=/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/events\nspark.logConf=true\nspark.master=spark://yp-spark-dal09-env5-0044:7082\nspark.port.maxRetries=512\nspark.r.command=/usr/local/src/bluemix_jupyter_bundle.v33/R/bin/Rscript\nspark.rdd.compress=True\nspark.serializer.objectStreamReset=100\nspark.shuffle.service.enabled=true\nspark.shuffle.service.port=7340\nspark.sql.tungsten.enabled=false\nspark.sql.unsafe.enabled=false\nspark.submit.deployMode=client\nspark.task.maxFailures=10\nspark.ui.enabled=false\nspark.ui.retainedJobs=0\nspark.ui.retainedStages=0\nspark.worker.ui.retainedExecutors=0\n17/02/16 08:58:43 INFO apache.spark.SecurityManager: Changing view acls to: sde1-92e9626d40d0f3-dcc0c4613008\n17/02/16 08:58:43 INFO apache.spark.SecurityManager: Changing modify acls to: sde1-92e9626d40d0f3-dcc0c4613008\n17/02/16 08:58:43 INFO apache.spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(sde1-92e9626d40d0f3-dcc0c4613008); users with modify permissions: Set(sde1-92e9626d40d0f3-dcc0c4613008)\n17/02/16 08:58:44 INFO spark.util.Utils: Successfully started service 'sparkDriver' on port 43406.\n17/02/16 08:58:44 INFO apache.spark.SparkEnv: The address of rpcenv is :10.143.133.36:43406\n17/02/16 08:58:44 INFO event.slf4j.Slf4jLogger: Slf4jLogger started\n17/02/16 08:58:44 INFO Remoting: Starting remoting\n17/02/16 08:58:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@10.143.133.36:42234]\n17/02/16 08:58:44 INFO spark.util.Utils: Successfully started service 'sparkDriverActorSystem' on port 42234.\n17/02/16 08:58:44 INFO apache.spark.SparkEnv: Registering MapOutputTracker\n17/02/16 08:58:44 INFO apache.spark.SparkEnv: Registering BlockManagerMaster\n17/02/16 08:58:44 INFO spark.storage.DiskBlockManager: Created local directory at /tmp/spark-160-ego-master/work/blockmgr-c9b6ebef-4b61-40db-b136-3dcaafd3323c\n17/02/16 08:58:44 INFO spark.storage.MemoryStore: MemoryStore started with capacity 909.0 MB\n17/02/16 08:58:44 INFO apache.spark.SparkEnv: Registering OutputCommitCoordinator\n17/02/16 08:58:44 INFO spark.util.EGOSparkDockerConfig: Docker not enabled\n17/02/16 08:58:44 INFO cluster.ego.EGOFineGrainedSchedulerBackend: setting reserve=0, priority=1, limit=2147483647,  master=spark://yp-spark-dal09-env5-0044:7082\n17/02/16 08:58:44 INFO client.ego.EGOAppClient$ClientEndpoint: Connecting to master spark://yp-spark-dal09-env5-0044:7082...\n17/02/16 08:58:44 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Connected to Spark cluster with app ID app-20170216085844-0143-1e7a6324-047d-4ece-892b-f1bae3335eb5\n17/02/16 08:58:44 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Application registered successfully as app-20170216085844-0143-1e7a6324-047d-4ece-892b-f1bae3335eb5\n17/02/16 08:58:44 INFO spark.util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35578.\n17/02/16 08:58:44 INFO network.netty.NettyBlockTransferService: Server created on 35578\n17/02/16 08:58:44 INFO spark.storage.BlockManager: external shuffle service port = 7340\n17/02/16 08:58:44 INFO spark.storage.BlockManagerMaster: Trying to register BlockManager\n17/02/16 08:58:44 INFO spark.storage.BlockManagerMasterEndpoint: Registering block manager 10.143.133.36:35578 with 909.0 MB RAM, BlockManagerId(driver, 10.143.133.36, 35578)\n17/02/16 08:58:44 INFO spark.storage.BlockManagerMaster: Registered BlockManager\n17/02/16 08:58:45 INFO spark.scheduler.EventLoggingListener: Logging events to file:/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/events/app-20170216085844-0143-1e7a6324-047d-4ece-892b-f1bae3335eb5\n17/02/16 08:58:45 INFO apache.spark.SparkContext: Registered listener com.ibm.spaas.listeners.DB2DialectRegistrar\n17/02/16 08:58:45 INFO cluster.ego.EGODeployScheduler: Spark context initialized.\n17/02/16 08:58:45 INFO root: application started with appid Some(app-20170216085844-0143-1e7a6324-047d-4ece-892b-f1bae3335eb5) and app name PySparkShell and application start time is 1487257122746\n17/02/16 09:00:51 INFO CloudantRecommender: [Starting load from Cloudant: , 2017-02-16 09:00:51 CST]\n17/02/16 09:00:51 INFO sql.hive.HiveContext: Initializing execution hive, version 1.2.1\n17/02/16 09:00:51 INFO hive.client.ClientWrapper: Inspected Hadoop version: 2.6.0\n17/02/16 09:00:51 INFO hive.client.ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0\n17/02/16 09:00:52 INFO hive.metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore\n17/02/16 09:00:52 INFO hive.metastore.ObjectStore: ObjectStore, initialize called\n17/02/16 09:00:52 INFO DataNucleus.Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored\n17/02/16 09:00:52 INFO DataNucleus.Persistence: Property datanucleus.cache.level2 unknown - will be ignored\n17/02/16 09:00:54 INFO hive.metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes=\"Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order\"\n17/02/16 09:00:55 INFO DataNucleus.Datastore: The class \"org.apache.hadoop.hive.metastore.model.MFieldSchema\" is tagged as \"embedded-only\" so does not have its own datastore table.\n17/02/16 09:00:55 INFO DataNucleus.Datastore: The class \"org.apache.hadoop.hive.metastore.model.MOrder\" is tagged as \"embedded-only\" so does not have its own datastore table.\n17/02/16 09:00:56 INFO DataNucleus.Datastore: The class \"org.apache.hadoop.hive.metastore.model.MFieldSchema\" is tagged as \"embedded-only\" so does not have its own datastore table.\n17/02/16 09:00:56 INFO DataNucleus.Datastore: The class \"org.apache.hadoop.hive.metastore.model.MOrder\" is tagged as \"embedded-only\" so does not have its own datastore table.\n17/02/16 09:00:56 INFO hive.metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY\n17/02/16 09:00:56 INFO hive.metastore.ObjectStore: Initialized ObjectStore\n17/02/16 09:00:56 WARN hive.metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0\n17/02/16 09:00:56 WARN hive.metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException\n17/02/16 09:00:57 INFO hive.metastore.HiveMetaStore: Added admin role in metastore\n17/02/16 09:00:57 INFO hive.metastore.HiveMetaStore: Added public role in metastore\n17/02/16 09:00:57 INFO hive.metastore.HiveMetaStore: No user is added in admin role, since config is empty\n17/02/16 09:00:57 INFO hive.metastore.HiveMetaStore: 0: get_all_databases\n17/02/16 09:00:57 INFO metastore.HiveMetaStore.audit: ugi=sde1-92e9626d40d0f3-dcc0c4613008\tip=unknown-ip-addr\tcmd=get_all_databases\t\n17/02/16 09:00:57 INFO hive.metastore.HiveMetaStore: 0: get_functions: db=default pat=*\n17/02/16 09:00:57 INFO metastore.HiveMetaStore.audit: ugi=sde1-92e9626d40d0f3-dcc0c4613008\tip=unknown-ip-addr\tcmd=get_functions: db=default pat=*\t\n17/02/16 09:00:57 INFO DataNucleus.Datastore: The class \"org.apache.hadoop.hive.metastore.model.MResourceUri\" is tagged as \"embedded-only\" so does not have its own datastore table.\n17/02/16 09:00:57 INFO ql.session.SessionState: Created HDFS directory: /tmp/hive/sde1-92e9626d40d0f3-dcc0c4613008\n17/02/16 09:00:57 INFO ql.session.SessionState: Created local directory: /gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/tmp/sde1-92e9626d40d0f3-dcc0c4613008\n17/02/16 09:00:57 INFO ql.session.SessionState: Created local directory: /gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/tmp/cdcc9d42-3394-48d6-8083-389241dcab3a_resources\n17/02/16 09:00:57 INFO ql.session.SessionState: Created HDFS directory: /tmp/hive/sde1-92e9626d40d0f3-dcc0c4613008/cdcc9d42-3394-48d6-8083-389241dcab3a\n17/02/16 09:00:57 INFO ql.session.SessionState: Created local directory: /gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/tmp/sde1-92e9626d40d0f3-dcc0c4613008/cdcc9d42-3394-48d6-8083-389241dcab3a\n17/02/16 09:00:57 INFO ql.session.SessionState: Created HDFS directory: /tmp/hive/sde1-92e9626d40d0f3-dcc0c4613008/cdcc9d42-3394-48d6-8083-389241dcab3a/_tmp_space.db\n17/02/16 09:00:57 INFO sql.hive.HiveContext: default warehouse location is /user/hive/warehouse\n17/02/16 09:00:57 INFO sql.hive.HiveContext: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.\n17/02/16 09:00:57 INFO hive.client.ClientWrapper: Inspected Hadoop version: 2.6.0\n17/02/16 09:00:57 INFO hive.client.ClientWrapper: Loaded org.apache.hadoop.hive.shims.Hadoop23Shims for Hadoop version 2.6.0\n17/02/16 09:00:57 INFO hive.metastore.HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore\n17/02/16 09:00:57 INFO hive.metastore.ObjectStore: ObjectStore, initialize called\n17/02/16 09:00:57 INFO DataNucleus.Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored\n17/02/16 09:00:57 INFO DataNucleus.Persistence: Property datanucleus.cache.level2 unknown - will be ignored\n17/02/16 09:01:00 INFO hive.metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes=\"Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order\"\n17/02/16 09:01:00 INFO DataNucleus.Datastore: The class \"org.apache.hadoop.hive.metastore.model.MFieldSchema\" is tagged as \"embedded-only\" so does not have its own datastore table.\n17/02/16 09:01:00 INFO DataNucleus.Datastore: The class \"org.apache.hadoop.hive.metastore.model.MOrder\" is tagged as \"embedded-only\" so does not have its own datastore table.\n17/02/16 09:01:01 INFO DataNucleus.Datastore: The class \"org.apache.hadoop.hive.metastore.model.MFieldSchema\" is tagged as \"embedded-only\" so does not have its own datastore table.\n17/02/16 09:01:01 INFO DataNucleus.Datastore: The class \"org.apache.hadoop.hive.metastore.model.MOrder\" is tagged as \"embedded-only\" so does not have its own datastore table.\n17/02/16 09:01:02 INFO hive.metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY\n17/02/16 09:01:02 INFO hive.metastore.ObjectStore: Initialized ObjectStore\n17/02/16 09:01:02 WARN hive.metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0\n17/02/16 09:01:02 WARN hive.metastore.ObjectStore: Failed to get database default, returning NoSuchObjectException\n17/02/16 09:01:02 INFO hive.metastore.HiveMetaStore: Added admin role in metastore\n17/02/16 09:01:02 INFO hive.metastore.HiveMetaStore: Added public role in metastore\n17/02/16 09:01:02 INFO hive.metastore.HiveMetaStore: No user is added in admin role, since config is empty\n17/02/16 09:01:02 INFO hive.metastore.HiveMetaStore: 0: get_all_databases\n17/02/16 09:01:02 INFO metastore.HiveMetaStore.audit: ugi=sde1-92e9626d40d0f3-dcc0c4613008\tip=unknown-ip-addr\tcmd=get_all_databases\t\n17/02/16 09:01:02 INFO hive.metastore.HiveMetaStore: 0: get_functions: db=default pat=*\n17/02/16 09:01:02 INFO metastore.HiveMetaStore.audit: ugi=sde1-92e9626d40d0f3-dcc0c4613008\tip=unknown-ip-addr\tcmd=get_functions: db=default pat=*\t\n17/02/16 09:01:02 INFO DataNucleus.Datastore: The class \"org.apache.hadoop.hive.metastore.model.MResourceUri\" is tagged as \"embedded-only\" so does not have its own datastore table.\n17/02/16 09:01:02 INFO ql.session.SessionState: Created local directory: /gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/tmp/b9eb6312-eac5-4bc2-abd0-a95318943adb_resources\n17/02/16 09:01:02 INFO ql.session.SessionState: Created HDFS directory: /tmp/hive/sde1-92e9626d40d0f3-dcc0c4613008/b9eb6312-eac5-4bc2-abd0-a95318943adb\n17/02/16 09:01:02 INFO ql.session.SessionState: Created local directory: /gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/notebook/tmp/sde1-92e9626d40d0f3-dcc0c4613008/b9eb6312-eac5-4bc2-abd0-a95318943adb\n17/02/16 09:01:02 INFO ql.session.SessionState: Created HDFS directory: /tmp/hive/sde1-92e9626d40d0f3-dcc0c4613008/b9eb6312-eac5-4bc2-abd0-a95318943adb/_tmp_space.db\nUse connectorVersion=1.6.4, dbName=ratingdb, indexName=null, viewName=null,jsonstore.rdd.partitions=5, jsonstore.rdd.maxInPartition=-1,jsonstore.rdd.minInPartition=10, jsonstore.rdd.requestTimeout=900000,bulkSize=20, schemaSampleSize=-1\n[WARN] [02/16/2017 09:01:03.448] [Thread-7] [JsonStoreDataAccess(akka://CloudantSpark-f5fb11a5-5f37-484a-8a70-3b47d9c7fd98)] Loading data from Cloudant using query: https://04d90c4d-df6b-448a-9b6e-e8dd2488c56c-bluemix.cloudant.com/ratingdb/_all_docs?limit=1\n17/02/16 09:01:04 INFO spark.common.JsonStoreRDD: Partition config - total=5, limit=200001 for totalRows of 1000002\n17/02/16 09:01:04 INFO apache.spark.SparkContext: Starting job: json at DefaultSource.scala:130\n17/02/16 09:01:04 INFO spark.scheduler.DAGScheduler: Got job 0 (json at DefaultSource.scala:130) with 5 output partitions\n17/02/16 09:01:04 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 0 (json at DefaultSource.scala:130)\n17/02/16 09:01:04 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()\n17/02/16 09:01:04 INFO spark.scheduler.DAGScheduler: Missing parents: List()\n17/02/16 09:01:04 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at json at DefaultSource.scala:130), which has no missing parents\n17/02/16 09:01:04 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(0)\n17/02/16 09:01:04 INFO spark.storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 4.1 KB, free 4.1 KB)\n17/02/16 09:01:04 INFO spark.storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.5 KB, free 6.6 KB)\n17/02/16 09:01:04 INFO spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.143.133.36:35578 (size: 2.5 KB, free: 909.0 MB)\n17/02/16 09:01:04 INFO apache.spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:01:04 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at json at DefaultSource.scala:130)\n17/02/16 09:01:04 INFO cluster.ego.EGODeployScheduler: Adding task set 0.0 with 5 tasks\n17/02/16 09:01:04 INFO cluster.ego.EGOFineGrainedSchedulerBackend: <EVENT> Spark driver SPARKDRIVER:82d31889-9ce4-448e-bdc3-348a792415fc workload coming in\n17/02/16 09:01:09 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (yp-spark-dal09-env5-0044:43592) with ID 95cd3b6f-f245-4f60-bf16-9fa43cbd7571\n17/02/16 09:01:09 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, yp-spark-dal09-env5-0044, partition 0,PROCESS_LOCAL, 2744 bytes)\n17/02/16 09:01:09 INFO spark.storage.BlockManagerMasterEndpoint: Registering block manager yp-spark-dal09-env5-0044:36970 with 4.3 GB RAM, BlockManagerId(95cd3b6f-f245-4f60-bf16-9fa43cbd7571, yp-spark-dal09-env5-0044, 36970)\n17/02/16 09:01:10 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (yp-spark-dal09-env5-0031:55418) with ID 1cf9d895-5ea7-404e-887b-7a4e4cc635ba\n17/02/16 09:01:10 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2744 bytes)\n17/02/16 09:01:10 INFO spark.storage.BlockManagerMasterEndpoint: Registering block manager yp-spark-dal09-env5-0031:38585 with 4.3 GB RAM, BlockManagerId(1cf9d895-5ea7-404e-887b-7a4e4cc635ba, yp-spark-dal09-env5-0031, 38585)\n17/02/16 09:01:10 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (yp-spark-dal09-env5-0047:48634) with ID aba2cf9b-ac74-4c07-99b0-f8250b8f7a60\n17/02/16 09:01:10 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2744 bytes)\n17/02/16 09:01:10 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, yp-spark-dal09-env5-0047, partition 3,PROCESS_LOCAL, 2744 bytes)\n17/02/16 09:01:10 INFO spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 2.5 KB, free: 4.3 GB)\n17/02/16 09:01:10 INFO spark.storage.BlockManagerMasterEndpoint: Registering block manager yp-spark-dal09-env5-0047:34157 with 4.3 GB RAM, BlockManagerId(aba2cf9b-ac74-4c07-99b0-f8250b8f7a60, yp-spark-dal09-env5-0047, 34157)\n17/02/16 09:01:10 INFO spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 2.5 KB, free: 4.3 GB)\n17/02/16 09:01:10 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (yp-spark-dal09-env5-0034:58052) with ID c5aa3a33-7528-4741-92cc-3eae1965e002\n17/02/16 09:01:10 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, yp-spark-dal09-env5-0034, partition 4,PROCESS_LOCAL, 2744 bytes)\n17/02/16 09:01:10 INFO spark.storage.BlockManagerMasterEndpoint: Registering block manager yp-spark-dal09-env5-0034:45747 with 4.3 GB RAM, BlockManagerId(c5aa3a33-7528-4741-92cc-3eae1965e002, yp-spark-dal09-env5-0034, 45747)\n17/02/16 09:01:10 INFO spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 2.5 KB, free: 4.3 GB)\n17/02/16 09:01:10 INFO spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 2.5 KB, free: 4.3 GB)\n17/02/16 09:01:26 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 17071 ms on yp-spark-dal09-env5-0044 (1/5)\n17/02/16 09:01:34 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 24128 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:01:39 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 29077 ms on yp-spark-dal09-env5-0047 (3/5)\n17/02/16 09:01:42 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 32341 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:01:50 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 40584 ms on yp-spark-dal09-env5-0034 (5/5)\n17/02/16 09:01:50 INFO spark.scheduler.DAGScheduler: ResultStage 0 (json at DefaultSource.scala:130) finished in 46.064 s\n17/02/16 09:01:50 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \n17/02/16 09:01:50 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(0)\n17/02/16 09:01:50 INFO spark.scheduler.DAGScheduler: Job 0 finished: json at DefaultSource.scala:130, took 46.216596 s\n17/02/16 09:01:51 INFO spark.storage.BlockManagerInfo: Removed broadcast_0_piece0 on 10.143.133.36:35578 in memory (size: 2.5 KB, free: 909.0 MB)\n17/02/16 09:01:51 INFO spark.storage.BlockManagerInfo: Removed broadcast_0_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 2.5 KB, free: 4.3 GB)\n17/02/16 09:01:51 INFO spark.storage.BlockManagerInfo: Removed broadcast_0_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 2.5 KB, free: 4.3 GB)\n17/02/16 09:01:51 INFO spark.storage.BlockManagerInfo: Removed broadcast_0_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 2.5 KB, free: 4.3 GB)\n17/02/16 09:01:51 INFO spark.storage.BlockManagerInfo: Removed broadcast_0_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 2.5 KB, free: 4.3 GB)\n17/02/16 09:01:51 INFO apache.spark.ContextCleaner: Cleaned accumulator 2\n17/02/16 09:01:51 INFO spark.storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 220.7 KB, free 220.7 KB)\n17/02/16 09:01:51 INFO spark.storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 19.3 KB, free 240.0 KB)\n17/02/16 09:01:51 INFO spark.storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.143.133.36:35578 (size: 19.3 KB, free: 909.0 MB)\n17/02/16 09:01:51 INFO apache.spark.SparkContext: Created broadcast 1 from rdd at DefaultSource.scala:54\n17/02/16 09:01:51 INFO CloudantRecommender: [Finished load from Cloudant: , 2017-02-16 09:01:51 CST]\n17/02/16 09:01:51 INFO apache.spark.SparkContext: Starting job: count at NativeMethodAccessorImpl.java:-2\n17/02/16 09:01:51 INFO spark.scheduler.DAGScheduler: Registering RDD 11 (count at NativeMethodAccessorImpl.java:-2)\n17/02/16 09:01:51 INFO spark.scheduler.DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:-2) with 1 output partitions\n17/02/16 09:01:51 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:-2)\n17/02/16 09:01:51 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)\n17/02/16 09:01:51 INFO spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 1)\n17/02/16 09:01:51 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:-2), which has no missing parents\n17/02/16 09:01:51 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(1)\n17/02/16 09:01:51 INFO spark.storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 14.9 KB, free 254.9 KB)\n17/02/16 09:01:51 INFO spark.storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.1 KB, free 261.9 KB)\n17/02/16 09:01:51 INFO spark.storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.143.133.36:35578 (size: 7.1 KB, free: 909.0 MB)\n17/02/16 09:01:51 INFO apache.spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:01:51 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[11] at count at NativeMethodAccessorImpl.java:-2)\n17/02/16 09:01:51 INFO cluster.ego.EGODeployScheduler: Adding task set 1.0 with 5 tasks\n17/02/16 09:01:51 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, yp-spark-dal09-env5-0047, partition 0,PROCESS_LOCAL, 2733 bytes)\n17/02/16 09:01:51 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2733 bytes)\n17/02/16 09:01:51 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, yp-spark-dal09-env5-0034, partition 2,PROCESS_LOCAL, 2733 bytes)\n17/02/16 09:01:51 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2733 bytes)\n17/02/16 09:01:51 INFO spark.storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 7.1 KB, free: 4.3 GB)\n17/02/16 09:01:51 INFO spark.storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 7.1 KB, free: 4.3 GB)\n17/02/16 09:01:51 INFO spark.storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 7.1 KB, free: 4.3 GB)\n17/02/16 09:01:51 INFO spark.storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 7.1 KB, free: 4.3 GB)\n17/02/16 09:01:53 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, yp-spark-dal09-env5-0047, partition 4,PROCESS_LOCAL, 2733 bytes)\n17/02/16 09:02:07 INFO spark.storage.BlockManagerInfo: Added rdd_8_0 in memory on yp-spark-dal09-env5-0047:34157 (size: 11.9 MB, free: 4.3 GB)\n17/02/16 09:02:07 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 15751 ms on yp-spark-dal09-env5-0047 (1/5)\n17/02/16 09:02:14 INFO spark.storage.BlockManagerInfo: Added rdd_8_1 in memory on yp-spark-dal09-env5-0031:38585 (size: 12.3 MB, free: 4.3 GB)\n17/02/16 09:02:14 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 22812 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:02:21 INFO spark.storage.BlockManagerInfo: Added rdd_8_2 in memory on yp-spark-dal09-env5-0034:45747 (size: 12.2 MB, free: 4.3 GB)\n17/02/16 09:02:21 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 29857 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:02:28 INFO spark.storage.BlockManagerInfo: Added rdd_8_3 in memory on yp-spark-dal09-env5-0044:36970 (size: 12.4 MB, free: 4.3 GB)\n17/02/16 09:02:28 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 37164 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:02:33 INFO spark.storage.BlockManagerInfo: Added rdd_8_4 in memory on yp-spark-dal09-env5-0047:34157 (size: 12.3 MB, free: 4.3 GB)\n17/02/16 09:02:33 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 39509 ms on yp-spark-dal09-env5-0047 (5/5)\n17/02/16 09:02:33 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \n17/02/16 09:02:33 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:-2) finished in 41.476 s\n17/02/16 09:02:33 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:33 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:33 INFO spark.scheduler.DAGScheduler: waiting: Set(ResultStage 2)\n17/02/16 09:02:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(1)\n17/02/16 09:02:33 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:33 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at count at NativeMethodAccessorImpl.java:-2), which has no missing parents\n17/02/16 09:02:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(2)\n17/02/16 09:02:33 INFO spark.storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 9.3 KB, free 271.2 KB)\n17/02/16 09:02:33 INFO spark.storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.6 KB, free 275.8 KB)\n17/02/16 09:02:33 INFO spark.storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.143.133.36:35578 (size: 4.6 KB, free: 909.0 MB)\n17/02/16 09:02:33 INFO apache.spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:33 INFO spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at count at NativeMethodAccessorImpl.java:-2)\n17/02/16 09:02:33 INFO cluster.ego.EGODeployScheduler: Adding task set 2.0 with 1 tasks\n17/02/16 09:02:33 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, yp-spark-dal09-env5-0047, partition 0,NODE_LOCAL, 1999 bytes)\n17/02/16 09:02:33 INFO spark.storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 4.6 KB, free: 4.3 GB)\n17/02/16 09:02:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 294 bytes\n17/02/16 09:02:33 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 135 ms on yp-spark-dal09-env5-0047 (1/1)\n17/02/16 09:02:33 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool \n17/02/16 09:02:33 INFO spark.scheduler.DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:-2) finished in 0.136 s\n17/02/16 09:02:33 INFO spark.scheduler.DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:-2, took 41.665208 s\n17/02/16 09:02:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(2)\n17/02/16 09:02:33 INFO CloudantRecommender: [Found, 1000002, records in Cloudant]\n17/02/16 09:02:33 INFO CloudantRecommender: [Starting train model: , 2017-02-16 09:02:33 CST]\n17/02/16 09:02:33 INFO apache.spark.SparkContext: Starting job: runJob at PythonRDD.scala:393\n17/02/16 09:02:33 INFO spark.scheduler.DAGScheduler: Got job 2 (runJob at PythonRDD.scala:393) with 1 output partitions\n17/02/16 09:02:33 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 3 (runJob at PythonRDD.scala:393)\n17/02/16 09:02:33 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()\n17/02/16 09:02:33 INFO spark.scheduler.DAGScheduler: Missing parents: List()\n17/02/16 09:02:33 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 3 (PythonRDD[18] at RDD at PythonRDD.scala:43), which has no missing parents\n17/02/16 09:02:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(3)\n17/02/16 09:02:33 INFO spark.storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.4 KB, free 289.2 KB)\n17/02/16 09:02:33 INFO spark.storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.1 KB, free 296.2 KB)\n17/02/16 09:02:33 INFO spark.storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.143.133.36:35578 (size: 7.1 KB, free: 909.0 MB)\n17/02/16 09:02:33 INFO apache.spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:33 INFO spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (PythonRDD[18] at RDD at PythonRDD.scala:43)\n17/02/16 09:02:33 INFO cluster.ego.EGODeployScheduler: Adding task set 3.0 with 1 tasks\n17/02/16 09:02:33 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 11, yp-spark-dal09-env5-0047, partition 0,PROCESS_LOCAL, 2744 bytes)\n17/02/16 09:02:33 INFO spark.storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 7.1 KB, free: 4.3 GB)\n17/02/16 09:02:34 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 11) in 771 ms on yp-spark-dal09-env5-0047 (1/1)\n17/02/16 09:02:34 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool \n17/02/16 09:02:34 INFO spark.scheduler.DAGScheduler: ResultStage 3 (runJob at PythonRDD.scala:393) finished in 0.773 s\n17/02/16 09:02:34 INFO spark.scheduler.DAGScheduler: Job 2 finished: runJob at PythonRDD.scala:393, took 0.791609 s\n17/02/16 09:02:34 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(3)\n17/02/16 09:02:34 INFO apache.spark.SparkContext: Starting job: count at ALS.scala:596\n17/02/16 09:02:34 INFO spark.scheduler.DAGScheduler: Registering RDD 22 (mapPartitions at ALS.scala:837)\n17/02/16 09:02:34 INFO spark.scheduler.DAGScheduler: Registering RDD 25 (map at ALS.scala:1080)\n17/02/16 09:02:34 INFO spark.scheduler.DAGScheduler: Got job 3 (count at ALS.scala:596) with 5 output partitions\n17/02/16 09:02:34 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 6 (count at ALS.scala:596)\n17/02/16 09:02:34 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)\n17/02/16 09:02:34 INFO spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 5)\n17/02/16 09:02:34 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[22] at mapPartitions at ALS.scala:837), which has no missing parents\n17/02/16 09:02:34 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(4)\n17/02/16 09:02:34 INFO spark.storage.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 15.4 KB, free 311.6 KB)\n17/02/16 09:02:34 INFO spark.storage.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.8 KB, free 319.4 KB)\n17/02/16 09:02:34 INFO spark.storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.143.133.36:35578 (size: 7.8 KB, free: 909.0 MB)\n17/02/16 09:02:34 INFO apache.spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:34 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[22] at mapPartitions at ALS.scala:837)\n17/02/16 09:02:34 INFO cluster.ego.EGODeployScheduler: Adding task set 4.0 with 5 tasks\n17/02/16 09:02:34 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 4.0 (TID 12, yp-spark-dal09-env5-0034, partition 2,PROCESS_LOCAL, 2733 bytes)\n17/02/16 09:02:34 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 4.0 (TID 13, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2733 bytes)\n17/02/16 09:02:34 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 14, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2733 bytes)\n17/02/16 09:02:34 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 15, yp-spark-dal09-env5-0047, partition 0,PROCESS_LOCAL, 2733 bytes)\n17/02/16 09:02:34 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 4.0 (TID 16, yp-spark-dal09-env5-0047, partition 4,PROCESS_LOCAL, 2733 bytes)\n17/02/16 09:02:34 INFO spark.storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 7.8 KB, free: 4.3 GB)\n17/02/16 09:02:34 INFO spark.storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 7.8 KB, free: 4.3 GB)\n17/02/16 09:02:34 INFO spark.storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 7.8 KB, free: 4.3 GB)\n17/02/16 09:02:34 INFO spark.storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 7.8 KB, free: 4.3 GB)\n17/02/16 09:02:34 WARN spark.scheduler.TaskSetManager: Lost task 4.0 in stage 4.0 (TID 16, yp-spark-dal09-env5-0047): net.razorvine.pickle.PickleException: couldn't introspect javabean: java.lang.IllegalArgumentException: wrong number of arguments\n\tat net.razorvine.pickle.Pickler.put_javabean(Pickler.java:705)\n\tat net.razorvine.pickle.Pickler.dispatch(Pickler.java:323)\n\tat net.razorvine.pickle.Pickler.save(Pickler.java:137)\n\tat net.razorvine.pickle.Pickler.put_arrayOfObjects(Pickler.java:513)\n\tat net.razorvine.pickle.Pickler.dispatch(Pickler.java:205)\n\tat net.razorvine.pickle.Pickler.save(Pickler.java:137)\n\tat net.razorvine.pickle.Pickler.dump(Pickler.java:107)\n\tat net.razorvine.pickle.Pickler.dumps(Pickler.java:92)\n\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.next(SerDeUtil.scala:121)\n\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.next(SerDeUtil.scala:110)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:727)\n\tat org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:110)\n\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:452)\n\tat org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:280)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1823)\n\tat org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:239)\n\n17/02/16 09:02:34 INFO spark.scheduler.TaskSetManager: Lost task 0.0 in stage 4.0 (TID 15) on executor yp-spark-dal09-env5-0047: net.razorvine.pickle.PickleException (couldn't introspect javabean: java.lang.IllegalArgumentException: wrong number of arguments) [duplicate 1]\n17/02/16 09:02:34 INFO spark.scheduler.TaskSetManager: Starting task 0.1 in stage 4.0 (TID 17, yp-spark-dal09-env5-0047, partition 0,PROCESS_LOCAL, 2733 bytes)\n17/02/16 09:02:34 INFO spark.scheduler.TaskSetManager: Starting task 4.1 in stage 4.0 (TID 18, yp-spark-dal09-env5-0047, partition 4,PROCESS_LOCAL, 2733 bytes)\n17/02/16 09:02:37 INFO spark.scheduler.TaskSetManager: Finished task 4.1 in stage 4.0 (TID 18) in 2528 ms on yp-spark-dal09-env5-0047 (1/5)\n17/02/16 09:02:37 INFO spark.scheduler.TaskSetManager: Finished task 0.1 in stage 4.0 (TID 17) in 2530 ms on yp-spark-dal09-env5-0047 (2/5)\n17/02/16 09:02:37 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 4.0 (TID 14) in 3206 ms on yp-spark-dal09-env5-0031 (3/5)\n17/02/16 09:02:37 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 4.0 (TID 12) in 3227 ms on yp-spark-dal09-env5-0034 (4/5)\n17/02/16 09:02:37 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 4.0 (TID 13) in 3342 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:02:37 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool \n17/02/16 09:02:37 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 4 (mapPartitions at ALS.scala:837) finished in 3.344 s\n17/02/16 09:02:37 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:37 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:37 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6)\n17/02/16 09:02:37 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:37 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(4)\n17/02/16 09:02:37 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[25] at map at ALS.scala:1080), which has no missing parents\n17/02/16 09:02:37 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(5)\n17/02/16 09:02:37 INFO spark.storage.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 16.5 KB, free 335.9 KB)\n17/02/16 09:02:37 INFO spark.storage.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.3 KB, free 344.2 KB)\n17/02/16 09:02:37 INFO spark.storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.143.133.36:35578 (size: 8.3 KB, free: 908.9 MB)\n17/02/16 09:02:37 INFO apache.spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:37 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[25] at map at ALS.scala:1080)\n17/02/16 09:02:37 INFO cluster.ego.EGODeployScheduler: Adding task set 5.0 with 5 tasks\n17/02/16 09:02:37 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 19, yp-spark-dal09-env5-0031, partition 0,NODE_LOCAL, 1883 bytes)\n17/02/16 09:02:37 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 5.0 (TID 20, yp-spark-dal09-env5-0044, partition 1,NODE_LOCAL, 1883 bytes)\n17/02/16 09:02:37 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 5.0 (TID 21, yp-spark-dal09-env5-0034, partition 2,NODE_LOCAL, 1883 bytes)\n17/02/16 09:02:37 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 5.0 (TID 22, yp-spark-dal09-env5-0047, partition 3,NODE_LOCAL, 1883 bytes)\n17/02/16 09:02:37 INFO spark.storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 8.3 KB, free: 4.3 GB)\n17/02/16 09:02:37 INFO spark.storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 8.3 KB, free: 4.3 GB)\n17/02/16 09:02:37 INFO spark.storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 8.3 KB, free: 4.3 GB)\n17/02/16 09:02:37 INFO spark.storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 8.3 KB, free: 4.3 GB)\n17/02/16 09:02:37 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:37 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 310 bytes\n17/02/16 09:02:37 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:37 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:37 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:37 INFO spark.storage.BlockManagerInfo: Added rdd_24_3 in memory on yp-spark-dal09-env5-0047:34157 (size: 2.7 MB, free: 4.3 GB)\n17/02/16 09:02:37 INFO spark.storage.BlockManagerInfo: Added rdd_24_0 in memory on yp-spark-dal09-env5-0031:38585 (size: 1407.0 KB, free: 4.3 GB)\n17/02/16 09:02:37 INFO spark.storage.BlockManagerInfo: Added rdd_24_1 in memory on yp-spark-dal09-env5-0044:36970 (size: 3.2 MB, free: 4.3 GB)\n17/02/16 09:02:37 INFO spark.storage.BlockManagerInfo: Added rdd_24_2 in memory on yp-spark-dal09-env5-0034:45747 (size: 3.2 MB, free: 4.3 GB)\n17/02/16 09:02:37 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 5.0 (TID 23, yp-spark-dal09-env5-0031, partition 4,NODE_LOCAL, 1883 bytes)\n17/02/16 09:02:37 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 19) in 300 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:02:37 INFO spark.storage.BlockManagerInfo: Added rdd_24_4 in memory on yp-spark-dal09-env5-0031:38585 (size: 927.8 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 5.0 (TID 22) in 354 ms on yp-spark-dal09-env5-0047 (2/5)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 5.0 (TID 23) in 70 ms on yp-spark-dal09-env5-0031 (3/5)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 5.0 (TID 20) in 394 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 5.0 (TID 21) in 430 ms on yp-spark-dal09-env5-0034 (5/5)\n17/02/16 09:02:38 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 5 (map at ALS.scala:1080) finished in 0.432 s\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: waiting: Set(ResultStage 6)\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:38 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(5)\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 6 (userOutBlocks MapPartitionsRDD[28] at mapValues at ALS.scala:1117), which has no missing parents\n17/02/16 09:02:38 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(6)\n17/02/16 09:02:38 INFO spark.storage.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 17.1 KB, free 361.3 KB)\n17/02/16 09:02:38 INFO spark.storage.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 8.5 KB, free 369.8 KB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.143.133.36:35578 (size: 8.5 KB, free: 908.9 MB)\n17/02/16 09:02:38 INFO apache.spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 6 (userOutBlocks MapPartitionsRDD[28] at mapValues at ALS.scala:1117)\n17/02/16 09:02:38 INFO cluster.ego.EGODeployScheduler: Adding task set 6.0 with 5 tasks\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 24, yp-spark-dal09-env5-0031, partition 0,NODE_LOCAL, 1894 bytes)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 25, yp-spark-dal09-env5-0044, partition 1,NODE_LOCAL, 1894 bytes)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 6.0 (TID 26, yp-spark-dal09-env5-0034, partition 3,NODE_LOCAL, 1894 bytes)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 6.0 (TID 27, yp-spark-dal09-env5-0047, partition 2,NODE_LOCAL, 1894 bytes)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:38 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 322 bytes\n17/02/16 09:02:38 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:38 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:38 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added rdd_27_0 in memory on yp-spark-dal09-env5-0031:38585 (size: 1559.8 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added rdd_27_3 in memory on yp-spark-dal09-env5-0034:45747 (size: 1561.8 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added rdd_27_1 in memory on yp-spark-dal09-env5-0044:36970 (size: 1601.2 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added rdd_28_0 in memory on yp-spark-dal09-env5-0031:38585 (size: 23.8 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added rdd_27_2 in memory on yp-spark-dal09-env5-0047:34157 (size: 1572.5 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 6.0 (TID 28, yp-spark-dal09-env5-0031, partition 4,NODE_LOCAL, 1894 bytes)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 24) in 306 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added rdd_28_3 in memory on yp-spark-dal09-env5-0034:45747 (size: 23.8 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 6.0 (TID 26) in 310 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added rdd_28_1 in memory on yp-spark-dal09-env5-0044:36970 (size: 23.8 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 6.0 (TID 25) in 326 ms on yp-spark-dal09-env5-0044 (3/5)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added rdd_28_2 in memory on yp-spark-dal09-env5-0047:34157 (size: 23.8 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 6.0 (TID 27) in 338 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added rdd_27_4 in memory on yp-spark-dal09-env5-0031:38585 (size: 1565.2 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added rdd_28_4 in memory on yp-spark-dal09-env5-0031:38585 (size: 23.8 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 6.0 (TID 28) in 143 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:02:38 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool \n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: ResultStage 6 (count at ALS.scala:596) finished in 0.450 s\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: Job 3 finished: count at ALS.scala:596, took 4.267469 s\n17/02/16 09:02:38 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(6)\n17/02/16 09:02:38 INFO apache.spark.SparkContext: Starting job: count at ALS.scala:604\n17/02/16 09:02:38 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 310 bytes\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: Registering RDD 30 (map at ALS.scala:1080)\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: Got job 4 (count at ALS.scala:604) with 5 output partitions\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 9 (count at ALS.scala:604)\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 8)\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[30] at map at ALS.scala:1080), which has no missing parents\n17/02/16 09:02:38 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(8)\n17/02/16 09:02:38 INFO spark.storage.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 16.7 KB, free 386.5 KB)\n17/02/16 09:02:38 INFO spark.storage.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KB, free 394.8 KB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.143.133.36:35578 (size: 8.3 KB, free: 908.9 MB)\n17/02/16 09:02:38 INFO apache.spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[30] at map at ALS.scala:1080)\n17/02/16 09:02:38 INFO cluster.ego.EGODeployScheduler: Adding task set 8.0 with 5 tasks\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 8.0 (TID 29, yp-spark-dal09-env5-0034, partition 2,PROCESS_LOCAL, 1883 bytes)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 8.0 (TID 30, yp-spark-dal09-env5-0047, partition 3,PROCESS_LOCAL, 1883 bytes)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 8.0 (TID 31, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 1883 bytes)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 32, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 1883 bytes)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 8.3 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 8.3 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 8.3 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 8.3 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 8.0 (TID 33, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 1883 bytes)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 32) in 62 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 8.0 (TID 30) in 97 ms on yp-spark-dal09-env5-0047 (2/5)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 8.0 (TID 33) in 39 ms on yp-spark-dal09-env5-0031 (3/5)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 8.0 (TID 29) in 108 ms on yp-spark-dal09-env5-0034 (4/5)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 8.0 (TID 31) in 113 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:02:38 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool \n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 8 (map at ALS.scala:1080) finished in 0.115 s\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: waiting: Set(ResultStage 9)\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:38 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(8)\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 9 (itemOutBlocks MapPartitionsRDD[33] at mapValues at ALS.scala:1117), which has no missing parents\n17/02/16 09:02:38 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(9)\n17/02/16 09:02:38 INFO spark.storage.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 17.3 KB, free 412.1 KB)\n17/02/16 09:02:38 INFO spark.storage.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.5 KB, free 420.6 KB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.143.133.36:35578 (size: 8.5 KB, free: 908.9 MB)\n17/02/16 09:02:38 INFO apache.spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:38 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 9 (itemOutBlocks MapPartitionsRDD[33] at mapValues at ALS.scala:1117)\n17/02/16 09:02:38 INFO cluster.ego.EGODeployScheduler: Adding task set 9.0 with 5 tasks\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 34, yp-spark-dal09-env5-0034, partition 0,NODE_LOCAL, 1894 bytes)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 9.0 (TID 35, yp-spark-dal09-env5-0031, partition 1,NODE_LOCAL, 1894 bytes)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 9.0 (TID 36, yp-spark-dal09-env5-0047, partition 2,NODE_LOCAL, 1894 bytes)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 9.0 (TID 37, yp-spark-dal09-env5-0044, partition 3,NODE_LOCAL, 1894 bytes)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:38 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 318 bytes\n17/02/16 09:02:38 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:38 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:38 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added rdd_32_1 in memory on yp-spark-dal09-env5-0031:38585 (size: 1576.8 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.storage.BlockManagerInfo: Added rdd_33_1 in memory on yp-spark-dal09-env5-0031:38585 (size: 14.0 KB, free: 4.3 GB)\n17/02/16 09:02:38 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 9.0 (TID 35) in 275 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Added rdd_32_3 in memory on yp-spark-dal09-env5-0044:36970 (size: 1674.2 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Added rdd_33_3 in memory on yp-spark-dal09-env5-0044:36970 (size: 13.5 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 9.0 (TID 38, yp-spark-dal09-env5-0044, partition 4,NODE_LOCAL, 1894 bytes)\n17/02/16 09:02:39 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 9.0 (TID 37) in 401 ms on yp-spark-dal09-env5-0044 (2/5)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Added rdd_32_2 in memory on yp-spark-dal09-env5-0047:34157 (size: 1541.1 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Added rdd_33_2 in memory on yp-spark-dal09-env5-0047:34157 (size: 13.8 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 9.0 (TID 36) in 416 ms on yp-spark-dal09-env5-0047 (3/5)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Added rdd_32_0 in memory on yp-spark-dal09-env5-0034:45747 (size: 1574.0 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Added rdd_33_0 in memory on yp-spark-dal09-env5-0034:45747 (size: 13.6 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 34) in 442 ms on yp-spark-dal09-env5-0034 (4/5)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Added rdd_32_4 in memory on yp-spark-dal09-env5-0044:36970 (size: 1476.1 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Added rdd_33_4 in memory on yp-spark-dal09-env5-0044:36970 (size: 13.8 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 9.0 (TID 38) in 173 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:02:39 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \n17/02/16 09:02:39 INFO spark.scheduler.DAGScheduler: ResultStage 9 (count at ALS.scala:604) finished in 0.576 s\n17/02/16 09:02:39 INFO spark.scheduler.DAGScheduler: Job 4 finished: count at ALS.scala:604, took 0.711738 s\n17/02/16 09:02:39 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(9)\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned accumulator 14\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_2_piece0 on 10.143.133.36:35578 in memory (size: 7.1 KB, free: 908.9 MB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_2_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 7.1 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_2_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 7.1 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_2_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 7.1 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_2_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 7.1 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned accumulator 13\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned shuffle 0\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned accumulator 12\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned accumulator 11\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned accumulator 10\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned accumulator 9\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned accumulator 8\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned accumulator 7\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned accumulator 6\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned accumulator 5\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.143.133.36:35578 in memory (size: 19.3 KB, free: 908.9 MB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.143.133.36:35578 in memory (size: 8.5 KB, free: 909.0 MB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_9_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_9_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_9_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_9_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned accumulator 20\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_8_piece0 on 10.143.133.36:35578 in memory (size: 8.3 KB, free: 909.0 MB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_8_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 8.3 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_8_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 8.3 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_8_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 8.3 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_8_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 8.3 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned accumulator 19\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.143.133.36:35578 in memory (size: 8.5 KB, free: 909.0 MB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_7_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_7_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_7_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_7_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned accumulator 18\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.143.133.36:35578 in memory (size: 8.3 KB, free: 909.0 MB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_6_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 8.3 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_6_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 8.3 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_6_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 8.3 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_6_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 8.3 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned accumulator 17\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.143.133.36:35578 in memory (size: 7.8 KB, free: 909.0 MB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_5_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 7.8 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_5_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 7.8 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_5_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 7.8 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_5_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 7.8 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned accumulator 16\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.143.133.36:35578 in memory (size: 7.1 KB, free: 909.0 MB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_4_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 7.1 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO apache.spark.ContextCleaner: Cleaned accumulator 15\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.143.133.36:35578 in memory (size: 4.6 KB, free: 909.0 MB)\n17/02/16 09:02:39 INFO spark.storage.BlockManagerInfo: Removed broadcast_3_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 4.6 KB, free: 4.3 GB)\n17/02/16 09:02:39 INFO apache.spark.SparkContext: Starting job: count at ALS.scala:263\n17/02/16 09:02:39 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 310 bytes\n17/02/16 09:02:39 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 322 bytes\n17/02/16 09:02:39 INFO spark.scheduler.DAGScheduler: Registering RDD 34 (map at ALS.scala:752)\n17/02/16 09:02:39 INFO spark.scheduler.DAGScheduler: Registering RDD 39 (flatMap at ALS.scala:1170)\n17/02/16 09:02:39 INFO spark.scheduler.DAGScheduler: Registering RDD 48 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 57 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 66 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 75 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 84 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 93 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 102 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 111 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 120 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 129 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 138 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 147 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 156 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 165 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 174 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 183 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 192 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 201 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 210 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 219 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 228 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 237 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 246 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 255 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 264 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 273 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 282 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 291 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 300 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 309 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 318 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 327 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 336 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 345 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 354 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 363 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 372 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 381 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Registering RDD 390 (flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Got job 5 (count at ALS.scala:263) with 5 output partitions\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 55 (count at ALS.scala:263)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 13, ShuffleMapStage 54)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 54)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[34] at map at ALS.scala:752), which has no missing parents\n17/02/16 09:02:40 INFO spark.storage.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 17.1 KB, free 17.1 KB)\n17/02/16 09:02:40 INFO spark.storage.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 8.5 KB, free 25.6 KB)\n17/02/16 09:02:40 INFO spark.storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.143.133.36:35578 (size: 8.5 KB, free: 909.0 MB)\n17/02/16 09:02:40 INFO apache.spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[34] at map at ALS.scala:752)\n17/02/16 09:02:40 INFO cluster.ego.EGODeployScheduler: Adding task set 14.0 with 5 tasks\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 14.0 (TID 39, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 1883 bytes)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 40, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 1883 bytes)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 14.0 (TID 41, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 1883 bytes)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 14.0 (TID 42, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 1883 bytes)\n17/02/16 09:02:40 INFO spark.storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:40 INFO spark.storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:40 INFO spark.storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:40 INFO spark.storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:40 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(14)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 14.0 (TID 42) in 61 ms on yp-spark-dal09-env5-0047 (1/5)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 14.0 (TID 39) in 67 ms on yp-spark-dal09-env5-0044 (2/5)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 14.0 (TID 43, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 1883 bytes)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 40) in 70 ms on yp-spark-dal09-env5-0031 (3/5)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 14.0 (TID 41) in 81 ms on yp-spark-dal09-env5-0034 (4/5)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 14.0 (TID 43) in 43 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:02:40 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 14.0, whose tasks have all completed, from pool \n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 14 (map at ALS.scala:752) finished in 0.114 s\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 30, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 54, ShuffleMapStage 25, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 26, ShuffleMapStage 48, ShuffleMapStage 27, ShuffleMapStage 19, ShuffleMapStage 49, ShuffleMapStage 20, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 21, ShuffleMapStage 43, ShuffleMapStage 22, ShuffleMapStage 44, ShuffleMapStage 23, ShuffleMapStage 15, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 16, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 17, ShuffleMapStage 39, ShuffleMapStage 18, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:40 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(14)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[39] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:40 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(15)\n17/02/16 09:02:40 INFO spark.storage.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 18.2 KB, free 43.8 KB)\n17/02/16 09:02:40 INFO spark.storage.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 8.8 KB, free 52.6 KB)\n17/02/16 09:02:40 INFO spark.storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.143.133.36:35578 (size: 8.8 KB, free: 909.0 MB)\n17/02/16 09:02:40 INFO apache.spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[39] at flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO cluster.ego.EGODeployScheduler: Adding task set 15.0 with 5 tasks\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 15.0 (TID 44, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2110 bytes)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 15.0 (TID 45, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2110 bytes)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 15.0 (TID 46, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2110 bytes)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 47, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2110 bytes)\n17/02/16 09:02:40 INFO spark.storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 8.8 KB, free: 4.3 GB)\n17/02/16 09:02:40 INFO spark.storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 8.8 KB, free: 4.3 GB)\n17/02/16 09:02:40 INFO spark.storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 8.8 KB, free: 4.3 GB)\n17/02/16 09:02:40 INFO spark.storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 8.8 KB, free: 4.3 GB)\n17/02/16 09:02:40 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:40 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 44 is 313 bytes\n17/02/16 09:02:40 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:40 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:40 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 44 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 15.0 (TID 44) in 51 ms on yp-spark-dal09-env5-0047 (1/5)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 15.0 (TID 48, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2110 bytes)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 47) in 56 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 15.0 (TID 46) in 80 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 15.0 (TID 45) in 85 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 15.0 (TID 48) in 33 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:02:40 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 15.0, whose tasks have all completed, from pool \n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 15 (flatMap at ALS.scala:1170) finished in 0.091 s\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 30, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 54, ShuffleMapStage 25, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 26, ShuffleMapStage 48, ShuffleMapStage 27, ShuffleMapStage 19, ShuffleMapStage 49, ShuffleMapStage 20, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 21, ShuffleMapStage 43, ShuffleMapStage 22, ShuffleMapStage 44, ShuffleMapStage 23, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 16, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 17, ShuffleMapStage 39, ShuffleMapStage 18, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:40 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(15)\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[48] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:40 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(16)\n17/02/16 09:02:40 INFO spark.storage.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 20.4 KB, free 72.9 KB)\n17/02/16 09:02:40 INFO spark.storage.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 9.5 KB, free 82.4 KB)\n17/02/16 09:02:40 INFO spark.storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.143.133.36:35578 (size: 9.5 KB, free: 909.0 MB)\n17/02/16 09:02:40 INFO apache.spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:40 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[48] at flatMap at ALS.scala:1170)\n17/02/16 09:02:40 INFO cluster.ego.EGODeployScheduler: Adding task set 16.0 with 5 tasks\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 16.0 (TID 49, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 16.0 (TID 50, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 16.0 (TID 51, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:40 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 16.0 (TID 52, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:40 INFO spark.storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 9.5 KB, free: 4.3 GB)\n17/02/16 09:02:40 INFO spark.storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 9.5 KB, free: 4.3 GB)\n17/02/16 09:02:40 INFO spark.storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 9.5 KB, free: 4.3 GB)\n17/02/16 09:02:40 INFO spark.storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 9.5 KB, free: 4.3 GB)\n17/02/16 09:02:40 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:40 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:40 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 43 is 296 bytes\n17/02/16 09:02:40 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 43 is 296 bytes\n17/02/16 09:02:40 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:40 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 43 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:41 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 16.0 (TID 51) in 819 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:02:41 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 16.0 (TID 53, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:41 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 16.0 (TID 50) in 876 ms on yp-spark-dal09-env5-0044 (2/5)\n17/02/16 09:02:41 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 16.0 (TID 49) in 891 ms on yp-spark-dal09-env5-0047 (3/5)\n17/02/16 09:02:41 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 16.0 (TID 52) in 907 ms on yp-spark-dal09-env5-0034 (4/5)\n17/02/16 09:02:41 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 16.0 (TID 53) in 511 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:02:41 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 16.0, whose tasks have all completed, from pool \n17/02/16 09:02:41 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 16 (flatMap at ALS.scala:1170) finished in 1.388 s\n17/02/16 09:02:41 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:41 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:41 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 30, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 54, ShuffleMapStage 25, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 26, ShuffleMapStage 48, ShuffleMapStage 27, ShuffleMapStage 19, ShuffleMapStage 49, ShuffleMapStage 20, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 21, ShuffleMapStage 43, ShuffleMapStage 22, ShuffleMapStage 44, ShuffleMapStage 23, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 17, ShuffleMapStage 39, ShuffleMapStage 18, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)\n17/02/16 09:02:41 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:41 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(16)\n17/02/16 09:02:41 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[57] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:41 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(17)\n17/02/16 09:02:41 INFO spark.storage.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 21.3 KB, free 103.7 KB)\n17/02/16 09:02:41 INFO spark.storage.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 9.7 KB, free 113.4 KB)\n17/02/16 09:02:41 INFO spark.storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.143.133.36:35578 (size: 9.7 KB, free: 909.0 MB)\n17/02/16 09:02:41 INFO apache.spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:41 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[57] at flatMap at ALS.scala:1170)\n17/02/16 09:02:41 INFO cluster.ego.EGODeployScheduler: Adding task set 17.0 with 5 tasks\n17/02/16 09:02:41 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 17.0 (TID 54, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:41 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 17.0 (TID 55, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:41 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 56, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:41 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 17.0 (TID 57, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:41 INFO spark.storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 9.7 KB, free: 4.3 GB)\n17/02/16 09:02:41 INFO spark.storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 9.7 KB, free: 4.3 GB)\n17/02/16 09:02:41 INFO spark.storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 9.7 KB, free: 4.3 GB)\n17/02/16 09:02:41 INFO spark.storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 9.7 KB, free: 4.3 GB)\n17/02/16 09:02:41 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:41 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 42 is 294 bytes\n17/02/16 09:02:41 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:41 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:41 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 42 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:42 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 17.0 (TID 57) in 408 ms on yp-spark-dal09-env5-0044 (1/5)\n17/02/16 09:02:42 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 17.0 (TID 55) in 433 ms on yp-spark-dal09-env5-0047 (2/5)\n17/02/16 09:02:42 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 17.0 (TID 54) in 554 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:02:42 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 17.0 (TID 58, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:42 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 56) in 556 ms on yp-spark-dal09-env5-0031 (4/5)\n17/02/16 09:02:42 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 17.0 (TID 58) in 400 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:02:42 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 17.0, whose tasks have all completed, from pool \n17/02/16 09:02:42 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 17 (flatMap at ALS.scala:1170) finished in 0.957 s\n17/02/16 09:02:42 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:42 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:42 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 30, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 54, ShuffleMapStage 25, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 26, ShuffleMapStage 48, ShuffleMapStage 27, ShuffleMapStage 19, ShuffleMapStage 49, ShuffleMapStage 20, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 21, ShuffleMapStage 43, ShuffleMapStage 22, ShuffleMapStage 44, ShuffleMapStage 23, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 18, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)\n17/02/16 09:02:42 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:42 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(17)\n17/02/16 09:02:42 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[66] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:42 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(18)\n17/02/16 09:02:42 INFO spark.storage.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 22.1 KB, free 135.5 KB)\n17/02/16 09:02:42 INFO spark.storage.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 9.9 KB, free 145.4 KB)\n17/02/16 09:02:42 INFO spark.storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.143.133.36:35578 (size: 9.9 KB, free: 909.0 MB)\n17/02/16 09:02:42 INFO apache.spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:42 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[66] at flatMap at ALS.scala:1170)\n17/02/16 09:02:42 INFO cluster.ego.EGODeployScheduler: Adding task set 18.0 with 5 tasks\n17/02/16 09:02:42 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 18.0 (TID 59, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:42 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 18.0 (TID 60, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:42 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 61, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:42 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 18.0 (TID 62, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:42 INFO spark.storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 9.9 KB, free: 4.3 GB)\n17/02/16 09:02:42 INFO spark.storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 9.9 KB, free: 4.3 GB)\n17/02/16 09:02:42 INFO spark.storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 9.9 KB, free: 4.3 GB)\n17/02/16 09:02:42 INFO spark.storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 9.9 KB, free: 4.3 GB)\n17/02/16 09:02:42 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:42 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 41 is 296 bytes\n17/02/16 09:02:42 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:42 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:42 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 41 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:43 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 18.0 (TID 62) in 379 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:02:43 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 18.0 (TID 59) in 381 ms on yp-spark-dal09-env5-0047 (2/5)\n17/02/16 09:02:43 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 61) in 383 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:02:43 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 18.0 (TID 63, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:43 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 18.0 (TID 60) in 390 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:02:43 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 18.0 (TID 63) in 344 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:02:43 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 18.0, whose tasks have all completed, from pool \n17/02/16 09:02:43 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 18 (flatMap at ALS.scala:1170) finished in 0.735 s\n17/02/16 09:02:43 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:43 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:43 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 30, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 54, ShuffleMapStage 25, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 26, ShuffleMapStage 48, ShuffleMapStage 27, ShuffleMapStage 19, ShuffleMapStage 49, ShuffleMapStage 20, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 21, ShuffleMapStage 43, ShuffleMapStage 22, ShuffleMapStage 44, ShuffleMapStage 23, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)\n17/02/16 09:02:43 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:43 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(18)\n17/02/16 09:02:43 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[75] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:43 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(19)\n17/02/16 09:02:43 INFO spark.storage.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 23.0 KB, free 168.4 KB)\n17/02/16 09:02:43 INFO spark.storage.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 10.1 KB, free 178.5 KB)\n17/02/16 09:02:43 INFO spark.storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.143.133.36:35578 (size: 10.1 KB, free: 908.9 MB)\n17/02/16 09:02:43 INFO apache.spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:43 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[75] at flatMap at ALS.scala:1170)\n17/02/16 09:02:43 INFO cluster.ego.EGODeployScheduler: Adding task set 19.0 with 5 tasks\n17/02/16 09:02:43 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 19.0 (TID 64, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:43 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 19.0 (TID 65, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:43 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 66, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:43 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 19.0 (TID 67, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:43 INFO spark.storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 10.1 KB, free: 4.3 GB)\n17/02/16 09:02:43 INFO spark.storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 10.1 KB, free: 4.3 GB)\n17/02/16 09:02:43 INFO spark.storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 10.1 KB, free: 4.3 GB)\n17/02/16 09:02:43 INFO spark.storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 10.1 KB, free: 4.3 GB)\n17/02/16 09:02:43 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:43 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:43 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 40 is 294 bytes\n17/02/16 09:02:43 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 40 is 294 bytes\n17/02/16 09:02:43 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:43 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 40 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:43 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 19.0 (TID 64) in 394 ms on yp-spark-dal09-env5-0034 (1/5)\n17/02/16 09:02:43 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 19.0 (TID 68, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:43 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 66) in 394 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:02:43 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 19.0 (TID 65) in 396 ms on yp-spark-dal09-env5-0044 (3/5)\n17/02/16 09:02:43 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 19.0 (TID 67) in 401 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:02:44 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 19.0 (TID 68) in 386 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:02:44 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 19.0, whose tasks have all completed, from pool \n17/02/16 09:02:44 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 19 (flatMap at ALS.scala:1170) finished in 0.781 s\n17/02/16 09:02:44 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:44 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:44 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 30, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 54, ShuffleMapStage 25, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 26, ShuffleMapStage 48, ShuffleMapStage 27, ShuffleMapStage 49, ShuffleMapStage 20, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 21, ShuffleMapStage 43, ShuffleMapStage 22, ShuffleMapStage 44, ShuffleMapStage 23, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)\n17/02/16 09:02:44 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:44 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(19)\n17/02/16 09:02:44 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[84] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:44 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(20)\n17/02/16 09:02:44 INFO spark.storage.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 23.9 KB, free 202.4 KB)\n17/02/16 09:02:44 INFO spark.storage.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 10.3 KB, free 212.7 KB)\n17/02/16 09:02:44 INFO spark.storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.143.133.36:35578 (size: 10.3 KB, free: 908.9 MB)\n17/02/16 09:02:44 INFO apache.spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:44 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[84] at flatMap at ALS.scala:1170)\n17/02/16 09:02:44 INFO cluster.ego.EGODeployScheduler: Adding task set 20.0 with 5 tasks\n17/02/16 09:02:44 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 20.0 (TID 69, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:44 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 20.0 (TID 70, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:44 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 20.0 (TID 71, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:44 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 20.0 (TID 72, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:44 INFO spark.storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 10.3 KB, free: 4.3 GB)\n17/02/16 09:02:44 INFO spark.storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 10.3 KB, free: 4.3 GB)\n17/02/16 09:02:44 INFO spark.storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 10.3 KB, free: 4.3 GB)\n17/02/16 09:02:44 INFO spark.storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 10.3 KB, free: 4.3 GB)\n17/02/16 09:02:44 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:44 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 39 is 296 bytes\n17/02/16 09:02:44 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:44 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:44 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 39 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:44 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 20.0 (TID 70) in 372 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:02:44 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 20.0 (TID 72) in 372 ms on yp-spark-dal09-env5-0047 (2/5)\n17/02/16 09:02:44 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 20.0 (TID 69) in 375 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:02:44 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 20.0 (TID 73, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:44 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 20.0 (TID 71) in 391 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:02:44 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 20.0 (TID 73) in 344 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:02:44 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 20.0, whose tasks have all completed, from pool \n17/02/16 09:02:44 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 20 (flatMap at ALS.scala:1170) finished in 0.737 s\n17/02/16 09:02:44 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:44 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:44 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 30, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 54, ShuffleMapStage 25, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 26, ShuffleMapStage 48, ShuffleMapStage 27, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 21, ShuffleMapStage 43, ShuffleMapStage 22, ShuffleMapStage 44, ShuffleMapStage 23, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)\n17/02/16 09:02:44 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:44 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(20)\n17/02/16 09:02:44 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[93] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:44 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(21)\n17/02/16 09:02:44 INFO spark.storage.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 24.8 KB, free 237.4 KB)\n17/02/16 09:02:44 INFO spark.storage.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 10.4 KB, free 247.8 KB)\n17/02/16 09:02:44 INFO spark.storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.143.133.36:35578 (size: 10.4 KB, free: 908.9 MB)\n17/02/16 09:02:44 INFO apache.spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:44 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[93] at flatMap at ALS.scala:1170)\n17/02/16 09:02:44 INFO cluster.ego.EGODeployScheduler: Adding task set 21.0 with 5 tasks\n17/02/16 09:02:44 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 21.0 (TID 74, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:44 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 21.0 (TID 75, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:44 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 21.0 (TID 76, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:44 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 21.0 (TID 77, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:44 INFO spark.storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 10.4 KB, free: 4.3 GB)\n17/02/16 09:02:44 INFO spark.storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 10.4 KB, free: 4.3 GB)\n17/02/16 09:02:44 INFO spark.storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 10.4 KB, free: 4.3 GB)\n17/02/16 09:02:44 INFO spark.storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 10.4 KB, free: 4.3 GB)\n17/02/16 09:02:44 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:44 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:44 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 38 is 294 bytes\n17/02/16 09:02:44 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 38 is 294 bytes\n17/02/16 09:02:44 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:44 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 38 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:45 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 21.0 (TID 78, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:45 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 21.0 (TID 75) in 390 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:02:45 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 21.0 (TID 77) in 394 ms on yp-spark-dal09-env5-0044 (2/5)\n17/02/16 09:02:45 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 21.0 (TID 76) in 397 ms on yp-spark-dal09-env5-0047 (3/5)\n17/02/16 09:02:45 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 21.0 (TID 74) in 398 ms on yp-spark-dal09-env5-0034 (4/5)\n17/02/16 09:02:45 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 21.0 (TID 78) in 384 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:02:45 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 21.0, whose tasks have all completed, from pool \n17/02/16 09:02:45 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 21 (flatMap at ALS.scala:1170) finished in 0.774 s\n17/02/16 09:02:45 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:45 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:45 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 30, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 54, ShuffleMapStage 25, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 26, ShuffleMapStage 48, ShuffleMapStage 27, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 22, ShuffleMapStage 44, ShuffleMapStage 23, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)\n17/02/16 09:02:45 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:45 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(21)\n17/02/16 09:02:45 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[102] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:45 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(22)\n17/02/16 09:02:45 INFO spark.storage.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 25.6 KB, free 273.5 KB)\n17/02/16 09:02:45 INFO spark.storage.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 10.6 KB, free 284.1 KB)\n17/02/16 09:02:45 INFO spark.storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.143.133.36:35578 (size: 10.6 KB, free: 908.9 MB)\n17/02/16 09:02:45 INFO apache.spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:45 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[102] at flatMap at ALS.scala:1170)\n17/02/16 09:02:45 INFO cluster.ego.EGODeployScheduler: Adding task set 22.0 with 5 tasks\n17/02/16 09:02:45 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 22.0 (TID 79, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:45 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 22.0 (TID 80, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:45 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 22.0 (TID 81, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:45 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 22.0 (TID 82, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:45 INFO spark.storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 10.6 KB, free: 4.3 GB)\n17/02/16 09:02:45 INFO spark.storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 10.6 KB, free: 4.3 GB)\n17/02/16 09:02:45 INFO spark.storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 10.6 KB, free: 4.3 GB)\n17/02/16 09:02:45 INFO spark.storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 10.6 KB, free: 4.3 GB)\n17/02/16 09:02:45 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:45 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 37 is 296 bytes\n17/02/16 09:02:45 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:45 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:45 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 37 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:46 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 22.0 (TID 80) in 369 ms on yp-spark-dal09-env5-0047 (1/5)\n17/02/16 09:02:46 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 22.0 (TID 79) in 375 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:02:46 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 22.0 (TID 82) in 376 ms on yp-spark-dal09-env5-0031 (3/5)\n17/02/16 09:02:46 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 22.0 (TID 83, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:46 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 22.0 (TID 81) in 388 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:02:46 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 22.0 (TID 83) in 342 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:02:46 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 22.0, whose tasks have all completed, from pool \n17/02/16 09:02:46 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 22 (flatMap at ALS.scala:1170) finished in 0.731 s\n17/02/16 09:02:46 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:46 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:46 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 30, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 54, ShuffleMapStage 25, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 26, ShuffleMapStage 48, ShuffleMapStage 27, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 23, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)\n17/02/16 09:02:46 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:46 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(22)\n17/02/16 09:02:46 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[111] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:46 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(23)\n17/02/16 09:02:46 INFO spark.storage.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 26.5 KB, free 310.6 KB)\n17/02/16 09:02:46 INFO spark.storage.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 10.8 KB, free 321.4 KB)\n17/02/16 09:02:46 INFO spark.storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.143.133.36:35578 (size: 10.8 KB, free: 908.9 MB)\n17/02/16 09:02:46 INFO apache.spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:46 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[111] at flatMap at ALS.scala:1170)\n17/02/16 09:02:46 INFO cluster.ego.EGODeployScheduler: Adding task set 23.0 with 5 tasks\n17/02/16 09:02:46 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 23.0 (TID 84, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:46 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 23.0 (TID 85, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:46 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 23.0 (TID 86, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:46 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 23.0 (TID 87, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:46 INFO spark.storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 10.8 KB, free: 4.3 GB)\n17/02/16 09:02:46 INFO spark.storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 10.8 KB, free: 4.3 GB)\n17/02/16 09:02:46 INFO spark.storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 10.8 KB, free: 4.3 GB)\n17/02/16 09:02:46 INFO spark.storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 10.8 KB, free: 4.3 GB)\n17/02/16 09:02:46 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:46 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 36 is 294 bytes\n17/02/16 09:02:46 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:46 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:46 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 36 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:46 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 23.0 (TID 85) in 392 ms on yp-spark-dal09-env5-0044 (1/5)\n17/02/16 09:02:46 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 23.0 (TID 88, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:46 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 23.0 (TID 84) in 394 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:02:46 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 23.0 (TID 87) in 394 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:02:46 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 23.0 (TID 86) in 395 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:02:47 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 23.0 (TID 88) in 386 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:02:47 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 23.0, whose tasks have all completed, from pool \n17/02/16 09:02:47 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 23 (flatMap at ALS.scala:1170) finished in 0.780 s\n17/02/16 09:02:47 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:47 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:47 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 30, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 54, ShuffleMapStage 25, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 26, ShuffleMapStage 48, ShuffleMapStage 27, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)\n17/02/16 09:02:47 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:47 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(23)\n17/02/16 09:02:47 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[120] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:47 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(24)\n17/02/16 09:02:47 INFO spark.storage.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 27.4 KB, free 348.8 KB)\n17/02/16 09:02:47 INFO spark.storage.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 11.0 KB, free 359.8 KB)\n17/02/16 09:02:47 INFO spark.storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.143.133.36:35578 (size: 11.0 KB, free: 908.9 MB)\n17/02/16 09:02:47 INFO apache.spark.SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:47 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[120] at flatMap at ALS.scala:1170)\n17/02/16 09:02:47 INFO cluster.ego.EGODeployScheduler: Adding task set 24.0 with 5 tasks\n17/02/16 09:02:47 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 24.0 (TID 89, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:47 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 24.0 (TID 90, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:47 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 24.0 (TID 91, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:47 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 24.0 (TID 92, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:47 INFO spark.storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 11.0 KB, free: 4.3 GB)\n17/02/16 09:02:47 INFO spark.storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 11.0 KB, free: 4.3 GB)\n17/02/16 09:02:47 INFO spark.storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 11.0 KB, free: 4.3 GB)\n17/02/16 09:02:47 INFO spark.storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 11.0 KB, free: 4.3 GB)\n17/02/16 09:02:47 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:47 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:47 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 35 is 296 bytes\n17/02/16 09:02:47 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 35 is 296 bytes\n17/02/16 09:02:47 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:47 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 35 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:47 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 24.0 (TID 90) in 364 ms on yp-spark-dal09-env5-0047 (1/5)\n17/02/16 09:02:47 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 24.0 (TID 92) in 371 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:02:47 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 24.0 (TID 91) in 374 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:02:47 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 24.0 (TID 93, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:47 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 24.0 (TID 89) in 388 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:02:47 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 24.0 (TID 93) in 333 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:02:47 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 24.0, whose tasks have all completed, from pool \n17/02/16 09:02:47 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 24 (flatMap at ALS.scala:1170) finished in 0.721 s\n17/02/16 09:02:47 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:47 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:47 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 30, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 54, ShuffleMapStage 25, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 26, ShuffleMapStage 48, ShuffleMapStage 27, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)\n17/02/16 09:02:47 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:47 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(24)\n17/02/16 09:02:47 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[129] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:47 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(25)\n17/02/16 09:02:47 INFO spark.storage.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 28.3 KB, free 388.1 KB)\n17/02/16 09:02:47 INFO spark.storage.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 11.1 KB, free 399.2 KB)\n17/02/16 09:02:47 INFO spark.storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.143.133.36:35578 (size: 11.1 KB, free: 908.9 MB)\n17/02/16 09:02:47 INFO apache.spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:47 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[129] at flatMap at ALS.scala:1170)\n17/02/16 09:02:47 INFO cluster.ego.EGODeployScheduler: Adding task set 25.0 with 5 tasks\n17/02/16 09:02:47 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 25.0 (TID 94, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:47 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 25.0 (TID 95, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:47 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 25.0 (TID 96, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:47 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 25.0 (TID 97, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:47 INFO spark.storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 11.1 KB, free: 4.3 GB)\n17/02/16 09:02:47 INFO spark.storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 11.1 KB, free: 4.3 GB)\n17/02/16 09:02:47 INFO spark.storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 11.1 KB, free: 4.3 GB)\n17/02/16 09:02:47 INFO spark.storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 11.1 KB, free: 4.3 GB)\n17/02/16 09:02:47 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:47 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 34 is 294 bytes\n17/02/16 09:02:47 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:47 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:47 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 34 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:48 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 25.0 (TID 96) in 382 ms on yp-spark-dal09-env5-0044 (1/5)\n17/02/16 09:02:48 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 25.0 (TID 95) in 389 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:02:48 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 25.0 (TID 97) in 390 ms on yp-spark-dal09-env5-0047 (3/5)\n17/02/16 09:02:48 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 25.0 (TID 98, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:48 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 25.0 (TID 94) in 395 ms on yp-spark-dal09-env5-0031 (4/5)\n17/02/16 09:02:48 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 25.0 (TID 98) in 386 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:02:48 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 25.0, whose tasks have all completed, from pool \n17/02/16 09:02:48 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 25 (flatMap at ALS.scala:1170) finished in 0.781 s\n17/02/16 09:02:48 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:48 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:48 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 30, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 26, ShuffleMapStage 48, ShuffleMapStage 27, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)\n17/02/16 09:02:48 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:48 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(25)\n17/02/16 09:02:48 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[138] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:48 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(26)\n17/02/16 09:02:48 INFO spark.storage.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 29.2 KB, free 428.4 KB)\n17/02/16 09:02:48 INFO spark.storage.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 11.4 KB, free 439.7 KB)\n17/02/16 09:02:48 INFO spark.storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on 10.143.133.36:35578 (size: 11.4 KB, free: 908.9 MB)\n17/02/16 09:02:48 INFO apache.spark.SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:48 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[138] at flatMap at ALS.scala:1170)\n17/02/16 09:02:48 INFO cluster.ego.EGODeployScheduler: Adding task set 26.0 with 5 tasks\n17/02/16 09:02:48 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 26.0 (TID 99, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:48 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 26.0 (TID 100, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:48 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 26.0 (TID 101, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:48 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 26.0 (TID 102, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:48 INFO spark.storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 11.4 KB, free: 4.3 GB)\n17/02/16 09:02:48 INFO spark.storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 11.4 KB, free: 4.3 GB)\n17/02/16 09:02:48 INFO spark.storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 11.4 KB, free: 4.3 GB)\n17/02/16 09:02:48 INFO spark.storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 11.4 KB, free: 4.3 GB)\n17/02/16 09:02:48 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:48 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 296 bytes\n17/02/16 09:02:48 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:48 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:48 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:49 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 26.0 (TID 100) in 365 ms on yp-spark-dal09-env5-0047 (1/5)\n17/02/16 09:02:49 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 26.0 (TID 101) in 371 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:02:49 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 26.0 (TID 99) in 374 ms on yp-spark-dal09-env5-0031 (3/5)\n17/02/16 09:02:49 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 26.0 (TID 103, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:49 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 26.0 (TID 102) in 375 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:02:49 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 26.0 (TID 103) in 332 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:02:49 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 26.0, whose tasks have all completed, from pool \n17/02/16 09:02:49 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 26 (flatMap at ALS.scala:1170) finished in 0.708 s\n17/02/16 09:02:49 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:49 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:49 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 30, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 27, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)\n17/02/16 09:02:49 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:49 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(26)\n17/02/16 09:02:49 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[147] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:49 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(27)\n17/02/16 09:02:49 INFO spark.storage.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 30.0 KB, free 469.8 KB)\n17/02/16 09:02:49 INFO spark.storage.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 11.5 KB, free 481.3 KB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on 10.143.133.36:35578 (size: 11.5 KB, free: 908.9 MB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_22_piece0 on 10.143.133.36:35578 in memory (size: 11.4 KB, free: 908.9 MB)\n17/02/16 09:02:49 INFO apache.spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_22_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 11.4 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[147] at flatMap at ALS.scala:1170)\n17/02/16 09:02:49 INFO cluster.ego.EGODeployScheduler: Adding task set 27.0 with 5 tasks\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_22_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 11.4 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_22_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 11.4 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_22_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 11.4 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 27.0 (TID 104, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:49 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 27.0 (TID 105, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:49 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 27.0 (TID 106, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:49 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 27.0 (TID 107, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_21_piece0 on 10.143.133.36:35578 in memory (size: 11.1 KB, free: 908.9 MB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_21_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 11.1 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_21_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 11.1 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_21_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 11.1 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_21_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 11.1 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_20_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 11.0 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_20_piece0 on 10.143.133.36:35578 in memory (size: 11.0 KB, free: 908.9 MB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_20_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 11.0 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_20_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 11.0 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 11.5 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 11.5 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_20_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 11.0 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 11.5 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 11.5 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_19_piece0 on 10.143.133.36:35578 in memory (size: 10.8 KB, free: 908.9 MB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_19_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 10.8 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_19_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 10.8 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_19_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 10.8 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_19_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 10.8 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:49 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:49 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:49 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 294 bytes\n17/02/16 09:02:49 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 294 bytes\n17/02/16 09:02:49 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 294 bytes\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_18_piece0 on 10.143.133.36:35578 in memory (size: 10.6 KB, free: 908.9 MB)\n17/02/16 09:02:49 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_18_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 10.6 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_18_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 10.6 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_18_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 10.6 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_18_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 10.6 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_17_piece0 on 10.143.133.36:35578 in memory (size: 10.4 KB, free: 908.9 MB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_17_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 10.4 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_17_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 10.4 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_17_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 10.4 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_17_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 10.4 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_16_piece0 on 10.143.133.36:35578 in memory (size: 10.3 KB, free: 908.9 MB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_16_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 10.3 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_16_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 10.3 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_16_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 10.3 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_16_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 10.3 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.143.133.36:35578 in memory (size: 10.1 KB, free: 908.9 MB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_15_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 10.1 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_15_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 10.1 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_15_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 10.1 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_15_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 10.1 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_14_piece0 on 10.143.133.36:35578 in memory (size: 9.9 KB, free: 909.0 MB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_14_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 9.9 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_14_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 9.9 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_14_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 9.9 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_14_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 9.9 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_13_piece0 on 10.143.133.36:35578 in memory (size: 9.7 KB, free: 909.0 MB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_13_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 9.7 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_13_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 9.7 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_13_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 9.7 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_13_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 9.7 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_12_piece0 on 10.143.133.36:35578 in memory (size: 9.5 KB, free: 909.0 MB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_12_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 9.5 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_12_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 9.5 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_12_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 9.5 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_12_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 9.5 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_11_piece0 on 10.143.133.36:35578 in memory (size: 8.8 KB, free: 909.0 MB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_11_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 8.8 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_11_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 8.8 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_11_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 8.8 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_11_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 8.8 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_10_piece0 on 10.143.133.36:35578 in memory (size: 8.5 KB, free: 909.0 MB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_10_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_10_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_10_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.storage.BlockManagerInfo: Removed broadcast_10_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 8.5 KB, free: 4.3 GB)\n17/02/16 09:02:49 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 27.0 (TID 108, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:49 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 27.0 (TID 105) in 384 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:02:49 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 27.0 (TID 106) in 387 ms on yp-spark-dal09-env5-0044 (2/5)\n17/02/16 09:02:49 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 27.0 (TID 107) in 390 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:02:49 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 27.0 (TID 104) in 393 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:02:50 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 27.0 (TID 108) in 376 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:02:50 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 27.0, whose tasks have all completed, from pool \n17/02/16 09:02:50 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 27 (flatMap at ALS.scala:1170) finished in 0.761 s\n17/02/16 09:02:50 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:50 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:50 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 30, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)\n17/02/16 09:02:50 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:50 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(27)\n17/02/16 09:02:50 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[156] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:50 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(28)\n17/02/16 09:02:50 INFO spark.storage.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 30.9 KB, free 72.4 KB)\n17/02/16 09:02:50 INFO spark.storage.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 11.7 KB, free 84.1 KB)\n17/02/16 09:02:50 INFO spark.storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on 10.143.133.36:35578 (size: 11.7 KB, free: 909.0 MB)\n17/02/16 09:02:50 INFO apache.spark.SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:50 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[156] at flatMap at ALS.scala:1170)\n17/02/16 09:02:50 INFO cluster.ego.EGODeployScheduler: Adding task set 28.0 with 5 tasks\n17/02/16 09:02:50 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 28.0 (TID 109, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:50 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 28.0 (TID 110, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:50 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 28.0 (TID 111, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:50 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 28.0 (TID 112, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:50 INFO spark.storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 11.7 KB, free: 4.3 GB)\n17/02/16 09:02:50 INFO spark.storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 11.7 KB, free: 4.3 GB)\n17/02/16 09:02:50 INFO spark.storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 11.7 KB, free: 4.3 GB)\n17/02/16 09:02:50 INFO spark.storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 11.7 KB, free: 4.3 GB)\n17/02/16 09:02:50 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:50 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:50 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 31 is 296 bytes\n17/02/16 09:02:50 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:50 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 31 is 296 bytes\n17/02/16 09:02:50 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:50 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 28.0 (TID 112) in 364 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:02:50 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 28.0 (TID 110) in 365 ms on yp-spark-dal09-env5-0047 (2/5)\n17/02/16 09:02:50 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 28.0 (TID 111) in 373 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:02:50 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 28.0 (TID 113, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:50 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 28.0 (TID 109) in 377 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:02:50 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 28.0 (TID 113) in 332 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:02:50 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 28.0, whose tasks have all completed, from pool \n17/02/16 09:02:50 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 28 (flatMap at ALS.scala:1170) finished in 0.709 s\n17/02/16 09:02:50 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:50 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:50 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 30, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 29)\n17/02/16 09:02:50 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:50 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(28)\n17/02/16 09:02:50 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[165] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:50 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(29)\n17/02/16 09:02:50 INFO spark.storage.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 31.8 KB, free 115.9 KB)\n17/02/16 09:02:50 INFO spark.storage.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 11.8 KB, free 127.8 KB)\n17/02/16 09:02:50 INFO spark.storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on 10.143.133.36:35578 (size: 11.8 KB, free: 909.0 MB)\n17/02/16 09:02:50 INFO apache.spark.SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:50 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[165] at flatMap at ALS.scala:1170)\n17/02/16 09:02:50 INFO cluster.ego.EGODeployScheduler: Adding task set 29.0 with 5 tasks\n17/02/16 09:02:50 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 29.0 (TID 114, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:50 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 29.0 (TID 115, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:50 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 29.0 (TID 116, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:50 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 29.0 (TID 117, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:50 INFO spark.storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 11.8 KB, free: 4.3 GB)\n17/02/16 09:02:50 INFO spark.storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 11.8 KB, free: 4.3 GB)\n17/02/16 09:02:50 INFO spark.storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 11.8 KB, free: 4.3 GB)\n17/02/16 09:02:50 INFO spark.storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 11.8 KB, free: 4.3 GB)\n17/02/16 09:02:50 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:50 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:50 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 30 is 294 bytes\n17/02/16 09:02:50 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 30 is 294 bytes\n17/02/16 09:02:50 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:50 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:51 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 29.0 (TID 115) in 378 ms on yp-spark-dal09-env5-0034 (1/5)\n17/02/16 09:02:51 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 29.0 (TID 114) in 381 ms on yp-spark-dal09-env5-0044 (2/5)\n17/02/16 09:02:51 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 29.0 (TID 118, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:51 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 29.0 (TID 116) in 384 ms on yp-spark-dal09-env5-0031 (3/5)\n17/02/16 09:02:51 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 29.0 (TID 117) in 392 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:02:51 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 29.0 (TID 118) in 376 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:02:51 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 29.0, whose tasks have all completed, from pool \n17/02/16 09:02:51 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 29 (flatMap at ALS.scala:1170) finished in 0.761 s\n17/02/16 09:02:51 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:51 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:51 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 30, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36)\n17/02/16 09:02:51 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:51 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(29)\n17/02/16 09:02:51 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[174] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:51 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(30)\n17/02/16 09:02:51 INFO spark.storage.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 32.7 KB, free 160.4 KB)\n17/02/16 09:02:51 INFO spark.storage.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 12.2 KB, free 172.6 KB)\n17/02/16 09:02:51 INFO spark.storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on 10.143.133.36:35578 (size: 12.2 KB, free: 909.0 MB)\n17/02/16 09:02:51 INFO apache.spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:51 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[174] at flatMap at ALS.scala:1170)\n17/02/16 09:02:51 INFO cluster.ego.EGODeployScheduler: Adding task set 30.0 with 5 tasks\n17/02/16 09:02:51 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 30.0 (TID 119, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:51 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 30.0 (TID 120, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:51 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 30.0 (TID 121, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:51 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 30.0 (TID 122, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:51 INFO spark.storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 12.2 KB, free: 4.3 GB)\n17/02/16 09:02:51 INFO spark.storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 12.2 KB, free: 4.3 GB)\n17/02/16 09:02:51 INFO spark.storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 12.2 KB, free: 4.3 GB)\n17/02/16 09:02:51 INFO spark.storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 12.2 KB, free: 4.3 GB)\n17/02/16 09:02:51 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:51 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 29 is 296 bytes\n17/02/16 09:02:51 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:51 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:51 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:52 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 30.0 (TID 122) in 361 ms on yp-spark-dal09-env5-0034 (1/5)\n17/02/16 09:02:52 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 30.0 (TID 121) in 367 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:02:52 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 30.0 (TID 123, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:52 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 30.0 (TID 120) in 380 ms on yp-spark-dal09-env5-0044 (3/5)\n17/02/16 09:02:52 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 30.0 (TID 119) in 382 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:02:52 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 30.0 (TID 123) in 337 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:02:52 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 30.0, whose tasks have all completed, from pool \n17/02/16 09:02:52 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 30 (flatMap at ALS.scala:1170) finished in 0.717 s\n17/02/16 09:02:52 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:52 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:52 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 31, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36)\n17/02/16 09:02:52 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:52 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(30)\n17/02/16 09:02:52 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[183] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:52 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(31)\n17/02/16 09:02:52 INFO spark.storage.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 33.5 KB, free 206.2 KB)\n17/02/16 09:02:52 INFO spark.storage.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 12.4 KB, free 218.6 KB)\n17/02/16 09:02:52 INFO spark.storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on 10.143.133.36:35578 (size: 12.4 KB, free: 908.9 MB)\n17/02/16 09:02:52 INFO apache.spark.SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:52 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[183] at flatMap at ALS.scala:1170)\n17/02/16 09:02:52 INFO cluster.ego.EGODeployScheduler: Adding task set 31.0 with 5 tasks\n17/02/16 09:02:52 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 31.0 (TID 124, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:52 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 31.0 (TID 125, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:52 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 31.0 (TID 126, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:52 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 31.0 (TID 127, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:52 INFO spark.storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 12.4 KB, free: 4.3 GB)\n17/02/16 09:02:52 INFO spark.storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 12.4 KB, free: 4.3 GB)\n17/02/16 09:02:52 INFO spark.storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 12.4 KB, free: 4.3 GB)\n17/02/16 09:02:52 INFO spark.storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 12.4 KB, free: 4.3 GB)\n17/02/16 09:02:52 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:52 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 28 is 294 bytes\n17/02/16 09:02:52 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:52 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:52 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:52 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 31.0 (TID 126) in 374 ms on yp-spark-dal09-env5-0034 (1/5)\n17/02/16 09:02:52 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 31.0 (TID 128, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:52 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 31.0 (TID 124) in 384 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:02:52 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 31.0 (TID 127) in 386 ms on yp-spark-dal09-env5-0044 (3/5)\n17/02/16 09:02:52 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 31.0 (TID 125) in 390 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:02:53 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 31.0 (TID 128) in 379 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:02:53 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 31.0, whose tasks have all completed, from pool \n17/02/16 09:02:53 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 31 (flatMap at ALS.scala:1170) finished in 0.764 s\n17/02/16 09:02:53 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:53 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:53 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 32, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36)\n17/02/16 09:02:53 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:53 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(31)\n17/02/16 09:02:53 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[192] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:53 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(32)\n17/02/16 09:02:53 INFO spark.storage.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 34.4 KB, free 253.0 KB)\n17/02/16 09:02:53 INFO spark.storage.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 12.5 KB, free 265.5 KB)\n17/02/16 09:02:53 INFO spark.storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on 10.143.133.36:35578 (size: 12.5 KB, free: 908.9 MB)\n17/02/16 09:02:53 INFO apache.spark.SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:53 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[192] at flatMap at ALS.scala:1170)\n17/02/16 09:02:53 INFO cluster.ego.EGODeployScheduler: Adding task set 32.0 with 5 tasks\n17/02/16 09:02:53 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 32.0 (TID 129, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:53 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 32.0 (TID 130, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:53 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 32.0 (TID 131, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:53 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 32.0 (TID 132, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:53 INFO spark.storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 12.5 KB, free: 4.3 GB)\n17/02/16 09:02:53 INFO spark.storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 12.5 KB, free: 4.3 GB)\n17/02/16 09:02:53 INFO spark.storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 12.5 KB, free: 4.3 GB)\n17/02/16 09:02:53 INFO spark.storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 12.5 KB, free: 4.3 GB)\n17/02/16 09:02:53 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:53 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 27 is 296 bytes\n17/02/16 09:02:53 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:53 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:53 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:53 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 32.0 (TID 129) in 357 ms on yp-spark-dal09-env5-0047 (1/5)\n17/02/16 09:02:53 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 32.0 (TID 131) in 362 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:02:53 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 32.0 (TID 132) in 364 ms on yp-spark-dal09-env5-0031 (3/5)\n17/02/16 09:02:53 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 32.0 (TID 133, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:53 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 32.0 (TID 130) in 380 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:02:53 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 32.0 (TID 133) in 340 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:02:53 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 32.0, whose tasks have all completed, from pool \n17/02/16 09:02:53 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 32 (flatMap at ALS.scala:1170) finished in 0.721 s\n17/02/16 09:02:53 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:53 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:53 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36)\n17/02/16 09:02:53 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:53 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(32)\n17/02/16 09:02:53 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[201] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:53 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(33)\n17/02/16 09:02:53 INFO spark.storage.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 35.3 KB, free 300.8 KB)\n17/02/16 09:02:53 INFO spark.storage.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 12.8 KB, free 313.6 KB)\n17/02/16 09:02:53 INFO spark.storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on 10.143.133.36:35578 (size: 12.8 KB, free: 908.9 MB)\n17/02/16 09:02:53 INFO apache.spark.SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:53 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[201] at flatMap at ALS.scala:1170)\n17/02/16 09:02:53 INFO cluster.ego.EGODeployScheduler: Adding task set 33.0 with 5 tasks\n17/02/16 09:02:53 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 33.0 (TID 134, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:53 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 33.0 (TID 135, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:53 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 33.0 (TID 136, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:53 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 33.0 (TID 137, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:53 INFO spark.storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 12.8 KB, free: 4.3 GB)\n17/02/16 09:02:53 INFO spark.storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 12.8 KB, free: 4.3 GB)\n17/02/16 09:02:53 INFO spark.storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 12.8 KB, free: 4.3 GB)\n17/02/16 09:02:53 INFO spark.storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 12.8 KB, free: 4.3 GB)\n17/02/16 09:02:53 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:53 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 26 is 294 bytes\n17/02/16 09:02:53 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:53 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:53 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:54 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 33.0 (TID 135) in 382 ms on yp-spark-dal09-env5-0047 (1/5)\n17/02/16 09:02:54 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 33.0 (TID 137) in 383 ms on yp-spark-dal09-env5-0044 (2/5)\n17/02/16 09:02:54 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 33.0 (TID 138, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:54 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 33.0 (TID 134) in 387 ms on yp-spark-dal09-env5-0031 (3/5)\n17/02/16 09:02:54 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 33.0 (TID 136) in 401 ms on yp-spark-dal09-env5-0034 (4/5)\n17/02/16 09:02:54 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 33.0 (TID 138) in 378 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:02:54 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 33.0, whose tasks have all completed, from pool \n17/02/16 09:02:54 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 33 (flatMap at ALS.scala:1170) finished in 0.765 s\n17/02/16 09:02:54 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:54 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:54 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36)\n17/02/16 09:02:54 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(33)\n17/02/16 09:02:54 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 34 (MapPartitionsRDD[210] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(34)\n17/02/16 09:02:54 INFO spark.storage.MemoryStore: Block broadcast_30 stored as values in memory (estimated size 36.2 KB, free 349.8 KB)\n17/02/16 09:02:54 INFO spark.storage.MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 12.9 KB, free 362.7 KB)\n17/02/16 09:02:54 INFO spark.storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on 10.143.133.36:35578 (size: 12.9 KB, free: 908.9 MB)\n17/02/16 09:02:54 INFO apache.spark.SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:54 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 34 (MapPartitionsRDD[210] at flatMap at ALS.scala:1170)\n17/02/16 09:02:54 INFO cluster.ego.EGODeployScheduler: Adding task set 34.0 with 5 tasks\n17/02/16 09:02:54 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 34.0 (TID 139, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:54 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 34.0 (TID 140, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:54 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 34.0 (TID 141, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:54 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 34.0 (TID 142, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:54 INFO spark.storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 12.9 KB, free: 4.3 GB)\n17/02/16 09:02:54 INFO spark.storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 12.9 KB, free: 4.3 GB)\n17/02/16 09:02:54 INFO spark.storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 12.9 KB, free: 4.3 GB)\n17/02/16 09:02:54 INFO spark.storage.BlockManagerInfo: Added broadcast_30_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 12.9 KB, free: 4.3 GB)\n17/02/16 09:02:54 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:54 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 25 is 296 bytes\n17/02/16 09:02:54 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:54 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:54 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:55 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 34.0 (TID 139) in 361 ms on yp-spark-dal09-env5-0034 (1/5)\n17/02/16 09:02:55 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 34.0 (TID 142) in 360 ms on yp-spark-dal09-env5-0047 (2/5)\n17/02/16 09:02:55 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 34.0 (TID 141) in 361 ms on yp-spark-dal09-env5-0031 (3/5)\n17/02/16 09:02:55 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 34.0 (TID 143, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:55 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 34.0 (TID 140) in 376 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:02:55 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 34.0 (TID 143) in 336 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:02:55 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 34.0, whose tasks have all completed, from pool \n17/02/16 09:02:55 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 34 (flatMap at ALS.scala:1170) finished in 0.713 s\n17/02/16 09:02:55 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:55 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:55 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 35, ShuffleMapStage 36)\n17/02/16 09:02:55 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:55 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(34)\n17/02/16 09:02:55 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 35 (MapPartitionsRDD[219] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:55 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(35)\n17/02/16 09:02:55 INFO spark.storage.MemoryStore: Block broadcast_31 stored as values in memory (estimated size 37.1 KB, free 399.7 KB)\n17/02/16 09:02:55 INFO spark.storage.MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 13.1 KB, free 412.8 KB)\n17/02/16 09:02:55 INFO spark.storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on 10.143.133.36:35578 (size: 13.1 KB, free: 908.9 MB)\n17/02/16 09:02:55 INFO apache.spark.SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:55 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 35 (MapPartitionsRDD[219] at flatMap at ALS.scala:1170)\n17/02/16 09:02:55 INFO cluster.ego.EGODeployScheduler: Adding task set 35.0 with 5 tasks\n17/02/16 09:02:55 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 35.0 (TID 144, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:55 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 35.0 (TID 145, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:55 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 35.0 (TID 146, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:55 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 35.0 (TID 147, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:55 INFO spark.storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 13.1 KB, free: 4.3 GB)\n17/02/16 09:02:55 INFO spark.storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 13.1 KB, free: 4.3 GB)\n17/02/16 09:02:55 INFO spark.storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 13.1 KB, free: 4.3 GB)\n17/02/16 09:02:55 INFO spark.storage.BlockManagerInfo: Added broadcast_31_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 13.1 KB, free: 4.3 GB)\n17/02/16 09:02:55 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:55 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 294 bytes\n17/02/16 09:02:55 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:55 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:55 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:55 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 35.0 (TID 145) in 382 ms on yp-spark-dal09-env5-0034 (1/5)\n17/02/16 09:02:55 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 35.0 (TID 144) in 385 ms on yp-spark-dal09-env5-0044 (2/5)\n17/02/16 09:02:55 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 35.0 (TID 146) in 386 ms on yp-spark-dal09-env5-0047 (3/5)\n17/02/16 09:02:55 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 35.0 (TID 148, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:55 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 35.0 (TID 147) in 452 ms on yp-spark-dal09-env5-0031 (4/5)\n17/02/16 09:02:56 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 35.0 (TID 148) in 441 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:02:56 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 35.0, whose tasks have all completed, from pool \n17/02/16 09:02:56 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 35 (flatMap at ALS.scala:1170) finished in 0.895 s\n17/02/16 09:02:56 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:56 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:56 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41, ShuffleMapStage 36)\n17/02/16 09:02:56 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:56 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(35)\n17/02/16 09:02:56 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 36 (MapPartitionsRDD[228] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:56 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(36)\n17/02/16 09:02:56 INFO spark.storage.MemoryStore: Block broadcast_32 stored as values in memory (estimated size 37.9 KB, free 450.8 KB)\n17/02/16 09:02:56 INFO spark.storage.MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 13.2 KB, free 464.0 KB)\n17/02/16 09:02:56 INFO spark.storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on 10.143.133.36:35578 (size: 13.2 KB, free: 908.9 MB)\n17/02/16 09:02:56 INFO apache.spark.SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:56 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 36 (MapPartitionsRDD[228] at flatMap at ALS.scala:1170)\n17/02/16 09:02:56 INFO cluster.ego.EGODeployScheduler: Adding task set 36.0 with 5 tasks\n17/02/16 09:02:56 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 36.0 (TID 149, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:56 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 36.0 (TID 150, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:56 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 36.0 (TID 151, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:56 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 36.0 (TID 152, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:56 INFO spark.storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 13.2 KB, free: 4.3 GB)\n17/02/16 09:02:56 INFO spark.storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 13.2 KB, free: 4.3 GB)\n17/02/16 09:02:56 INFO spark.storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 13.2 KB, free: 4.3 GB)\n17/02/16 09:02:56 INFO spark.storage.BlockManagerInfo: Added broadcast_32_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 13.2 KB, free: 4.3 GB)\n17/02/16 09:02:56 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:56 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 296 bytes\n17/02/16 09:02:56 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:56 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:56 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:56 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 36.0 (TID 150) in 358 ms on yp-spark-dal09-env5-0047 (1/5)\n17/02/16 09:02:56 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 36.0 (TID 151) in 358 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:02:56 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 36.0 (TID 149) in 369 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:02:56 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 36.0 (TID 153, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:56 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 36.0 (TID 152) in 407 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:02:57 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 36.0 (TID 153) in 338 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:02:57 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 36.0, whose tasks have all completed, from pool \n17/02/16 09:02:57 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 36 (flatMap at ALS.scala:1170) finished in 0.747 s\n17/02/16 09:02:57 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:57 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:57 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 37, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41)\n17/02/16 09:02:57 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:57 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(36)\n17/02/16 09:02:57 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[237] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:57 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(37)\n17/02/16 09:02:57 INFO spark.storage.MemoryStore: Block broadcast_33 stored as values in memory (estimated size 38.8 KB, free 502.8 KB)\n17/02/16 09:02:57 INFO spark.storage.MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 13.4 KB, free 516.2 KB)\n17/02/16 09:02:57 INFO spark.storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on 10.143.133.36:35578 (size: 13.4 KB, free: 908.9 MB)\n17/02/16 09:02:57 INFO apache.spark.SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:57 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[237] at flatMap at ALS.scala:1170)\n17/02/16 09:02:57 INFO cluster.ego.EGODeployScheduler: Adding task set 37.0 with 5 tasks\n17/02/16 09:02:57 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 37.0 (TID 154, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:57 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 37.0 (TID 155, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:57 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 37.0 (TID 156, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:57 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 37.0 (TID 157, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:57 INFO spark.storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 13.4 KB, free: 4.3 GB)\n17/02/16 09:02:57 INFO spark.storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 13.4 KB, free: 4.3 GB)\n17/02/16 09:02:57 INFO spark.storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 13.4 KB, free: 4.3 GB)\n17/02/16 09:02:57 INFO spark.storage.BlockManagerInfo: Added broadcast_33_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 13.4 KB, free: 4.3 GB)\n17/02/16 09:02:57 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:57 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:57 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 294 bytes\n17/02/16 09:02:57 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 294 bytes\n17/02/16 09:02:57 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:57 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:57 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 37.0 (TID 158, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:57 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 37.0 (TID 156) in 376 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:02:57 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 37.0 (TID 157) in 384 ms on yp-spark-dal09-env5-0047 (2/5)\n17/02/16 09:02:57 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 37.0 (TID 155) in 386 ms on yp-spark-dal09-env5-0044 (3/5)\n17/02/16 09:02:57 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 37.0 (TID 154) in 388 ms on yp-spark-dal09-env5-0034 (4/5)\n17/02/16 09:02:57 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 37.0 (TID 158) in 366 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:02:57 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 37.0, whose tasks have all completed, from pool \n17/02/16 09:02:57 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 37 (flatMap at ALS.scala:1170) finished in 0.743 s\n17/02/16 09:02:57 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:57 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:57 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 46, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41)\n17/02/16 09:02:57 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:57 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(37)\n17/02/16 09:02:57 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[246] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:57 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(38)\n17/02/16 09:02:57 INFO spark.storage.MemoryStore: Block broadcast_34 stored as values in memory (estimated size 39.7 KB, free 555.9 KB)\n17/02/16 09:02:57 INFO spark.storage.MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 13.6 KB, free 569.6 KB)\n17/02/16 09:02:57 INFO spark.storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on 10.143.133.36:35578 (size: 13.6 KB, free: 908.9 MB)\n17/02/16 09:02:57 INFO apache.spark.SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:57 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[246] at flatMap at ALS.scala:1170)\n17/02/16 09:02:57 INFO cluster.ego.EGODeployScheduler: Adding task set 38.0 with 5 tasks\n17/02/16 09:02:57 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 38.0 (TID 159, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:57 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 38.0 (TID 160, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:57 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 38.0 (TID 161, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:57 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 38.0 (TID 162, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:57 INFO spark.storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 13.6 KB, free: 4.3 GB)\n17/02/16 09:02:57 INFO spark.storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 13.6 KB, free: 4.3 GB)\n17/02/16 09:02:57 INFO spark.storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 13.6 KB, free: 4.3 GB)\n17/02/16 09:02:57 INFO spark.storage.BlockManagerInfo: Added broadcast_34_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 13.6 KB, free: 4.3 GB)\n17/02/16 09:02:57 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:57 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 21 is 296 bytes\n17/02/16 09:02:57 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:57 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:57 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:58 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 38.0 (TID 162) in 358 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:02:58 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 38.0 (TID 159) in 358 ms on yp-spark-dal09-env5-0047 (2/5)\n17/02/16 09:02:58 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 38.0 (TID 160) in 359 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:02:58 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 38.0 (TID 163, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:58 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 38.0 (TID 161) in 421 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:02:58 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 38.0 (TID 163) in 378 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:02:58 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 38.0, whose tasks have all completed, from pool \n17/02/16 09:02:58 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 38 (flatMap at ALS.scala:1170) finished in 0.800 s\n17/02/16 09:02:58 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:58 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:58 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 46, ShuffleMapStage 39, ShuffleMapStage 40, ShuffleMapStage 41)\n17/02/16 09:02:58 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:58 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(38)\n17/02/16 09:02:58 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 39 (MapPartitionsRDD[255] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:58 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(39)\n17/02/16 09:02:58 INFO spark.storage.MemoryStore: Block broadcast_35 stored as values in memory (estimated size 40.6 KB, free 610.1 KB)\n17/02/16 09:02:58 INFO spark.storage.MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 13.8 KB, free 624.0 KB)\n17/02/16 09:02:58 INFO spark.storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on 10.143.133.36:35578 (size: 13.8 KB, free: 908.8 MB)\n17/02/16 09:02:58 INFO apache.spark.SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:58 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 39 (MapPartitionsRDD[255] at flatMap at ALS.scala:1170)\n17/02/16 09:02:58 INFO cluster.ego.EGODeployScheduler: Adding task set 39.0 with 5 tasks\n17/02/16 09:02:58 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 39.0 (TID 164, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:58 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 39.0 (TID 165, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:58 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 39.0 (TID 166, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:58 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 39.0 (TID 167, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:58 INFO spark.storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 13.8 KB, free: 4.3 GB)\n17/02/16 09:02:58 INFO spark.storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 13.8 KB, free: 4.3 GB)\n17/02/16 09:02:58 INFO spark.storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 13.8 KB, free: 4.3 GB)\n17/02/16 09:02:58 INFO spark.storage.BlockManagerInfo: Added broadcast_35_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 13.8 KB, free: 4.3 GB)\n17/02/16 09:02:58 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:58 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 20 is 294 bytes\n17/02/16 09:02:58 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:58 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:58 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:59 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 39.0 (TID 168, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:59 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 39.0 (TID 167) in 376 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:02:59 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 39.0 (TID 164) in 379 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:02:59 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 39.0 (TID 166) in 384 ms on yp-spark-dal09-env5-0047 (3/5)\n17/02/16 09:02:59 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 39.0 (TID 165) in 447 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:02:59 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 39.0 (TID 168) in 368 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:02:59 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 39.0, whose tasks have all completed, from pool \n17/02/16 09:02:59 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 39 (flatMap at ALS.scala:1170) finished in 0.744 s\n17/02/16 09:02:59 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:02:59 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:02:59 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 46, ShuffleMapStage 40, ShuffleMapStage 41)\n17/02/16 09:02:59 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:02:59 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(39)\n17/02/16 09:02:59 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[264] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:02:59 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(40)\n17/02/16 09:02:59 INFO spark.storage.MemoryStore: Block broadcast_36 stored as values in memory (estimated size 41.4 KB, free 665.4 KB)\n17/02/16 09:02:59 INFO spark.storage.MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 14.0 KB, free 679.4 KB)\n17/02/16 09:02:59 INFO spark.storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on 10.143.133.36:35578 (size: 14.0 KB, free: 908.8 MB)\n17/02/16 09:02:59 INFO apache.spark.SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:02:59 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[264] at flatMap at ALS.scala:1170)\n17/02/16 09:02:59 INFO cluster.ego.EGODeployScheduler: Adding task set 40.0 with 5 tasks\n17/02/16 09:02:59 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 40.0 (TID 169, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:59 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 40.0 (TID 170, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:59 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 40.0 (TID 171, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:59 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 40.0 (TID 172, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:59 INFO spark.storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 14.0 KB, free: 4.3 GB)\n17/02/16 09:02:59 INFO spark.storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 14.0 KB, free: 4.3 GB)\n17/02/16 09:02:59 INFO spark.storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 14.0 KB, free: 4.3 GB)\n17/02/16 09:02:59 INFO spark.storage.BlockManagerInfo: Added broadcast_36_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 14.0 KB, free: 4.3 GB)\n17/02/16 09:02:59 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:02:59 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 19 is 296 bytes\n17/02/16 09:02:59 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:02:59 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:02:59 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:02:59 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 40.0 (TID 169) in 357 ms on yp-spark-dal09-env5-0047 (1/5)\n17/02/16 09:02:59 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 40.0 (TID 172) in 358 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:02:59 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 40.0 (TID 171) in 363 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:02:59 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 40.0 (TID 173, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:02:59 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 40.0 (TID 170) in 374 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:03:00 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 40.0 (TID 173) in 333 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:03:00 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 40.0, whose tasks have all completed, from pool \n17/02/16 09:03:00 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 40 (flatMap at ALS.scala:1170) finished in 0.707 s\n17/02/16 09:03:00 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:00 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:00 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 46, ShuffleMapStage 41)\n17/02/16 09:03:00 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:00 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(40)\n17/02/16 09:03:00 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 41 (MapPartitionsRDD[273] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:03:00 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(41)\n17/02/16 09:03:00 INFO spark.storage.MemoryStore: Block broadcast_37 stored as values in memory (estimated size 42.3 KB, free 721.7 KB)\n17/02/16 09:03:00 INFO spark.storage.MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 14.2 KB, free 735.9 KB)\n17/02/16 09:03:00 INFO spark.storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on 10.143.133.36:35578 (size: 14.2 KB, free: 908.8 MB)\n17/02/16 09:03:00 INFO apache.spark.SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:00 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 41 (MapPartitionsRDD[273] at flatMap at ALS.scala:1170)\n17/02/16 09:03:00 INFO cluster.ego.EGODeployScheduler: Adding task set 41.0 with 5 tasks\n17/02/16 09:03:00 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 41.0 (TID 174, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:00 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 41.0 (TID 175, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:00 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 41.0 (TID 176, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:00 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 41.0 (TID 177, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:00 INFO spark.storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 14.2 KB, free: 4.3 GB)\n17/02/16 09:03:00 INFO spark.storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 14.2 KB, free: 4.3 GB)\n17/02/16 09:03:00 INFO spark.storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 14.2 KB, free: 4.3 GB)\n17/02/16 09:03:00 INFO spark.storage.BlockManagerInfo: Added broadcast_37_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 14.2 KB, free: 4.3 GB)\n17/02/16 09:03:00 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:00 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 294 bytes\n17/02/16 09:03:00 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:00 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:00 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:00 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 41.0 (TID 178, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:00 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 41.0 (TID 177) in 375 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:03:00 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 41.0 (TID 175) in 381 ms on yp-spark-dal09-env5-0044 (2/5)\n17/02/16 09:03:00 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 41.0 (TID 176) in 383 ms on yp-spark-dal09-env5-0047 (3/5)\n17/02/16 09:03:00 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 41.0 (TID 174) in 466 ms on yp-spark-dal09-env5-0034 (4/5)\n17/02/16 09:03:00 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 41.0 (TID 178) in 368 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:03:00 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 41.0, whose tasks have all completed, from pool \n17/02/16 09:03:00 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 41 (flatMap at ALS.scala:1170) finished in 0.745 s\n17/02/16 09:03:00 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:00 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:00 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 42, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 46)\n17/02/16 09:03:00 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:00 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(41)\n17/02/16 09:03:00 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 42 (MapPartitionsRDD[282] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:03:00 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(42)\n17/02/16 09:03:00 INFO spark.storage.MemoryStore: Block broadcast_38 stored as values in memory (estimated size 43.2 KB, free 779.1 KB)\n17/02/16 09:03:00 INFO spark.storage.MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 14.3 KB, free 793.4 KB)\n17/02/16 09:03:00 INFO spark.storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on 10.143.133.36:35578 (size: 14.3 KB, free: 908.8 MB)\n17/02/16 09:03:00 INFO apache.spark.SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:00 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 42 (MapPartitionsRDD[282] at flatMap at ALS.scala:1170)\n17/02/16 09:03:00 INFO cluster.ego.EGODeployScheduler: Adding task set 42.0 with 5 tasks\n17/02/16 09:03:00 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 42.0 (TID 179, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:00 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 42.0 (TID 180, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:00 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 42.0 (TID 181, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:00 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 42.0 (TID 182, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:00 INFO spark.storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 14.3 KB, free: 4.3 GB)\n17/02/16 09:03:00 INFO spark.storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 14.3 KB, free: 4.3 GB)\n17/02/16 09:03:00 INFO spark.storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 14.3 KB, free: 4.3 GB)\n17/02/16 09:03:00 INFO spark.storage.BlockManagerInfo: Added broadcast_38_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 14.3 KB, free: 4.3 GB)\n17/02/16 09:03:00 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:00 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 296 bytes\n17/02/16 09:03:00 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:00 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:00 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:01 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 42.0 (TID 179) in 358 ms on yp-spark-dal09-env5-0047 (1/5)\n17/02/16 09:03:01 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 42.0 (TID 180) in 359 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:03:01 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 42.0 (TID 183, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:01 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 42.0 (TID 182) in 384 ms on yp-spark-dal09-env5-0044 (3/5)\n17/02/16 09:03:01 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 42.0 (TID 181) in 407 ms on yp-spark-dal09-env5-0034 (4/5)\n17/02/16 09:03:01 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 42.0 (TID 183) in 330 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:03:01 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 42.0, whose tasks have all completed, from pool \n17/02/16 09:03:01 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 42 (flatMap at ALS.scala:1170) finished in 0.715 s\n17/02/16 09:03:01 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:01 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:01 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 43, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 46)\n17/02/16 09:03:01 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:01 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(42)\n17/02/16 09:03:01 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[291] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:03:01 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(43)\n17/02/16 09:03:01 INFO spark.storage.MemoryStore: Block broadcast_39 stored as values in memory (estimated size 44.1 KB, free 837.5 KB)\n17/02/16 09:03:01 INFO spark.storage.MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 14.5 KB, free 852.0 KB)\n17/02/16 09:03:01 INFO spark.storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on 10.143.133.36:35578 (size: 14.5 KB, free: 908.8 MB)\n17/02/16 09:03:01 INFO apache.spark.SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:01 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[291] at flatMap at ALS.scala:1170)\n17/02/16 09:03:01 INFO cluster.ego.EGODeployScheduler: Adding task set 43.0 with 5 tasks\n17/02/16 09:03:01 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 43.0 (TID 184, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:01 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 43.0 (TID 185, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:01 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 43.0 (TID 186, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:01 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 43.0 (TID 187, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:01 INFO spark.storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 14.5 KB, free: 4.3 GB)\n17/02/16 09:03:01 INFO spark.storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 14.5 KB, free: 4.3 GB)\n17/02/16 09:03:01 INFO spark.storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 14.5 KB, free: 4.3 GB)\n17/02/16 09:03:01 INFO spark.storage.BlockManagerInfo: Added broadcast_39_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 14.5 KB, free: 4.3 GB)\n17/02/16 09:03:01 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:01 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:01 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 294 bytes\n17/02/16 09:03:01 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 294 bytes\n17/02/16 09:03:01 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:01 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:02 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 43.0 (TID 188, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:02 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 43.0 (TID 186) in 374 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:03:02 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 43.0 (TID 185) in 376 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:03:02 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 43.0 (TID 184) in 378 ms on yp-spark-dal09-env5-0044 (3/5)\n17/02/16 09:03:02 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 43.0 (TID 187) in 382 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:03:02 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 43.0 (TID 188) in 365 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:03:02 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 43.0, whose tasks have all completed, from pool \n17/02/16 09:03:02 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 43 (flatMap at ALS.scala:1170) finished in 0.740 s\n17/02/16 09:03:02 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:02 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:02 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 44, ShuffleMapStage 45, ShuffleMapStage 46)\n17/02/16 09:03:02 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:02 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(43)\n17/02/16 09:03:02 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[300] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:03:02 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(44)\n17/02/16 09:03:02 INFO spark.storage.MemoryStore: Block broadcast_40 stored as values in memory (estimated size 45.0 KB, free 896.9 KB)\n17/02/16 09:03:02 INFO spark.storage.MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 14.7 KB, free 911.6 KB)\n17/02/16 09:03:02 INFO spark.storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on 10.143.133.36:35578 (size: 14.7 KB, free: 908.8 MB)\n17/02/16 09:03:02 INFO apache.spark.SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:02 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[300] at flatMap at ALS.scala:1170)\n17/02/16 09:03:02 INFO cluster.ego.EGODeployScheduler: Adding task set 44.0 with 5 tasks\n17/02/16 09:03:02 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 44.0 (TID 189, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:02 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 44.0 (TID 190, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:02 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 44.0 (TID 191, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:02 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 44.0 (TID 192, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:02 INFO spark.storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 14.7 KB, free: 4.3 GB)\n17/02/16 09:03:02 INFO spark.storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 14.7 KB, free: 4.3 GB)\n17/02/16 09:03:02 INFO spark.storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 14.7 KB, free: 4.3 GB)\n17/02/16 09:03:02 INFO spark.storage.BlockManagerInfo: Added broadcast_40_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 14.7 KB, free: 4.3 GB)\n17/02/16 09:03:02 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:02 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 296 bytes\n17/02/16 09:03:02 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:02 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:02 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:02 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 44.0 (TID 191) in 356 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:03:02 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 44.0 (TID 192) in 360 ms on yp-spark-dal09-env5-0047 (2/5)\n17/02/16 09:03:02 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 44.0 (TID 189) in 361 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:03:02 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 44.0 (TID 193, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:02 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 44.0 (TID 190) in 374 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:03:03 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 44.0 (TID 193) in 332 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:03:03 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 44.0, whose tasks have all completed, from pool \n17/02/16 09:03:03 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 44 (flatMap at ALS.scala:1170) finished in 0.706 s\n17/02/16 09:03:03 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:03 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:03 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 45, ShuffleMapStage 46)\n17/02/16 09:03:03 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(44)\n17/02/16 09:03:03 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:03 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 45 (MapPartitionsRDD[309] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:03:03 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(45)\n17/02/16 09:03:03 INFO spark.storage.MemoryStore: Block broadcast_41 stored as values in memory (estimated size 45.8 KB, free 957.5 KB)\n17/02/16 09:03:03 INFO spark.storage.MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 14.8 KB, free 972.3 KB)\n17/02/16 09:03:03 INFO spark.storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on 10.143.133.36:35578 (size: 14.8 KB, free: 908.8 MB)\n17/02/16 09:03:03 INFO apache.spark.SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:03 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 45 (MapPartitionsRDD[309] at flatMap at ALS.scala:1170)\n17/02/16 09:03:03 INFO cluster.ego.EGODeployScheduler: Adding task set 45.0 with 5 tasks\n17/02/16 09:03:03 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 45.0 (TID 194, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:03 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 45.0 (TID 195, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:03 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 45.0 (TID 196, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:03 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 45.0 (TID 197, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:03 INFO spark.storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 14.8 KB, free: 4.3 GB)\n17/02/16 09:03:03 INFO spark.storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 14.8 KB, free: 4.3 GB)\n17/02/16 09:03:03 INFO spark.storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 14.8 KB, free: 4.3 GB)\n17/02/16 09:03:03 INFO spark.storage.BlockManagerInfo: Added broadcast_41_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 14.8 KB, free: 4.3 GB)\n17/02/16 09:03:03 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:03 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 294 bytes\n17/02/16 09:03:03 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:03 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:03 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:03 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 45.0 (TID 198, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:03 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 45.0 (TID 196) in 374 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:03:03 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 45.0 (TID 194) in 377 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:03:03 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 45.0 (TID 197) in 377 ms on yp-spark-dal09-env5-0044 (3/5)\n17/02/16 09:03:03 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 45.0 (TID 195) in 382 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:03:03 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 45.0 (TID 198) in 368 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:03:03 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 45.0, whose tasks have all completed, from pool \n17/02/16 09:03:03 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 45 (flatMap at ALS.scala:1170) finished in 0.742 s\n17/02/16 09:03:03 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:03 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:03 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50, ShuffleMapStage 46)\n17/02/16 09:03:03 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:03 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(45)\n17/02/16 09:03:03 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[318] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:03:03 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(46)\n17/02/16 09:03:03 INFO spark.storage.MemoryStore: Block broadcast_42 stored as values in memory (estimated size 46.7 KB, free 1019.0 KB)\n17/02/16 09:03:03 INFO spark.storage.MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 15.0 KB, free 1034.0 KB)\n17/02/16 09:03:03 INFO spark.storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on 10.143.133.36:35578 (size: 15.0 KB, free: 908.7 MB)\n17/02/16 09:03:03 INFO apache.spark.SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:03 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[318] at flatMap at ALS.scala:1170)\n17/02/16 09:03:03 INFO cluster.ego.EGODeployScheduler: Adding task set 46.0 with 5 tasks\n17/02/16 09:03:03 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 46.0 (TID 199, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:03 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 46.0 (TID 200, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:03 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 46.0 (TID 201, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:03 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 46.0 (TID 202, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:03 INFO spark.storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 15.0 KB, free: 4.3 GB)\n17/02/16 09:03:03 INFO spark.storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 15.0 KB, free: 4.3 GB)\n17/02/16 09:03:03 INFO spark.storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 15.0 KB, free: 4.3 GB)\n17/02/16 09:03:03 INFO spark.storage.BlockManagerInfo: Added broadcast_42_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 15.0 KB, free: 4.3 GB)\n17/02/16 09:03:03 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:03 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:03 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:03 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 296 bytes\n17/02/16 09:03:03 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 296 bytes\n17/02/16 09:03:03 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 296 bytes\n17/02/16 09:03:03 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:04 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 46.0 (TID 202) in 358 ms on yp-spark-dal09-env5-0047 (1/5)\n17/02/16 09:03:04 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 46.0 (TID 199) in 358 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:03:04 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 46.0 (TID 201) in 361 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:03:04 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 46.0 (TID 203, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:04 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 46.0 (TID 200) in 377 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:03:04 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 46.0 (TID 203) in 331 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:03:04 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 46.0, whose tasks have all completed, from pool \n17/02/16 09:03:04 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 46 (flatMap at ALS.scala:1170) finished in 0.708 s\n17/02/16 09:03:04 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:04 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:04 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 47, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50)\n17/02/16 09:03:04 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:04 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(46)\n17/02/16 09:03:04 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 47 (MapPartitionsRDD[327] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:03:04 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(47)\n17/02/16 09:03:04 INFO spark.storage.MemoryStore: Block broadcast_43 stored as values in memory (estimated size 47.6 KB, free 1081.5 KB)\n17/02/16 09:03:04 INFO spark.storage.MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 15.1 KB, free 1096.7 KB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on 10.143.133.36:35578 (size: 15.1 KB, free: 908.7 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_41_piece0 on 10.143.133.36:35578 in memory (size: 14.8 KB, free: 908.7 MB)\n17/02/16 09:03:04 INFO apache.spark.SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:04 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 47 (MapPartitionsRDD[327] at flatMap at ALS.scala:1170)\n17/02/16 09:03:04 INFO cluster.ego.EGODeployScheduler: Adding task set 47.0 with 5 tasks\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_41_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 14.8 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_41_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 14.8 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_41_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 14.8 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_41_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 14.8 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 47.0 (TID 204, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:04 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 47.0 (TID 205, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:04 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 47.0 (TID 206, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:04 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 47.0 (TID 207, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_40_piece0 on 10.143.133.36:35578 in memory (size: 14.7 KB, free: 908.8 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_40_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 14.7 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_40_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 14.7 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_40_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 14.7 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_40_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 14.7 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 15.1 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 15.1 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_39_piece0 on 10.143.133.36:35578 in memory (size: 14.5 KB, free: 908.8 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_39_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 14.5 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 15.1 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_39_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 14.5 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_39_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 14.5 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Added broadcast_43_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 15.1 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_39_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 14.5 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_38_piece0 on 10.143.133.36:35578 in memory (size: 14.3 KB, free: 908.8 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_38_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 14.3 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_38_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 14.3 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_38_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 14.3 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:04 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_38_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 14.3 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 294 bytes\n17/02/16 09:03:04 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 294 bytes\n17/02/16 09:03:04 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:04 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_37_piece0 on 10.143.133.36:35578 in memory (size: 14.2 KB, free: 908.8 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_37_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 14.2 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_37_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 14.2 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_37_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 14.2 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_37_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 14.2 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_36_piece0 on 10.143.133.36:35578 in memory (size: 14.0 KB, free: 908.8 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_36_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 14.0 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_36_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 14.0 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_36_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 14.0 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_36_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 14.0 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_35_piece0 on 10.143.133.36:35578 in memory (size: 13.8 KB, free: 908.8 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_35_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 13.8 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_35_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 13.8 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_35_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 13.8 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_35_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 13.8 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_34_piece0 on 10.143.133.36:35578 in memory (size: 13.6 KB, free: 908.8 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_34_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 13.6 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_34_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 13.6 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_34_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 13.6 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_34_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 13.6 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_33_piece0 on 10.143.133.36:35578 in memory (size: 13.4 KB, free: 908.8 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_33_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 13.4 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_33_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 13.4 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_33_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 13.4 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_33_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 13.4 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_32_piece0 on 10.143.133.36:35578 in memory (size: 13.2 KB, free: 908.9 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_32_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 13.2 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_32_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 13.2 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_32_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 13.2 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_32_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 13.2 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_31_piece0 on 10.143.133.36:35578 in memory (size: 13.1 KB, free: 908.9 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_31_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 13.1 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_31_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 13.1 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_31_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 13.1 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_31_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 13.1 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_30_piece0 on 10.143.133.36:35578 in memory (size: 12.9 KB, free: 908.9 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_30_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 12.9 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_30_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 12.9 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_30_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 12.9 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_30_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 12.9 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_29_piece0 on 10.143.133.36:35578 in memory (size: 12.8 KB, free: 908.9 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_29_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 12.8 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_29_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 12.8 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_29_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 12.8 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_29_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 12.8 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_28_piece0 on 10.143.133.36:35578 in memory (size: 12.5 KB, free: 908.9 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_28_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 12.5 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_28_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 12.5 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_28_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 12.5 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_28_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 12.5 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_27_piece0 on 10.143.133.36:35578 in memory (size: 12.4 KB, free: 908.9 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_27_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 12.4 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_27_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 12.4 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_27_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 12.4 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_27_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 12.4 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_26_piece0 on 10.143.133.36:35578 in memory (size: 12.2 KB, free: 908.9 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_26_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 12.2 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_26_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 12.2 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_26_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 12.2 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_26_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 12.2 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_25_piece0 on 10.143.133.36:35578 in memory (size: 11.8 KB, free: 908.9 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_25_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 11.8 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_25_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 11.8 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_25_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 11.8 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_25_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 11.8 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_24_piece0 on 10.143.133.36:35578 in memory (size: 11.7 KB, free: 909.0 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_24_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 11.7 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_24_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 11.7 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_24_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 11.7 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_24_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 11.7 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_23_piece0 on 10.143.133.36:35578 in memory (size: 11.5 KB, free: 909.0 MB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_23_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 11.5 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_23_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 11.5 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_23_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 11.5 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.storage.BlockManagerInfo: Removed broadcast_23_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 11.5 KB, free: 4.3 GB)\n17/02/16 09:03:04 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 47.0 (TID 208, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:04 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 47.0 (TID 206) in 377 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:03:04 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 47.0 (TID 207) in 382 ms on yp-spark-dal09-env5-0044 (2/5)\n17/02/16 09:03:04 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 47.0 (TID 204) in 386 ms on yp-spark-dal09-env5-0047 (3/5)\n17/02/16 09:03:05 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 47.0 (TID 205) in 471 ms on yp-spark-dal09-env5-0034 (4/5)\n17/02/16 09:03:05 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 47.0 (TID 208) in 369 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:03:05 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 47.0, whose tasks have all completed, from pool \n17/02/16 09:03:05 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 47 (flatMap at ALS.scala:1170) finished in 0.746 s\n17/02/16 09:03:05 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:05 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:05 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 48, ShuffleMapStage 49, ShuffleMapStage 50)\n17/02/16 09:03:05 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:05 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(47)\n17/02/16 09:03:05 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[336] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:03:05 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(48)\n17/02/16 09:03:05 INFO spark.storage.MemoryStore: Block broadcast_44 stored as values in memory (estimated size 48.5 KB, free 172.9 KB)\n17/02/16 09:03:05 INFO spark.storage.MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 15.3 KB, free 188.2 KB)\n17/02/16 09:03:05 INFO spark.storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on 10.143.133.36:35578 (size: 15.3 KB, free: 909.0 MB)\n17/02/16 09:03:05 INFO apache.spark.SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:05 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[336] at flatMap at ALS.scala:1170)\n17/02/16 09:03:05 INFO cluster.ego.EGODeployScheduler: Adding task set 48.0 with 5 tasks\n17/02/16 09:03:05 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 48.0 (TID 209, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:05 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 48.0 (TID 210, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:05 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 48.0 (TID 211, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:05 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 48.0 (TID 212, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:05 INFO spark.storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 15.3 KB, free: 4.3 GB)\n17/02/16 09:03:05 INFO spark.storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 15.3 KB, free: 4.3 GB)\n17/02/16 09:03:05 INFO spark.storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 15.3 KB, free: 4.3 GB)\n17/02/16 09:03:05 INFO spark.storage.BlockManagerInfo: Added broadcast_44_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 15.3 KB, free: 4.3 GB)\n17/02/16 09:03:05 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:05 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 296 bytes\n17/02/16 09:03:05 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:05 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:05 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:05 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 48.0 (TID 211) in 357 ms on yp-spark-dal09-env5-0034 (1/5)\n17/02/16 09:03:05 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 48.0 (TID 209) in 360 ms on yp-spark-dal09-env5-0047 (2/5)\n17/02/16 09:03:05 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 48.0 (TID 210) in 360 ms on yp-spark-dal09-env5-0031 (3/5)\n17/02/16 09:03:05 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 48.0 (TID 213, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:05 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 48.0 (TID 212) in 372 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:03:06 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 48.0 (TID 213) in 330 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:03:06 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 48.0, whose tasks have all completed, from pool \n17/02/16 09:03:06 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 48 (flatMap at ALS.scala:1170) finished in 0.704 s\n17/02/16 09:03:06 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:06 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:06 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 49, ShuffleMapStage 50)\n17/02/16 09:03:06 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:06 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(48)\n17/02/16 09:03:06 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[345] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:03:06 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(49)\n17/02/16 09:03:06 INFO spark.storage.MemoryStore: Block broadcast_45 stored as values in memory (estimated size 49.3 KB, free 237.5 KB)\n17/02/16 09:03:06 INFO spark.storage.MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 15.4 KB, free 252.9 KB)\n17/02/16 09:03:06 INFO spark.storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on 10.143.133.36:35578 (size: 15.4 KB, free: 908.9 MB)\n17/02/16 09:03:06 INFO apache.spark.SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:06 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[345] at flatMap at ALS.scala:1170)\n17/02/16 09:03:06 INFO cluster.ego.EGODeployScheduler: Adding task set 49.0 with 5 tasks\n17/02/16 09:03:06 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 49.0 (TID 214, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:06 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 49.0 (TID 215, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:06 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 49.0 (TID 216, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:06 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 49.0 (TID 217, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:06 INFO spark.storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 15.4 KB, free: 4.3 GB)\n17/02/16 09:03:06 INFO spark.storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 15.4 KB, free: 4.3 GB)\n17/02/16 09:03:06 INFO spark.storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 15.4 KB, free: 4.3 GB)\n17/02/16 09:03:06 INFO spark.storage.BlockManagerInfo: Added broadcast_45_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 15.4 KB, free: 4.3 GB)\n17/02/16 09:03:06 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:06 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 294 bytes\n17/02/16 09:03:06 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:06 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:06 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 10 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:06 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 49.0 (TID 218, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:06 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 49.0 (TID 215) in 375 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:03:06 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 49.0 (TID 214) in 376 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:03:06 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 49.0 (TID 217) in 378 ms on yp-spark-dal09-env5-0044 (3/5)\n17/02/16 09:03:06 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 49.0 (TID 216) in 384 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:03:06 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 49.0 (TID 218) in 365 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:03:06 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 49.0, whose tasks have all completed, from pool \n17/02/16 09:03:06 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 49 (flatMap at ALS.scala:1170) finished in 0.741 s\n17/02/16 09:03:06 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:06 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:06 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55, ShuffleMapStage 50)\n17/02/16 09:03:06 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:06 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(49)\n17/02/16 09:03:06 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[354] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:03:06 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(50)\n17/02/16 09:03:06 INFO spark.storage.MemoryStore: Block broadcast_46 stored as values in memory (estimated size 50.2 KB, free 303.2 KB)\n17/02/16 09:03:06 INFO spark.storage.MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 15.6 KB, free 318.8 KB)\n17/02/16 09:03:06 INFO spark.storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on 10.143.133.36:35578 (size: 15.6 KB, free: 908.9 MB)\n17/02/16 09:03:06 INFO apache.spark.SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:06 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[354] at flatMap at ALS.scala:1170)\n17/02/16 09:03:06 INFO cluster.ego.EGODeployScheduler: Adding task set 50.0 with 5 tasks\n17/02/16 09:03:06 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 50.0 (TID 219, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:06 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 50.0 (TID 220, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:06 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 50.0 (TID 221, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:06 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 50.0 (TID 222, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:06 INFO spark.storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 15.6 KB, free: 4.3 GB)\n17/02/16 09:03:06 INFO spark.storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 15.6 KB, free: 4.3 GB)\n17/02/16 09:03:06 INFO spark.storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 15.6 KB, free: 4.3 GB)\n17/02/16 09:03:06 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:06 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 296 bytes\n17/02/16 09:03:06 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:06 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:06 INFO spark.storage.BlockManagerInfo: Added broadcast_46_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 15.6 KB, free: 4.3 GB)\n17/02/16 09:03:06 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 9 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:07 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 50.0 (TID 219) in 358 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:03:07 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 50.0 (TID 222) in 363 ms on yp-spark-dal09-env5-0047 (2/5)\n17/02/16 09:03:07 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 50.0 (TID 221) in 372 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:03:07 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 50.0 (TID 223, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:07 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 50.0 (TID 220) in 374 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:03:07 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 50.0 (TID 223) in 330 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:03:07 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 50.0, whose tasks have all completed, from pool \n17/02/16 09:03:07 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 50 (flatMap at ALS.scala:1170) finished in 0.704 s\n17/02/16 09:03:07 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:07 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:07 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 51, ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55)\n17/02/16 09:03:07 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:07 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(50)\n17/02/16 09:03:07 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 51 (MapPartitionsRDD[363] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:03:07 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(51)\n17/02/16 09:03:07 INFO spark.storage.MemoryStore: Block broadcast_47 stored as values in memory (estimated size 51.1 KB, free 369.9 KB)\n17/02/16 09:03:07 INFO spark.storage.MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 15.7 KB, free 385.5 KB)\n17/02/16 09:03:07 INFO spark.storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on 10.143.133.36:35578 (size: 15.7 KB, free: 908.9 MB)\n17/02/16 09:03:07 INFO apache.spark.SparkContext: Created broadcast 47 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:07 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 51 (MapPartitionsRDD[363] at flatMap at ALS.scala:1170)\n17/02/16 09:03:07 INFO cluster.ego.EGODeployScheduler: Adding task set 51.0 with 5 tasks\n17/02/16 09:03:07 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 51.0 (TID 224, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:07 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 51.0 (TID 225, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:07 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 51.0 (TID 226, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:07 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 51.0 (TID 227, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:07 INFO spark.storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 15.7 KB, free: 4.3 GB)\n17/02/16 09:03:07 INFO spark.storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 15.7 KB, free: 4.3 GB)\n17/02/16 09:03:07 INFO spark.storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 15.7 KB, free: 4.3 GB)\n17/02/16 09:03:07 INFO spark.storage.BlockManagerInfo: Added broadcast_47_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 15.7 KB, free: 4.3 GB)\n17/02/16 09:03:07 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:07 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 294 bytes\n17/02/16 09:03:07 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:07 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:07 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 8 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:07 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 51.0 (TID 225) in 374 ms on yp-spark-dal09-env5-0034 (1/5)\n17/02/16 09:03:07 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 51.0 (TID 228, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:07 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 51.0 (TID 224) in 376 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:03:07 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 51.0 (TID 226) in 379 ms on yp-spark-dal09-env5-0044 (3/5)\n17/02/16 09:03:07 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 51.0 (TID 227) in 384 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:03:08 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 51.0 (TID 228) in 366 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:03:08 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 51.0, whose tasks have all completed, from pool \n17/02/16 09:03:08 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 51 (flatMap at ALS.scala:1170) finished in 0.743 s\n17/02/16 09:03:08 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:08 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:08 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 52, ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55)\n17/02/16 09:03:08 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:08 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(51)\n17/02/16 09:03:08 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[372] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:03:08 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(52)\n17/02/16 09:03:08 INFO spark.storage.MemoryStore: Block broadcast_48 stored as values in memory (estimated size 52.0 KB, free 437.5 KB)\n17/02/16 09:03:08 INFO spark.storage.MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 15.9 KB, free 453.4 KB)\n17/02/16 09:03:08 INFO spark.storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on 10.143.133.36:35578 (size: 15.9 KB, free: 908.9 MB)\n17/02/16 09:03:08 INFO apache.spark.SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:08 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[372] at flatMap at ALS.scala:1170)\n17/02/16 09:03:08 INFO cluster.ego.EGODeployScheduler: Adding task set 52.0 with 5 tasks\n17/02/16 09:03:08 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 52.0 (TID 229, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:08 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 52.0 (TID 230, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:08 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 52.0 (TID 231, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:08 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 52.0 (TID 232, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:08 INFO spark.storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 15.9 KB, free: 4.3 GB)\n17/02/16 09:03:08 INFO spark.storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 15.9 KB, free: 4.3 GB)\n17/02/16 09:03:08 INFO spark.storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 15.9 KB, free: 4.3 GB)\n17/02/16 09:03:08 INFO spark.storage.BlockManagerInfo: Added broadcast_48_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 15.9 KB, free: 4.3 GB)\n17/02/16 09:03:08 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:08 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 296 bytes\n17/02/16 09:03:08 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:08 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:08 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 7 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:08 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 52.0 (TID 229) in 357 ms on yp-spark-dal09-env5-0047 (1/5)\n17/02/16 09:03:08 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 52.0 (TID 231) in 358 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:03:08 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 52.0 (TID 230) in 359 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:03:08 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 52.0 (TID 233, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:08 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 52.0 (TID 232) in 374 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:03:08 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 52.0 (TID 233) in 329 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:03:08 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 52.0, whose tasks have all completed, from pool \n17/02/16 09:03:08 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 52 (flatMap at ALS.scala:1170) finished in 0.704 s\n17/02/16 09:03:08 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:08 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:08 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 53, ShuffleMapStage 54, ResultStage 55)\n17/02/16 09:03:08 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:08 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(52)\n17/02/16 09:03:08 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 53 (MapPartitionsRDD[381] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:03:08 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(53)\n17/02/16 09:03:08 INFO spark.storage.MemoryStore: Block broadcast_49 stored as values in memory (estimated size 52.9 KB, free 506.3 KB)\n17/02/16 09:03:08 INFO spark.storage.MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 16.0 KB, free 522.3 KB)\n17/02/16 09:03:08 INFO spark.storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on 10.143.133.36:35578 (size: 16.0 KB, free: 908.9 MB)\n17/02/16 09:03:08 INFO apache.spark.SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:08 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 53 (MapPartitionsRDD[381] at flatMap at ALS.scala:1170)\n17/02/16 09:03:08 INFO cluster.ego.EGODeployScheduler: Adding task set 53.0 with 5 tasks\n17/02/16 09:03:08 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 53.0 (TID 234, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:08 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 53.0 (TID 235, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:08 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 53.0 (TID 236, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:08 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 53.0 (TID 237, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:08 INFO spark.storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 16.0 KB, free: 4.3 GB)\n17/02/16 09:03:08 INFO spark.storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 16.0 KB, free: 4.3 GB)\n17/02/16 09:03:08 INFO spark.storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 16.0 KB, free: 4.3 GB)\n17/02/16 09:03:08 INFO spark.storage.BlockManagerInfo: Added broadcast_49_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 16.0 KB, free: 4.3 GB)\n17/02/16 09:03:08 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:08 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 294 bytes\n17/02/16 09:03:08 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:08 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:08 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 6 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:09 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 53.0 (TID 238, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:09 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 53.0 (TID 236) in 376 ms on yp-spark-dal09-env5-0031 (1/5)\n17/02/16 09:03:09 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 53.0 (TID 237) in 377 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:03:09 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 53.0 (TID 234) in 379 ms on yp-spark-dal09-env5-0044 (3/5)\n17/02/16 09:03:09 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 53.0 (TID 235) in 383 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:03:09 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 53.0 (TID 238) in 369 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:03:09 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 53.0, whose tasks have all completed, from pool \n17/02/16 09:03:09 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 53 (flatMap at ALS.scala:1170) finished in 0.746 s\n17/02/16 09:03:09 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:09 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:09 INFO spark.scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 54, ResultStage 55)\n17/02/16 09:03:09 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:09 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(53)\n17/02/16 09:03:09 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 54 (MapPartitionsRDD[390] at flatMap at ALS.scala:1170), which has no missing parents\n17/02/16 09:03:09 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(54)\n17/02/16 09:03:09 INFO spark.storage.MemoryStore: Block broadcast_50 stored as values in memory (estimated size 53.7 KB, free 576.1 KB)\n17/02/16 09:03:09 INFO spark.storage.MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 16.2 KB, free 592.3 KB)\n17/02/16 09:03:09 INFO spark.storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on 10.143.133.36:35578 (size: 16.2 KB, free: 908.9 MB)\n17/02/16 09:03:09 INFO apache.spark.SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:09 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 54 (MapPartitionsRDD[390] at flatMap at ALS.scala:1170)\n17/02/16 09:03:09 INFO cluster.ego.EGODeployScheduler: Adding task set 54.0 with 5 tasks\n17/02/16 09:03:09 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 54.0 (TID 239, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:09 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 54.0 (TID 240, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:09 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 54.0 (TID 241, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:09 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 54.0 (TID 242, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:09 INFO spark.storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 16.2 KB, free: 4.3 GB)\n17/02/16 09:03:09 INFO spark.storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 16.2 KB, free: 4.3 GB)\n17/02/16 09:03:09 INFO spark.storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 16.2 KB, free: 4.3 GB)\n17/02/16 09:03:09 INFO spark.storage.BlockManagerInfo: Added broadcast_50_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 16.2 KB, free: 4.3 GB)\n17/02/16 09:03:09 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:09 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 296 bytes\n17/02/16 09:03:09 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:09 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:09 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:10 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 54.0 (TID 242) in 356 ms on yp-spark-dal09-env5-0047 (1/5)\n17/02/16 09:03:10 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 54.0 (TID 241) in 358 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:03:10 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 54.0 (TID 240) in 360 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:03:10 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 54.0 (TID 243, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:10 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 54.0 (TID 239) in 376 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:03:10 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 54.0 (TID 243) in 329 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:03:10 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 54.0, whose tasks have all completed, from pool \n17/02/16 09:03:10 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 54 (flatMap at ALS.scala:1170) finished in 0.704 s\n17/02/16 09:03:10 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:10 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:10 INFO spark.scheduler.DAGScheduler: waiting: Set(ResultStage 55)\n17/02/16 09:03:10 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:10 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(54)\n17/02/16 09:03:10 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 55 (users MapPartitionsRDD[406] at mapValues at ALS.scala:255), which has no missing parents\n17/02/16 09:03:10 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(55)\n17/02/16 09:03:10 INFO spark.storage.MemoryStore: Block broadcast_51 stored as values in memory (estimated size 54.9 KB, free 647.2 KB)\n17/02/16 09:03:10 INFO spark.storage.MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 16.5 KB, free 663.8 KB)\n17/02/16 09:03:10 INFO spark.storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on 10.143.133.36:35578 (size: 16.5 KB, free: 908.8 MB)\n17/02/16 09:03:10 INFO apache.spark.SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:10 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 55 (users MapPartitionsRDD[406] at mapValues at ALS.scala:255)\n17/02/16 09:03:10 INFO cluster.ego.EGODeployScheduler: Adding task set 55.0 with 5 tasks\n17/02/16 09:03:10 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 55.0 (TID 244, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:10 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 55.0 (TID 245, yp-spark-dal09-env5-0034, partition 3,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:10 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 55.0 (TID 246, yp-spark-dal09-env5-0044, partition 1,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:10 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 55.0 (TID 247, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:10 INFO spark.storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 16.5 KB, free: 4.3 GB)\n17/02/16 09:03:10 INFO spark.storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 16.5 KB, free: 4.3 GB)\n17/02/16 09:03:10 INFO spark.storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 16.5 KB, free: 4.3 GB)\n17/02/16 09:03:10 INFO spark.storage.BlockManagerInfo: Added broadcast_51_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 16.5 KB, free: 4.3 GB)\n17/02/16 09:03:10 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:10 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 294 bytes\n17/02/16 09:03:10 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:10 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:10 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:10 INFO spark.storage.BlockManagerInfo: Added rdd_406_1 in memory on yp-spark-dal09-env5-0044:36970 (size: 539.1 KB, free: 4.3 GB)\n17/02/16 09:03:10 INFO spark.storage.BlockManagerInfo: Added rdd_406_0 in memory on yp-spark-dal09-env5-0031:38585 (size: 539.1 KB, free: 4.3 GB)\n17/02/16 09:03:10 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 55.0 (TID 248, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:10 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 55.0 (TID 246) in 411 ms on yp-spark-dal09-env5-0044 (1/5)\n17/02/16 09:03:10 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 55.0 (TID 247) in 411 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:03:10 INFO spark.storage.BlockManagerInfo: Added rdd_406_3 in memory on yp-spark-dal09-env5-0034:45747 (size: 539.1 KB, free: 4.3 GB)\n17/02/16 09:03:10 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 55.0 (TID 245) in 418 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:03:10 INFO spark.storage.BlockManagerInfo: Added rdd_406_2 in memory on yp-spark-dal09-env5-0047:34157 (size: 539.1 KB, free: 4.3 GB)\n17/02/16 09:03:10 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 55.0 (TID 244) in 424 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:03:11 INFO spark.storage.BlockManagerInfo: Added rdd_406_4 in memory on yp-spark-dal09-env5-0031:38585 (size: 539.1 KB, free: 4.3 GB)\n17/02/16 09:03:11 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 55.0 (TID 248) in 392 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:03:11 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 55.0, whose tasks have all completed, from pool \n17/02/16 09:03:11 INFO spark.scheduler.DAGScheduler: ResultStage 55 (count at ALS.scala:263) finished in 0.804 s\n17/02/16 09:03:11 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(55)\n17/02/16 09:03:11 INFO spark.scheduler.DAGScheduler: Job 5 finished: count at ALS.scala:263, took 31.254017 s\n17/02/16 09:03:11 INFO apache.spark.SparkContext: Starting job: count at ALS.scala:264\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 310 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 318 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 322 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 44 is 313 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 43 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 42 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 41 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 40 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 39 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 38 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 37 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 36 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 35 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 34 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 31 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 30 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 29 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 28 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 27 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 26 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 25 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 21 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 20 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 19 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 296 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 294 bytes\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 296 bytes\n17/02/16 09:03:11 INFO spark.scheduler.DAGScheduler: Got job 6 (count at ALS.scala:264) with 5 output partitions\n17/02/16 09:03:11 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 100 (count at ALS.scala:264)\n17/02/16 09:03:11 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 99, ShuffleMapStage 57)\n17/02/16 09:03:11 INFO spark.scheduler.DAGScheduler: Missing parents: List()\n17/02/16 09:03:11 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 100 (products MapPartitionsRDD[407] at mapValues at ALS.scala:259), which has no missing parents\n17/02/16 09:03:11 INFO spark.storage.MemoryStore: Block broadcast_52 stored as values in memory (estimated size 54.1 KB, free 717.8 KB)\n17/02/16 09:03:11 INFO spark.storage.MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 16.4 KB, free 734.2 KB)\n17/02/16 09:03:11 INFO spark.storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on 10.143.133.36:35578 (size: 16.4 KB, free: 908.8 MB)\n17/02/16 09:03:11 INFO apache.spark.SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:11 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 100 (products MapPartitionsRDD[407] at mapValues at ALS.scala:259)\n17/02/16 09:03:11 INFO cluster.ego.EGODeployScheduler: Adding task set 100.0 with 5 tasks\n17/02/16 09:03:11 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 100.0 (TID 249, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:11 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 100.0 (TID 250, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:11 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 100.0 (TID 251, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:11 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 100.0 (TID 252, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:11 INFO spark.storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 16.4 KB, free: 4.3 GB)\n17/02/16 09:03:11 INFO spark.storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 16.4 KB, free: 4.3 GB)\n17/02/16 09:03:11 INFO spark.storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 16.4 KB, free: 4.3 GB)\n17/02/16 09:03:11 INFO spark.storage.BlockManagerInfo: Added broadcast_52_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 16.4 KB, free: 4.3 GB)\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:11 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(100)\n17/02/16 09:03:11 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:11 INFO spark.storage.BlockManagerInfo: Added rdd_407_2 in memory on yp-spark-dal09-env5-0047:34157 (size: 314.7 KB, free: 4.2 GB)\n17/02/16 09:03:11 INFO spark.storage.BlockManagerInfo: Added rdd_407_1 in memory on yp-spark-dal09-env5-0031:38585 (size: 314.7 KB, free: 4.3 GB)\n17/02/16 09:03:11 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 100.0 (TID 250) in 381 ms on yp-spark-dal09-env5-0047 (1/5)\n17/02/16 09:03:11 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 100.0 (TID 251) in 381 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:03:11 INFO spark.storage.BlockManagerInfo: Added rdd_407_0 in memory on yp-spark-dal09-env5-0034:45747 (size: 314.6 KB, free: 4.3 GB)\n17/02/16 09:03:11 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 100.0 (TID 249) in 385 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:03:11 INFO spark.storage.BlockManagerInfo: Added rdd_407_3 in memory on yp-spark-dal09-env5-0044:36970 (size: 314.6 KB, free: 4.3 GB)\n17/02/16 09:03:11 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 100.0 (TID 253, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:11 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 100.0 (TID 252) in 392 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:03:12 INFO spark.storage.BlockManagerInfo: Added rdd_407_4 in memory on yp-spark-dal09-env5-0044:36970 (size: 314.6 KB, free: 4.3 GB)\n17/02/16 09:03:12 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 100.0 (TID 253) in 342 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:03:12 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 100.0, whose tasks have all completed, from pool \n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: ResultStage 100 (count at ALS.scala:264) finished in 0.736 s\n17/02/16 09:03:12 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(100)\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Job 6 finished: count at ALS.scala:264, took 0.774355 s\n17/02/16 09:03:12 INFO apache.spark.SparkContext: Starting job: first at MatrixFactorizationModel.scala:67\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Got job 7 (first at MatrixFactorizationModel.scala:67) with 1 output partitions\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 146 (first at MatrixFactorizationModel.scala:67)\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 104, ShuffleMapStage 145)\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Missing parents: List()\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 146 (users MapPartitionsRDD[406] at mapValues at ALS.scala:255), which has no missing parents\n17/02/16 09:03:12 INFO spark.storage.MemoryStore: Block broadcast_53 stored as values in memory (estimated size 55.1 KB, free 789.3 KB)\n17/02/16 09:03:12 INFO spark.storage.MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 16.6 KB, free 806.0 KB)\n17/02/16 09:03:12 INFO spark.storage.BlockManagerInfo: Added broadcast_53_piece0 in memory on 10.143.133.36:35578 (size: 16.6 KB, free: 908.8 MB)\n17/02/16 09:03:12 INFO apache.spark.SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 146 (users MapPartitionsRDD[406] at mapValues at ALS.scala:255)\n17/02/16 09:03:12 INFO cluster.ego.EGODeployScheduler: Adding task set 146.0 with 1 tasks\n17/02/16 09:03:12 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 146.0 (TID 254, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:12 INFO spark.storage.BlockManagerInfo: Added broadcast_53_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 16.6 KB, free: 4.3 GB)\n17/02/16 09:03:12 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 146.0 (TID 254) in 14 ms on yp-spark-dal09-env5-0031 (1/1)\n17/02/16 09:03:12 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 146.0, whose tasks have all completed, from pool \n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: ResultStage 146 (first at MatrixFactorizationModel.scala:67) finished in 0.015 s\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Job 7 finished: first at MatrixFactorizationModel.scala:67, took 0.035909 s\n17/02/16 09:03:12 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(146)\n17/02/16 09:03:12 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(146)\n17/02/16 09:03:12 INFO apache.spark.SparkContext: Starting job: first at MatrixFactorizationModel.scala:67\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Got job 8 (first at MatrixFactorizationModel.scala:67) with 1 output partitions\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 191 (first at MatrixFactorizationModel.scala:67)\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 190, ShuffleMapStage 148)\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Missing parents: List()\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 191 (products MapPartitionsRDD[407] at mapValues at ALS.scala:259), which has no missing parents\n17/02/16 09:03:12 INFO spark.storage.MemoryStore: Block broadcast_54 stored as values in memory (estimated size 54.2 KB, free 860.2 KB)\n17/02/16 09:03:12 INFO spark.storage.MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 16.4 KB, free 876.6 KB)\n17/02/16 09:03:12 INFO spark.storage.BlockManagerInfo: Added broadcast_54_piece0 in memory on 10.143.133.36:35578 (size: 16.4 KB, free: 908.8 MB)\n17/02/16 09:03:12 INFO apache.spark.SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 191 (products MapPartitionsRDD[407] at mapValues at ALS.scala:259)\n17/02/16 09:03:12 INFO cluster.ego.EGODeployScheduler: Adding task set 191.0 with 1 tasks\n17/02/16 09:03:12 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 191.0 (TID 255, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:12 INFO spark.storage.BlockManagerInfo: Added broadcast_54_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 16.4 KB, free: 4.3 GB)\n17/02/16 09:03:12 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(191)\n17/02/16 09:03:12 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 191.0 (TID 255) in 15 ms on yp-spark-dal09-env5-0034 (1/1)\n17/02/16 09:03:12 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 191.0, whose tasks have all completed, from pool \n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: ResultStage 191 (first at MatrixFactorizationModel.scala:67) finished in 0.015 s\n17/02/16 09:03:12 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(191)\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Job 8 finished: first at MatrixFactorizationModel.scala:67, took 0.033314 s\n17/02/16 09:03:12 INFO apache.spark.SparkContext: Starting job: first at MatrixFactorizationModel.scala:67\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Got job 9 (first at MatrixFactorizationModel.scala:67) with 1 output partitions\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 237 (first at MatrixFactorizationModel.scala:67)\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 195, ShuffleMapStage 236)\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Missing parents: List()\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 237 (users MapPartitionsRDD[406] at mapValues at ALS.scala:255), which has no missing parents\n17/02/16 09:03:12 INFO spark.storage.MemoryStore: Block broadcast_55 stored as values in memory (estimated size 55.1 KB, free 931.7 KB)\n17/02/16 09:03:12 INFO spark.storage.MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 16.6 KB, free 948.4 KB)\n17/02/16 09:03:12 INFO spark.storage.BlockManagerInfo: Added broadcast_55_piece0 in memory on 10.143.133.36:35578 (size: 16.6 KB, free: 908.8 MB)\n17/02/16 09:03:12 INFO apache.spark.SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 237 (users MapPartitionsRDD[406] at mapValues at ALS.scala:255)\n17/02/16 09:03:12 INFO cluster.ego.EGODeployScheduler: Adding task set 237.0 with 1 tasks\n17/02/16 09:03:12 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 237.0 (TID 256, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:12 INFO spark.storage.BlockManagerInfo: Added broadcast_55_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 16.6 KB, free: 4.3 GB)\n17/02/16 09:03:12 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 237.0 (TID 256) in 10 ms on yp-spark-dal09-env5-0031 (1/1)\n17/02/16 09:03:12 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 237.0, whose tasks have all completed, from pool \n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: ResultStage 237 (first at MatrixFactorizationModel.scala:67) finished in 0.011 s\n17/02/16 09:03:12 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(237)\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Job 9 finished: first at MatrixFactorizationModel.scala:67, took 0.027247 s\n17/02/16 09:03:12 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(237)\n17/02/16 09:03:12 INFO apache.spark.SparkContext: Starting job: first at MatrixFactorizationModel.scala:67\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Got job 10 (first at MatrixFactorizationModel.scala:67) with 1 output partitions\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 282 (first at MatrixFactorizationModel.scala:67)\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 281, ShuffleMapStage 239)\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Missing parents: List()\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 282 (products MapPartitionsRDD[407] at mapValues at ALS.scala:259), which has no missing parents\n17/02/16 09:03:12 INFO spark.storage.MemoryStore: Block broadcast_56 stored as values in memory (estimated size 54.2 KB, free 1002.6 KB)\n17/02/16 09:03:12 INFO spark.storage.MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 16.4 KB, free 1019.0 KB)\n17/02/16 09:03:12 INFO spark.storage.BlockManagerInfo: Added broadcast_56_piece0 in memory on 10.143.133.36:35578 (size: 16.4 KB, free: 908.8 MB)\n17/02/16 09:03:12 INFO apache.spark.SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 282 (products MapPartitionsRDD[407] at mapValues at ALS.scala:259)\n17/02/16 09:03:12 INFO cluster.ego.EGODeployScheduler: Adding task set 282.0 with 1 tasks\n17/02/16 09:03:12 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 282.0 (TID 257, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:12 INFO spark.storage.BlockManagerInfo: Added broadcast_56_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 16.4 KB, free: 4.3 GB)\n17/02/16 09:03:12 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(282)\n17/02/16 09:03:12 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 282.0 (TID 257) in 11 ms on yp-spark-dal09-env5-0034 (1/1)\n17/02/16 09:03:12 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 282.0, whose tasks have all completed, from pool \n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: ResultStage 282 (first at MatrixFactorizationModel.scala:67) finished in 0.011 s\n17/02/16 09:03:12 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(282)\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Job 10 finished: first at MatrixFactorizationModel.scala:67, took 0.028165 s\n17/02/16 09:03:12 INFO CloudantRecommender: [Finished train model: , 2017-02-16 09:03:12 CST]\n17/02/16 09:03:12 INFO CloudantRecommender: [Starting __get_top_recommendations: , 2017-02-16 09:03:12 CST]\n17/02/16 09:03:12 INFO apache.spark.SparkContext: Starting job: runJob at PythonRDD.scala:393\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Registering RDD 411 (flatMap at MatrixFactorizationModel.scala:278)\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Got job 11 (runJob at PythonRDD.scala:393) with 1 output partitions\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 372 (runJob at PythonRDD.scala:393)\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 371)\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 371)\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 371 (MapPartitionsRDD[411] at flatMap at MatrixFactorizationModel.scala:278), which has no missing parents\n17/02/16 09:03:12 INFO spark.storage.MemoryStore: Block broadcast_57 stored as values in memory (estimated size 58.4 KB, free 1077.5 KB)\n17/02/16 09:03:12 INFO spark.storage.MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 17.9 KB, free 1095.4 KB)\n17/02/16 09:03:12 INFO spark.storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on 10.143.133.36:35578 (size: 17.9 KB, free: 908.7 MB)\n17/02/16 09:03:12 INFO apache.spark.SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:12 INFO spark.scheduler.DAGScheduler: Submitting 25 missing tasks from ShuffleMapStage 371 (MapPartitionsRDD[411] at flatMap at MatrixFactorizationModel.scala:278)\n17/02/16 09:03:12 INFO cluster.ego.EGODeployScheduler: Adding task set 371.0 with 25 tasks\n17/02/16 09:03:12 INFO spark.scheduler.TaskSetManager: Starting task 10.0 in stage 371.0 (TID 258, yp-spark-dal09-env5-0047, partition 10,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:12 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 371.0 (TID 259, yp-spark-dal09-env5-0031, partition 0,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:12 INFO spark.scheduler.TaskSetManager: Starting task 15.0 in stage 371.0 (TID 260, yp-spark-dal09-env5-0034, partition 15,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:12 INFO spark.scheduler.TaskSetManager: Starting task 5.0 in stage 371.0 (TID 261, yp-spark-dal09-env5-0044, partition 5,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:12 INFO spark.storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 17.9 KB, free: 4.3 GB)\n17/02/16 09:03:12 INFO spark.storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 17.9 KB, free: 4.3 GB)\n17/02/16 09:03:12 INFO spark.storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 17.9 KB, free: 4.3 GB)\n17/02/16 09:03:12 INFO spark.storage.BlockManagerInfo: Added broadcast_57_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 17.9 KB, free: 4.2 GB)\n17/02/16 09:03:12 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(371)\n17/02/16 09:03:12 INFO spark.scheduler.TaskSetManager: Starting task 11.0 in stage 371.0 (TID 262, yp-spark-dal09-env5-0047, partition 11,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:13 INFO spark.scheduler.TaskSetManager: Starting task 12.0 in stage 371.0 (TID 263, yp-spark-dal09-env5-0047, partition 12,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:13 INFO spark.scheduler.TaskSetManager: Finished task 11.0 in stage 371.0 (TID 262) in 945 ms on yp-spark-dal09-env5-0047 (1/25)\n17/02/16 09:03:13 INFO spark.scheduler.TaskSetManager: Starting task 13.0 in stage 371.0 (TID 264, yp-spark-dal09-env5-0047, partition 13,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:13 INFO spark.scheduler.TaskSetManager: Finished task 10.0 in stage 371.0 (TID 258) in 1318 ms on yp-spark-dal09-env5-0047 (2/25)\n17/02/16 09:03:13 INFO spark.scheduler.TaskSetManager: Starting task 16.0 in stage 371.0 (TID 265, yp-spark-dal09-env5-0034, partition 16,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:13 INFO spark.scheduler.TaskSetManager: Finished task 15.0 in stage 371.0 (TID 260) in 1335 ms on yp-spark-dal09-env5-0034 (3/25)\n17/02/16 09:03:13 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 371.0 (TID 266, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:13 INFO spark.scheduler.TaskSetManager: Starting task 17.0 in stage 371.0 (TID 267, yp-spark-dal09-env5-0034, partition 17,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:13 INFO spark.scheduler.TaskSetManager: Starting task 6.0 in stage 371.0 (TID 268, yp-spark-dal09-env5-0044, partition 6,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:13 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 371.0 (TID 269, yp-spark-dal09-env5-0031, partition 2,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:13 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 371.0 (TID 259) in 1490 ms on yp-spark-dal09-env5-0031 (4/25)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Starting task 7.0 in stage 371.0 (TID 270, yp-spark-dal09-env5-0044, partition 7,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Finished task 5.0 in stage 371.0 (TID 261) in 1753 ms on yp-spark-dal09-env5-0044 (5/25)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 371.0 (TID 271, yp-spark-dal09-env5-0031, partition 3,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 371.0 (TID 266) in 609 ms on yp-spark-dal09-env5-0031 (6/25)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Starting task 18.0 in stage 371.0 (TID 272, yp-spark-dal09-env5-0034, partition 18,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Finished task 16.0 in stage 371.0 (TID 265) in 629 ms on yp-spark-dal09-env5-0034 (7/25)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Starting task 19.0 in stage 371.0 (TID 273, yp-spark-dal09-env5-0034, partition 19,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Finished task 17.0 in stage 371.0 (TID 267) in 637 ms on yp-spark-dal09-env5-0034 (8/25)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Starting task 14.0 in stage 371.0 (TID 274, yp-spark-dal09-env5-0047, partition 14,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Finished task 13.0 in stage 371.0 (TID 264) in 694 ms on yp-spark-dal09-env5-0047 (9/25)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Finished task 12.0 in stage 371.0 (TID 263) in 719 ms on yp-spark-dal09-env5-0047 (10/25)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Starting task 8.0 in stage 371.0 (TID 275, yp-spark-dal09-env5-0044, partition 8,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Finished task 6.0 in stage 371.0 (TID 268) in 720 ms on yp-spark-dal09-env5-0044 (11/25)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 371.0 (TID 276, yp-spark-dal09-env5-0031, partition 4,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 371.0 (TID 269) in 695 ms on yp-spark-dal09-env5-0031 (12/25)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Starting task 9.0 in stage 371.0 (TID 277, yp-spark-dal09-env5-0044, partition 9,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Finished task 7.0 in stage 371.0 (TID 270) in 622 ms on yp-spark-dal09-env5-0044 (13/25)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Finished task 18.0 in stage 371.0 (TID 272) in 617 ms on yp-spark-dal09-env5-0034 (14/25)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Finished task 14.0 in stage 371.0 (TID 274) in 617 ms on yp-spark-dal09-env5-0047 (15/25)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Finished task 19.0 in stage 371.0 (TID 273) in 687 ms on yp-spark-dal09-env5-0034 (16/25)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Starting task 20.0 in stage 371.0 (TID 278, yp-spark-dal09-env5-0031, partition 20,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:14 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 371.0 (TID 271) in 749 ms on yp-spark-dal09-env5-0031 (17/25)\n17/02/16 09:03:15 INFO spark.scheduler.TaskSetManager: Finished task 8.0 in stage 371.0 (TID 275) in 737 ms on yp-spark-dal09-env5-0044 (18/25)\n17/02/16 09:03:15 INFO spark.scheduler.TaskSetManager: Starting task 21.0 in stage 371.0 (TID 279, yp-spark-dal09-env5-0031, partition 21,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:15 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 371.0 (TID 276) in 751 ms on yp-spark-dal09-env5-0031 (19/25)\n17/02/16 09:03:15 INFO spark.scheduler.TaskSetManager: Finished task 9.0 in stage 371.0 (TID 277) in 625 ms on yp-spark-dal09-env5-0044 (20/25)\n17/02/16 09:03:15 INFO spark.scheduler.TaskSetManager: Starting task 22.0 in stage 371.0 (TID 280, yp-spark-dal09-env5-0031, partition 22,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:15 INFO spark.scheduler.TaskSetManager: Finished task 20.0 in stage 371.0 (TID 278) in 877 ms on yp-spark-dal09-env5-0031 (21/25)\n17/02/16 09:03:16 INFO spark.scheduler.TaskSetManager: Starting task 23.0 in stage 371.0 (TID 281, yp-spark-dal09-env5-0031, partition 23,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:16 INFO spark.scheduler.TaskSetManager: Finished task 21.0 in stage 371.0 (TID 279) in 856 ms on yp-spark-dal09-env5-0031 (22/25)\n17/02/16 09:03:16 INFO spark.scheduler.TaskSetManager: Starting task 24.0 in stage 371.0 (TID 282, yp-spark-dal09-env5-0031, partition 24,PROCESS_LOCAL, 2519 bytes)\n17/02/16 09:03:16 INFO spark.scheduler.TaskSetManager: Finished task 22.0 in stage 371.0 (TID 280) in 738 ms on yp-spark-dal09-env5-0031 (23/25)\n17/02/16 09:03:16 INFO spark.scheduler.TaskSetManager: Finished task 23.0 in stage 371.0 (TID 281) in 660 ms on yp-spark-dal09-env5-0031 (24/25)\n17/02/16 09:03:17 INFO spark.scheduler.TaskSetManager: Finished task 24.0 in stage 371.0 (TID 282) in 572 ms on yp-spark-dal09-env5-0031 (25/25)\n17/02/16 09:03:17 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 371.0, whose tasks have all completed, from pool \n17/02/16 09:03:17 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 371 (flatMap at MatrixFactorizationModel.scala:278) finished in 4.884 s\n17/02/16 09:03:17 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:17 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:17 INFO spark.scheduler.DAGScheduler: waiting: Set(ResultStage 372)\n17/02/16 09:03:17 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:17 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(371)\n17/02/16 09:03:17 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 372 (PythonRDD[417] at RDD at PythonRDD.scala:43), which has no missing parents\n17/02/16 09:03:17 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(372)\n17/02/16 09:03:17 INFO spark.storage.MemoryStore: Block broadcast_58 stored as values in memory (estimated size 60.5 KB, free 1155.9 KB)\n17/02/16 09:03:17 INFO spark.storage.MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 18.9 KB, free 1174.8 KB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Added broadcast_58_piece0 in memory on 10.143.133.36:35578 (size: 18.9 KB, free: 908.7 MB)\n17/02/16 09:03:17 INFO apache.spark.SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:17 INFO spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 372 (PythonRDD[417] at RDD at PythonRDD.scala:43)\n17/02/16 09:03:17 INFO cluster.ego.EGODeployScheduler: Adding task set 372.0 with 1 tasks\n17/02/16 09:03:17 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 372.0 (TID 283, yp-spark-dal09-env5-0031, partition 0,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Added broadcast_58_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 18.9 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 45 is 333 bytes\n17/02/16 09:03:17 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (yp-spark-dal09-env5-0030:49824) with ID 42ea9ecb-5a33-421c-8229-bdbed45188c2\n17/02/16 09:03:17 INFO spark.storage.BlockManagerMasterEndpoint: Registering block manager yp-spark-dal09-env5-0030:45125 with 4.3 GB RAM, BlockManagerId(42ea9ecb-5a33-421c-8229-bdbed45188c2, yp-spark-dal09-env5-0030, 45125)\n17/02/16 09:03:17 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (yp-spark-dal09-env5-0045:34904) with ID c4d314d2-1da9-4b7b-8572-371461538ecc\n17/02/16 09:03:17 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 372.0 (TID 283) in 115 ms on yp-spark-dal09-env5-0031 (1/1)\n17/02/16 09:03:17 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 372.0, whose tasks have all completed, from pool \n17/02/16 09:03:17 INFO spark.scheduler.DAGScheduler: ResultStage 372 (runJob at PythonRDD.scala:393) finished in 0.116 s\n17/02/16 09:03:17 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(372)\n17/02/16 09:03:17 INFO spark.scheduler.DAGScheduler: Job 11 finished: runJob at PythonRDD.scala:393, took 5.046141 s\n17/02/16 09:03:17 INFO spark.storage.BlockManagerMasterEndpoint: Registering block manager yp-spark-dal09-env5-0045:37648 with 4.3 GB RAM, BlockManagerId(c4d314d2-1da9-4b7b-8572-371461538ecc, yp-spark-dal09-env5-0045, 37648)\n17/02/16 09:03:17 INFO CloudantRecommender: [Finished __get_top_recommendations: , 2017-02-16 09:03:17 CST]\n17/02/16 09:03:17 INFO CloudantRecommender: [Created new recommendations db, recommendationdb_1487257397]\n17/02/16 09:03:17 INFO apache.spark.SparkContext: Starting job: collect at <ipython-input-7-5997fdef2cd1>:145\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 310 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 318 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 322 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 44 is 313 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 43 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 42 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 41 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 40 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 39 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 38 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 37 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 36 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 35 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 34 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 31 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 30 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 29 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 28 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 27 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 26 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 25 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 21 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 20 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 19 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 294 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 296 bytes\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 4 is 294 bytes\n17/02/16 09:03:17 INFO spark.scheduler.DAGScheduler: Got job 12 (collect at <ipython-input-7-5997fdef2cd1>:145) with 25 output partitions\n17/02/16 09:03:17 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 462 (collect at <ipython-input-7-5997fdef2cd1>:145)\n17/02/16 09:03:17 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 461)\n17/02/16 09:03:17 INFO spark.scheduler.DAGScheduler: Missing parents: List()\n17/02/16 09:03:17 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 462 (PythonRDD[427] at collect at <ipython-input-7-5997fdef2cd1>:145), which has no missing parents\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_58_piece0 on 10.143.133.36:35578 in memory (size: 18.9 KB, free: 908.7 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_58_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 18.9 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.MemoryStore: Block broadcast_59 stored as values in memory (estimated size 71.9 KB, free 1167.3 KB)\n17/02/16 09:03:17 INFO spark.storage.MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 24.7 KB, free 1192.0 KB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on 10.143.133.36:35578 (size: 24.7 KB, free: 908.7 MB)\n17/02/16 09:03:17 INFO apache.spark.SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:17 INFO spark.scheduler.DAGScheduler: Submitting 25 missing tasks from ResultStage 462 (PythonRDD[427] at collect at <ipython-input-7-5997fdef2cd1>:145)\n17/02/16 09:03:17 INFO cluster.ego.EGODeployScheduler: Adding task set 462.0 with 25 tasks\n17/02/16 09:03:17 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 462.0 (TID 284, yp-spark-dal09-env5-0031, partition 0,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:17 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 462.0 (TID 285, yp-spark-dal09-env5-0047, partition 2,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:17 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 462.0 (TID 286, yp-spark-dal09-env5-0044, partition 1,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:17 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 462.0 (TID 287, yp-spark-dal09-env5-0034, partition 3,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 24.7 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 69\n17/02/16 09:03:17 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(462)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_57_piece0 on 10.143.133.36:35578 in memory (size: 17.9 KB, free: 908.7 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_57_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 17.9 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_57_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 17.9 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_57_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 17.9 KB, free: 4.2 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_57_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 17.9 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 24.7 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 24.7 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 68\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Added broadcast_59_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 24.7 KB, free: 4.2 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_56_piece0 on 10.143.133.36:35578 in memory (size: 16.4 KB, free: 908.8 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_56_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 16.4 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 67\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_55_piece0 on 10.143.133.36:35578 in memory (size: 16.6 KB, free: 908.8 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_55_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 16.6 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 66\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_54_piece0 on 10.143.133.36:35578 in memory (size: 16.4 KB, free: 908.8 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_54_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 16.4 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 65\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_53_piece0 on 10.143.133.36:35578 in memory (size: 16.6 KB, free: 908.8 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_53_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 16.6 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 64\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_52_piece0 on 10.143.133.36:35578 in memory (size: 16.4 KB, free: 908.8 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_52_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 16.4 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_52_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 16.4 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_52_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 16.4 KB, free: 4.2 GB)\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_52_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 16.4 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 63\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_51_piece0 on 10.143.133.36:35578 in memory (size: 16.5 KB, free: 908.8 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_51_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 16.5 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_51_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 16.5 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_51_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 16.5 KB, free: 4.2 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_51_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 16.5 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 62\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_50_piece0 on 10.143.133.36:35578 in memory (size: 16.2 KB, free: 908.9 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_50_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 16.2 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_50_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 16.2 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_50_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 16.2 KB, free: 4.2 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_50_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 16.2 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 61\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_49_piece0 on 10.143.133.36:35578 in memory (size: 16.0 KB, free: 908.9 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_49_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 16.0 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_49_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 16.0 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 45 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_49_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 16.0 KB, free: 4.2 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_49_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 16.0 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 60\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_48_piece0 on 10.143.133.36:35578 in memory (size: 15.9 KB, free: 908.9 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_48_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 15.9 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_48_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 15.9 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_48_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 15.9 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_48_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 15.9 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 59\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_47_piece0 on 10.143.133.36:35578 in memory (size: 15.7 KB, free: 908.9 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_47_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 15.7 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_47_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 15.7 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_47_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 15.7 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_47_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 15.7 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 58\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_46_piece0 on 10.143.133.36:35578 in memory (size: 15.6 KB, free: 908.9 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_46_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 15.6 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_46_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 15.6 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_46_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 15.6 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_46_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 15.6 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 57\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_45_piece0 on 10.143.133.36:35578 in memory (size: 15.4 KB, free: 908.9 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_45_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 15.4 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_45_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 15.4 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_45_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 15.4 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_45_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 15.4 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 56\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_44_piece0 on 10.143.133.36:35578 in memory (size: 15.3 KB, free: 908.9 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_44_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 15.3 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_44_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 15.3 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_44_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 15.3 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_44_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 15.3 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 55\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_43_piece0 on 10.143.133.36:35578 in memory (size: 15.1 KB, free: 909.0 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_43_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 15.1 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_43_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 15.1 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_43_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 15.1 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_43_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 15.1 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 54\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_42_piece0 on 10.143.133.36:35578 in memory (size: 15.0 KB, free: 909.0 MB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_42_piece0 on yp-spark-dal09-env5-0034:45747 in memory (size: 15.0 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_42_piece0 on yp-spark-dal09-env5-0044:36970 in memory (size: 15.0 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_42_piece0 on yp-spark-dal09-env5-0047:34157 in memory (size: 15.0 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Removed broadcast_42_piece0 on yp-spark-dal09-env5-0031:38585 in memory (size: 15.0 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 53\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 52\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 51\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 50\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 49\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 48\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 47\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 46\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 45\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 44\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 43\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 42\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 41\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 40\n17/02/16 09:03:17 INFO apache.spark.ContextCleaner: Cleaned accumulator 39\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Added rdd_423_1 in memory on yp-spark-dal09-env5-0044:36970 (size: 99.6 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Added rdd_423_3 in memory on yp-spark-dal09-env5-0034:45747 (size: 99.6 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Added rdd_423_2 in memory on yp-spark-dal09-env5-0047:34157 (size: 99.6 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Added rdd_423_0 in memory on yp-spark-dal09-env5-0031:38585 (size: 99.2 KB, free: 4.3 GB)\n17/02/16 09:03:17 INFO spark.scheduler.TaskSetManager: Starting task 6.0 in stage 462.0 (TID 288, yp-spark-dal09-env5-0044, partition 6,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:17 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 462.0 (TID 286) in 322 ms on yp-spark-dal09-env5-0044 (1/25)\n17/02/16 09:03:17 INFO spark.scheduler.TaskSetManager: Starting task 8.0 in stage 462.0 (TID 289, yp-spark-dal09-env5-0034, partition 8,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:17 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 462.0 (TID 287) in 353 ms on yp-spark-dal09-env5-0034 (2/25)\n17/02/16 09:03:17 INFO spark.scheduler.TaskSetManager: Starting task 7.0 in stage 462.0 (TID 290, yp-spark-dal09-env5-0047, partition 7,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:17 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 462.0 (TID 285) in 364 ms on yp-spark-dal09-env5-0047 (3/25)\n17/02/16 09:03:17 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 462.0 (TID 291, yp-spark-dal09-env5-0031, partition 4,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:17 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 462.0 (TID 284) in 403 ms on yp-spark-dal09-env5-0031 (4/25)\n17/02/16 09:03:17 INFO spark.storage.BlockManagerInfo: Added rdd_423_6 in memory on yp-spark-dal09-env5-0044:36970 (size: 99.6 KB, free: 4.3 GB)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_8 in memory on yp-spark-dal09-env5-0034:45747 (size: 99.6 KB, free: 4.3 GB)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_7 in memory on yp-spark-dal09-env5-0047:34157 (size: 99.6 KB, free: 4.2 GB)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 11.0 in stage 462.0 (TID 292, yp-spark-dal09-env5-0044, partition 11,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 6.0 in stage 462.0 (TID 288) in 168 ms on yp-spark-dal09-env5-0044 (5/25)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_4 in memory on yp-spark-dal09-env5-0031:38585 (size: 99.6 KB, free: 4.3 GB)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 13.0 in stage 462.0 (TID 293, yp-spark-dal09-env5-0034, partition 13,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 8.0 in stage 462.0 (TID 289) in 146 ms on yp-spark-dal09-env5-0034 (6/25)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 12.0 in stage 462.0 (TID 294, yp-spark-dal09-env5-0047, partition 12,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 7.0 in stage 462.0 (TID 290) in 155 ms on yp-spark-dal09-env5-0047 (7/25)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 5.0 in stage 462.0 (TID 295, yp-spark-dal09-env5-0031, partition 5,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 462.0 (TID 291) in 146 ms on yp-spark-dal09-env5-0031 (8/25)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_11 in memory on yp-spark-dal09-env5-0044:36970 (size: 99.6 KB, free: 4.3 GB)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_13 in memory on yp-spark-dal09-env5-0034:45747 (size: 99.6 KB, free: 4.3 GB)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_12 in memory on yp-spark-dal09-env5-0047:34157 (size: 99.6 KB, free: 4.2 GB)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 16.0 in stage 462.0 (TID 296, yp-spark-dal09-env5-0044, partition 16,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 11.0 in stage 462.0 (TID 292) in 134 ms on yp-spark-dal09-env5-0044 (9/25)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_5 in memory on yp-spark-dal09-env5-0031:38585 (size: 99.6 KB, free: 4.3 GB)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 18.0 in stage 462.0 (TID 297, yp-spark-dal09-env5-0034, partition 18,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 13.0 in stage 462.0 (TID 293) in 134 ms on yp-spark-dal09-env5-0034 (10/25)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 17.0 in stage 462.0 (TID 298, yp-spark-dal09-env5-0047, partition 17,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 12.0 in stage 462.0 (TID 294) in 135 ms on yp-spark-dal09-env5-0047 (11/25)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 9.0 in stage 462.0 (TID 299, yp-spark-dal09-env5-0031, partition 9,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 5.0 in stage 462.0 (TID 295) in 134 ms on yp-spark-dal09-env5-0031 (12/25)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_16 in memory on yp-spark-dal09-env5-0044:36970 (size: 99.2 KB, free: 4.3 GB)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_18 in memory on yp-spark-dal09-env5-0034:45747 (size: 99.6 KB, free: 4.3 GB)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_17 in memory on yp-spark-dal09-env5-0047:34157 (size: 99.2 KB, free: 4.2 GB)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 21.0 in stage 462.0 (TID 300, yp-spark-dal09-env5-0044, partition 21,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 16.0 in stage 462.0 (TID 296) in 126 ms on yp-spark-dal09-env5-0044 (13/25)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_9 in memory on yp-spark-dal09-env5-0031:38585 (size: 99.6 KB, free: 4.3 GB)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 23.0 in stage 462.0 (TID 301, yp-spark-dal09-env5-0034, partition 23,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 18.0 in stage 462.0 (TID 297) in 145 ms on yp-spark-dal09-env5-0034 (14/25)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 22.0 in stage 462.0 (TID 302, yp-spark-dal09-env5-0047, partition 22,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 17.0 in stage 462.0 (TID 298) in 127 ms on yp-spark-dal09-env5-0047 (15/25)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 10.0 in stage 462.0 (TID 303, yp-spark-dal09-env5-0031, partition 10,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 9.0 in stage 462.0 (TID 299) in 127 ms on yp-spark-dal09-env5-0031 (16/25)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_21 in memory on yp-spark-dal09-env5-0044:36970 (size: 99.2 KB, free: 4.3 GB)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_23 in memory on yp-spark-dal09-env5-0034:45747 (size: 99.2 KB, free: 4.3 GB)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_22 in memory on yp-spark-dal09-env5-0047:34157 (size: 99.2 KB, free: 4.2 GB)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 21.0 in stage 462.0 (TID 300) in 124 ms on yp-spark-dal09-env5-0044 (17/25)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_10 in memory on yp-spark-dal09-env5-0031:38585 (size: 99.6 KB, free: 4.3 GB)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 23.0 in stage 462.0 (TID 301) in 121 ms on yp-spark-dal09-env5-0034 (18/25)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 22.0 in stage 462.0 (TID 302) in 127 ms on yp-spark-dal09-env5-0047 (19/25)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 14.0 in stage 462.0 (TID 304, yp-spark-dal09-env5-0031, partition 14,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 10.0 in stage 462.0 (TID 303) in 126 ms on yp-spark-dal09-env5-0031 (20/25)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_14 in memory on yp-spark-dal09-env5-0031:38585 (size: 99.6 KB, free: 4.3 GB)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 15.0 in stage 462.0 (TID 305, yp-spark-dal09-env5-0031, partition 15,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 14.0 in stage 462.0 (TID 304) in 125 ms on yp-spark-dal09-env5-0031 (21/25)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_15 in memory on yp-spark-dal09-env5-0031:38585 (size: 99.6 KB, free: 4.3 GB)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 19.0 in stage 462.0 (TID 306, yp-spark-dal09-env5-0031, partition 19,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 15.0 in stage 462.0 (TID 305) in 122 ms on yp-spark-dal09-env5-0031 (22/25)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_19 in memory on yp-spark-dal09-env5-0031:38585 (size: 99.2 KB, free: 4.3 GB)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 20.0 in stage 462.0 (TID 307, yp-spark-dal09-env5-0031, partition 20,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 19.0 in stage 462.0 (TID 306) in 119 ms on yp-spark-dal09-env5-0031 (23/25)\n17/02/16 09:03:18 INFO spark.storage.BlockManagerInfo: Added rdd_423_20 in memory on yp-spark-dal09-env5-0031:38585 (size: 99.2 KB, free: 4.3 GB)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Starting task 24.0 in stage 462.0 (TID 308, yp-spark-dal09-env5-0031, partition 24,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:18 INFO spark.scheduler.TaskSetManager: Finished task 20.0 in stage 462.0 (TID 307) in 123 ms on yp-spark-dal09-env5-0031 (24/25)\n17/02/16 09:03:19 INFO spark.storage.BlockManagerInfo: Added rdd_423_24 in memory on yp-spark-dal09-env5-0031:38585 (size: 99.2 KB, free: 4.3 GB)\n17/02/16 09:03:19 INFO spark.scheduler.TaskSetManager: Finished task 24.0 in stage 462.0 (TID 308) in 122 ms on yp-spark-dal09-env5-0031 (25/25)\n17/02/16 09:03:19 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 462.0, whose tasks have all completed, from pool \n17/02/16 09:03:19 INFO spark.scheduler.DAGScheduler: ResultStage 462 (collect at <ipython-input-7-5997fdef2cd1>:145) finished in 1.545 s\n17/02/16 09:03:19 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(462)\n17/02/16 09:03:19 INFO spark.scheduler.DAGScheduler: Job 12 finished: collect at <ipython-input-7-5997fdef2cd1>:145, took 1.603962 s\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 0, 2017-02-16 09:03:19 CST]\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 100, 2017-02-16 09:03:19 CST]\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 200, 2017-02-16 09:03:19 CST]\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 300, 2017-02-16 09:03:19 CST]\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 400, 2017-02-16 09:03:19 CST]\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 500, 2017-02-16 09:03:19 CST]\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 600, 2017-02-16 09:03:19 CST]\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 700, 2017-02-16 09:03:19 CST]\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 800, 2017-02-16 09:03:19 CST]\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 900, 2017-02-16 09:03:19 CST]\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 1000, 2017-02-16 09:03:19 CST]\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 1100, 2017-02-16 09:03:19 CST]\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1200, 2017-02-16 09:03:22 CST]\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1300, 2017-02-16 09:03:22 CST]\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1400, 2017-02-16 09:03:22 CST]\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1500, 2017-02-16 09:03:22 CST]\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1600, 2017-02-16 09:03:22 CST]\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1700, 2017-02-16 09:03:22 CST]\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1800, 2017-02-16 09:03:22 CST]\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1900, 2017-02-16 09:03:22 CST]\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 2000, 2017-02-16 09:03:22 CST]\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 2100, 2017-02-16 09:03:22 CST]\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 2200, 2017-02-16 09:03:22 CST]\n17/02/16 09:03:24 INFO CloudantRecommender: [Saved recommendations chunk, 2300, 2017-02-16 09:03:24 CST]\n17/02/16 09:03:24 INFO CloudantRecommender: [Saved recommendations chunk, 2400, 2017-02-16 09:03:24 CST]\n17/02/16 09:03:24 INFO CloudantRecommender: [Saved recommendations chunk, 2500, 2017-02-16 09:03:24 CST]\n17/02/16 09:03:24 INFO CloudantRecommender: [Saved recommendations chunk, 2600, 2017-02-16 09:03:24 CST]\n17/02/16 09:03:24 INFO CloudantRecommender: [Saved recommendations chunk, 2700, 2017-02-16 09:03:24 CST]\n17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 2800, 2017-02-16 09:03:25 CST]\n17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 2900, 2017-02-16 09:03:25 CST]\n17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 3000, 2017-02-16 09:03:25 CST]\n17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 3100, 2017-02-16 09:03:25 CST]\n17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 3200, 2017-02-16 09:03:25 CST]\n17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 3300, 2017-02-16 09:03:25 CST]\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3400, 2017-02-16 09:03:27 CST]\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3500, 2017-02-16 09:03:27 CST]\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3600, 2017-02-16 09:03:27 CST]\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3700, 2017-02-16 09:03:27 CST]\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3800, 2017-02-16 09:03:27 CST]\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3900, 2017-02-16 09:03:27 CST]\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 4000, 2017-02-16 09:03:27 CST]\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 4100, 2017-02-16 09:03:27 CST]\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 4200, 2017-02-16 09:03:27 CST]\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 4300, 2017-02-16 09:03:27 CST]\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 4400, 2017-02-16 09:03:27 CST]\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 4500, 2017-02-16 09:03:30 CST]\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 4600, 2017-02-16 09:03:30 CST]\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 4700, 2017-02-16 09:03:30 CST]\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 4800, 2017-02-16 09:03:30 CST]\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 4900, 2017-02-16 09:03:30 CST]\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5000, 2017-02-16 09:03:30 CST]\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5100, 2017-02-16 09:03:30 CST]\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5200, 2017-02-16 09:03:30 CST]\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5300, 2017-02-16 09:03:30 CST]\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5400, 2017-02-16 09:03:30 CST]\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5500, 2017-02-16 09:03:30 CST]\n17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendations chunk, 5600, 2017-02-16 09:03:32 CST]\n17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendations chunk, 5700, 2017-02-16 09:03:32 CST]\n17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendations chunk, 5800, 2017-02-16 09:03:32 CST]\n17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendations chunk, 5900, 2017-02-16 09:03:32 CST]\n17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendations chunk, 6000, 2017-02-16 09:03:32 CST]\n17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendationdb metadata record, {'timestamp_utc': '2017-02-16T15:03:32.780720', '_id': 'recommendation_metadata', 'latest_db': 'recommendationdb_1487257397'}]\n17/02/16 09:03:32 INFO apache.spark.SparkContext: Starting job: sortByKey at <ipython-input-7-5997fdef2cd1>:102\n17/02/16 09:03:32 INFO spark.scheduler.DAGScheduler: Got job 13 (sortByKey at <ipython-input-7-5997fdef2cd1>:102) with 5 output partitions\n17/02/16 09:03:32 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 507 (sortByKey at <ipython-input-7-5997fdef2cd1>:102)\n17/02/16 09:03:32 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 506, ShuffleMapStage 464)\n17/02/16 09:03:32 INFO spark.scheduler.DAGScheduler: Missing parents: List()\n17/02/16 09:03:32 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 507 (PythonRDD[431] at sortByKey at <ipython-input-7-5997fdef2cd1>:102), which has no missing parents\n17/02/16 09:03:32 INFO spark.storage.MemoryStore: Block broadcast_60 stored as values in memory (estimated size 57.0 KB, free 153.6 KB)\n17/02/16 09:03:32 INFO spark.storage.MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 18.1 KB, free 171.6 KB)\n17/02/16 09:03:32 INFO spark.storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on 10.143.133.36:35578 (size: 18.1 KB, free: 909.0 MB)\n17/02/16 09:03:32 INFO apache.spark.SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:32 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 507 (PythonRDD[431] at sortByKey at <ipython-input-7-5997fdef2cd1>:102)\n17/02/16 09:03:32 INFO cluster.ego.EGODeployScheduler: Adding task set 507.0 with 5 tasks\n17/02/16 09:03:32 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 507.0 (TID 309, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:32 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 507.0 (TID 310, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:32 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 507.0 (TID 311, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:32 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 507.0 (TID 312, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:32 INFO spark.storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 18.1 KB, free: 4.3 GB)\n17/02/16 09:03:32 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(507)\n17/02/16 09:03:32 INFO spark.storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 18.1 KB, free: 4.3 GB)\n17/02/16 09:03:32 INFO spark.storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 18.1 KB, free: 4.3 GB)\n17/02/16 09:03:32 INFO spark.storage.BlockManagerInfo: Added broadcast_60_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 18.1 KB, free: 4.2 GB)\n17/02/16 09:03:32 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 507.0 (TID 313, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:32 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 507.0 (TID 310) in 52 ms on yp-spark-dal09-env5-0044 (1/5)\n17/02/16 09:03:32 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 507.0 (TID 309) in 55 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:03:32 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 507.0 (TID 311) in 60 ms on yp-spark-dal09-env5-0031 (3/5)\n17/02/16 09:03:32 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 507.0 (TID 312) in 63 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:03:32 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 507.0 (TID 313) in 35 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:03:32 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 507.0, whose tasks have all completed, from pool \n17/02/16 09:03:32 INFO spark.scheduler.DAGScheduler: ResultStage 507 (sortByKey at <ipython-input-7-5997fdef2cd1>:102) finished in 0.088 s\n17/02/16 09:03:32 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(507)\n17/02/16 09:03:32 INFO spark.scheduler.DAGScheduler: Job 13 finished: sortByKey at <ipython-input-7-5997fdef2cd1>:102, took 0.104472 s\n17/02/16 09:03:32 INFO apache.spark.SparkContext: Starting job: sortByKey at <ipython-input-7-5997fdef2cd1>:102\n17/02/16 09:03:32 INFO spark.scheduler.DAGScheduler: Got job 14 (sortByKey at <ipython-input-7-5997fdef2cd1>:102) with 5 output partitions\n17/02/16 09:03:32 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 552 (sortByKey at <ipython-input-7-5997fdef2cd1>:102)\n17/02/16 09:03:32 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 509, ShuffleMapStage 551)\n17/02/16 09:03:32 INFO spark.scheduler.DAGScheduler: Missing parents: List()\n17/02/16 09:03:32 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 552 (PythonRDD[432] at sortByKey at <ipython-input-7-5997fdef2cd1>:102), which has no missing parents\n17/02/16 09:03:32 INFO spark.storage.MemoryStore: Block broadcast_61 stored as values in memory (estimated size 56.7 KB, free 228.4 KB)\n17/02/16 09:03:32 INFO spark.storage.MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 18.0 KB, free 246.4 KB)\n17/02/16 09:03:32 INFO spark.storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on 10.143.133.36:35578 (size: 18.0 KB, free: 908.9 MB)\n17/02/16 09:03:32 INFO apache.spark.SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:32 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 552 (PythonRDD[432] at sortByKey at <ipython-input-7-5997fdef2cd1>:102)\n17/02/16 09:03:32 INFO cluster.ego.EGODeployScheduler: Adding task set 552.0 with 5 tasks\n17/02/16 09:03:32 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 552.0 (TID 314, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:32 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 552.0 (TID 315, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:32 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 552.0 (TID 316, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:32 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 552.0 (TID 317, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:32 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(552)\n17/02/16 09:03:32 INFO spark.storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 18.0 KB, free: 4.3 GB)\n17/02/16 09:03:32 INFO spark.storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 18.0 KB, free: 4.3 GB)\n17/02/16 09:03:32 INFO spark.storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 18.0 KB, free: 4.2 GB)\n17/02/16 09:03:32 INFO spark.storage.BlockManagerInfo: Added broadcast_61_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 18.0 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 552.0 (TID 318, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2198 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 552.0 (TID 316) in 39 ms on yp-spark-dal09-env5-0044 (1/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 552.0 (TID 315) in 40 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 552.0 (TID 314) in 43 ms on yp-spark-dal09-env5-0031 (3/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 552.0 (TID 317) in 43 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 552.0 (TID 318) in 35 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 552.0, whose tasks have all completed, from pool \n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: ResultStage 552 (sortByKey at <ipython-input-7-5997fdef2cd1>:102) finished in 0.075 s\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(552)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Job 14 finished: sortByKey at <ipython-input-7-5997fdef2cd1>:102, took 0.089355 s\n17/02/16 09:03:33 INFO apache.spark.SparkContext: Starting job: sortByKey at <ipython-input-7-5997fdef2cd1>:104\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Registering RDD 434 (sortByKey at <ipython-input-7-5997fdef2cd1>:102)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Got job 15 (sortByKey at <ipython-input-7-5997fdef2cd1>:104) with 5 output partitions\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 598 (sortByKey at <ipython-input-7-5997fdef2cd1>:104)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 597)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 597)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 597 (PairwiseRDD[434] at sortByKey at <ipython-input-7-5997fdef2cd1>:102), which has no missing parents\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_62 stored as values in memory (estimated size 57.7 KB, free 304.1 KB)\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 18.7 KB, free 322.9 KB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on 10.143.133.36:35578 (size: 18.7 KB, free: 908.9 MB)\n17/02/16 09:03:33 INFO apache.spark.SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 597 (PairwiseRDD[434] at sortByKey at <ipython-input-7-5997fdef2cd1>:102)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Adding task set 597.0 with 5 tasks\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 597.0 (TID 319, yp-spark-dal09-env5-0044, partition 3,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 597.0 (TID 320, yp-spark-dal09-env5-0047, partition 2,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 597.0 (TID 321, yp-spark-dal09-env5-0031, partition 1,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 597.0 (TID 322, yp-spark-dal09-env5-0034, partition 0,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(597)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 18.7 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 18.7 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 18.7 KB, free: 4.2 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_62_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 18.7 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 597.0 (TID 323, yp-spark-dal09-env5-0044, partition 4,PROCESS_LOCAL, 2187 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 597.0 (TID 319) in 44 ms on yp-spark-dal09-env5-0044 (1/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 597.0 (TID 322) in 47 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 597.0 (TID 320) in 52 ms on yp-spark-dal09-env5-0047 (3/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 597.0 (TID 323) in 35 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 597.0 (TID 321) in 87 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 597.0, whose tasks have all completed, from pool \n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 597 (sortByKey at <ipython-input-7-5997fdef2cd1>:102) finished in 0.089 s\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: waiting: Set(ResultStage 598)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(597)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 598 (PythonRDD[437] at sortByKey at <ipython-input-7-5997fdef2cd1>:104), which has no missing parents\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(598)\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_63 stored as values in memory (estimated size 6.1 KB, free 328.9 KB)\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 3.8 KB, free 332.7 KB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on 10.143.133.36:35578 (size: 3.8 KB, free: 908.9 MB)\n17/02/16 09:03:33 INFO apache.spark.SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 598 (PythonRDD[437] at sortByKey at <ipython-input-7-5997fdef2cd1>:104)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Adding task set 598.0 with 5 tasks\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 598.0 (TID 324, yp-spark-dal09-env5-0034, partition 0,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 598.0 (TID 325, yp-spark-dal09-env5-0044, partition 1,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 598.0 (TID 326, yp-spark-dal09-env5-0031, partition 3,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 598.0 (TID 327, yp-spark-dal09-env5-0047, partition 4,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 3.8 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 3.8 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 3.8 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 46 is 303 bytes\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_63_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 3.8 KB, free: 4.2 GB)\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 598.0 (TID 328, yp-spark-dal09-env5-0044, partition 2,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 598.0 (TID 325) in 12 ms on yp-spark-dal09-env5-0044 (1/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 598.0 (TID 324) in 13 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 598.0 (TID 326) in 15 ms on yp-spark-dal09-env5-0031 (3/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 598.0 (TID 328) in 12 ms on yp-spark-dal09-env5-0044 (4/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 598.0 (TID 327) in 56 ms on yp-spark-dal09-env5-0047 (5/5)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 598.0, whose tasks have all completed, from pool \n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: ResultStage 598 (sortByKey at <ipython-input-7-5997fdef2cd1>:104) finished in 0.058 s\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(598)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Job 15 finished: sortByKey at <ipython-input-7-5997fdef2cd1>:104, took 0.165914 s\n17/02/16 09:03:33 INFO apache.spark.SparkContext: Starting job: sortByKey at <ipython-input-7-5997fdef2cd1>:104\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 310 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 318 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 322 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 44 is 313 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 43 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 42 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 41 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 40 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 39 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 38 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 37 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 36 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 35 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 34 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 31 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 30 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 29 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 28 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 27 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 26 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 25 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 21 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 20 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 19 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 296 bytes\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Got job 16 (sortByKey at <ipython-input-7-5997fdef2cd1>:104) with 5 output partitions\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 644 (sortByKey at <ipython-input-7-5997fdef2cd1>:104)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 643)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Missing parents: List()\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 644 (PythonRDD[438] at sortByKey at <ipython-input-7-5997fdef2cd1>:104), which has no missing parents\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_64 stored as values in memory (estimated size 6.1 KB, free 338.8 KB)\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 3.9 KB, free 342.7 KB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on 10.143.133.36:35578 (size: 3.9 KB, free: 908.9 MB)\n17/02/16 09:03:33 INFO apache.spark.SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 644 (PythonRDD[438] at sortByKey at <ipython-input-7-5997fdef2cd1>:104)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Adding task set 644.0 with 5 tasks\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 644.0 (TID 329, yp-spark-dal09-env5-0047, partition 0,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 644.0 (TID 330, yp-spark-dal09-env5-0034, partition 1,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 644.0 (TID 331, yp-spark-dal09-env5-0031, partition 3,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 644.0 (TID 332, yp-spark-dal09-env5-0044, partition 2,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(644)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 3.9 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 3.9 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 3.9 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_64_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 3.9 KB, free: 4.2 GB)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 644.0 (TID 333, yp-spark-dal09-env5-0034, partition 4,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 644.0 (TID 330) in 13 ms on yp-spark-dal09-env5-0034 (1/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 644.0 (TID 332) in 13 ms on yp-spark-dal09-env5-0044 (2/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 644.0 (TID 331) in 14 ms on yp-spark-dal09-env5-0031 (3/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 644.0 (TID 329) in 15 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 644.0 (TID 333) in 13 ms on yp-spark-dal09-env5-0034 (5/5)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 644.0, whose tasks have all completed, from pool \n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: ResultStage 644 (sortByKey at <ipython-input-7-5997fdef2cd1>:104) finished in 0.026 s\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(644)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Job 16 finished: sortByKey at <ipython-input-7-5997fdef2cd1>:104, took 0.043845 s\n17/02/16 09:03:33 INFO apache.spark.SparkContext: Starting job: collect at <ipython-input-7-5997fdef2cd1>:104\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Registering RDD 440 (sortByKey at <ipython-input-7-5997fdef2cd1>:104)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Got job 17 (collect at <ipython-input-7-5997fdef2cd1>:104) with 5 output partitions\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 691 (collect at <ipython-input-7-5997fdef2cd1>:104)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 690)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 690)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 690 (PairwiseRDD[440] at sortByKey at <ipython-input-7-5997fdef2cd1>:104), which has no missing parents\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_65 stored as values in memory (estimated size 6.7 KB, free 349.4 KB)\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 4.3 KB, free 353.8 KB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on 10.143.133.36:35578 (size: 4.3 KB, free: 908.9 MB)\n17/02/16 09:03:33 INFO apache.spark.SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 690 (PairwiseRDD[440] at sortByKey at <ipython-input-7-5997fdef2cd1>:104)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Adding task set 690.0 with 5 tasks\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 690.0 (TID 334, yp-spark-dal09-env5-0034, partition 0,NODE_LOCAL, 1883 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 690.0 (TID 335, yp-spark-dal09-env5-0047, partition 1,NODE_LOCAL, 1883 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 690.0 (TID 336, yp-spark-dal09-env5-0044, partition 2,NODE_LOCAL, 1883 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 690.0 (TID 337, yp-spark-dal09-env5-0031, partition 3,NODE_LOCAL, 1883 bytes)\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(690)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 4.3 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 4.3 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 4.3 KB, free: 4.2 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_65_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 4.3 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 690.0 (TID 338, yp-spark-dal09-env5-0034, partition 4,NODE_LOCAL, 1883 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 690.0 (TID 334) in 14 ms on yp-spark-dal09-env5-0034 (1/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 690.0 (TID 336) in 15 ms on yp-spark-dal09-env5-0044 (2/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 690.0 (TID 335) in 16 ms on yp-spark-dal09-env5-0047 (3/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 690.0 (TID 337) in 22 ms on yp-spark-dal09-env5-0031 (4/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 690.0 (TID 338) in 15 ms on yp-spark-dal09-env5-0034 (5/5)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 690.0, whose tasks have all completed, from pool \n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 690 (sortByKey at <ipython-input-7-5997fdef2cd1>:104) finished in 0.028 s\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: waiting: Set(ResultStage 691)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(690)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 691 (PythonRDD[443] at collect at <ipython-input-7-5997fdef2cd1>:104), which has no missing parents\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(691)\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_66 stored as values in memory (estimated size 5.6 KB, free 359.3 KB)\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 3.4 KB, free 362.8 KB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on 10.143.133.36:35578 (size: 3.4 KB, free: 908.9 MB)\n17/02/16 09:03:33 INFO apache.spark.SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 691 (PythonRDD[443] at collect at <ipython-input-7-5997fdef2cd1>:104)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Adding task set 691.0 with 5 tasks\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 691.0 (TID 339, yp-spark-dal09-env5-0044, partition 2,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 691.0 (TID 340, yp-spark-dal09-env5-0034, partition 0,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 691.0 (TID 341, yp-spark-dal09-env5-0031, partition 3,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 691.0 (TID 342, yp-spark-dal09-env5-0047, partition 1,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 3.4 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 3.4 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 3.4 KB, free: 4.2 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_66_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 3.4 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 47 is 319 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 47 is 319 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 47 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 691.0 (TID 339) in 10 ms on yp-spark-dal09-env5-0044 (1/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 691.0 (TID 343, yp-spark-dal09-env5-0034, partition 4,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 691.0 (TID 340) in 11 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 691.0 (TID 342) in 11 ms on yp-spark-dal09-env5-0047 (3/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 691.0 (TID 343) in 12 ms on yp-spark-dal09-env5-0034 (4/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 691.0 (TID 341) in 51 ms on yp-spark-dal09-env5-0031 (5/5)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 691.0, whose tasks have all completed, from pool \n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: ResultStage 691 (collect at <ipython-input-7-5997fdef2cd1>:104) finished in 0.052 s\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(691)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Job 17 finished: collect at <ipython-input-7-5997fdef2cd1>:104, took 0.096597 s\n17/02/16 09:03:33 INFO apache.spark.SparkContext: Starting job: sortByKey at <ipython-input-7-5997fdef2cd1>:105\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 310 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 3 is 318 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 322 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 44 is 313 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 43 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 42 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 41 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 40 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 39 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 38 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 37 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 36 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 35 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 34 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 31 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 30 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 29 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 28 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 27 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 26 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 25 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 21 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 20 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 19 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 9 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 8 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 7 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 6 is 294 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 5 is 296 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 46 is 303 bytes\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Got job 18 (sortByKey at <ipython-input-7-5997fdef2cd1>:105) with 5 output partitions\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 737 (sortByKey at <ipython-input-7-5997fdef2cd1>:105)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 736)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Missing parents: List()\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 737 (PythonRDD[444] at sortByKey at <ipython-input-7-5997fdef2cd1>:105), which has no missing parents\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_67 stored as values in memory (estimated size 6.1 KB, free 368.8 KB)\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 3.8 KB, free 372.6 KB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on 10.143.133.36:35578 (size: 3.8 KB, free: 908.9 MB)\n17/02/16 09:03:33 INFO apache.spark.SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 737 (PythonRDD[444] at sortByKey at <ipython-input-7-5997fdef2cd1>:105)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Adding task set 737.0 with 5 tasks\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 737.0 (TID 344, yp-spark-dal09-env5-0034, partition 0,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 737.0 (TID 345, yp-spark-dal09-env5-0047, partition 1,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 737.0 (TID 346, yp-spark-dal09-env5-0044, partition 2,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 737.0 (TID 347, yp-spark-dal09-env5-0031, partition 3,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 3.8 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(737)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 3.8 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 3.8 KB, free: 4.2 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_67_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 3.8 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 46 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 737.0 (TID 348, yp-spark-dal09-env5-0034, partition 4,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 737.0 (TID 344) in 10 ms on yp-spark-dal09-env5-0034 (1/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 737.0 (TID 346) in 11 ms on yp-spark-dal09-env5-0044 (2/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 737.0 (TID 345) in 11 ms on yp-spark-dal09-env5-0047 (3/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 737.0 (TID 347) in 12 ms on yp-spark-dal09-env5-0031 (4/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 737.0 (TID 348) in 12 ms on yp-spark-dal09-env5-0034 (5/5)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 737.0, whose tasks have all completed, from pool \n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: ResultStage 737 (sortByKey at <ipython-input-7-5997fdef2cd1>:105) finished in 0.024 s\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(737)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Job 18 finished: sortByKey at <ipython-input-7-5997fdef2cd1>:105, took 0.041222 s\n17/02/16 09:03:33 INFO apache.spark.SparkContext: Starting job: sortByKey at <ipython-input-7-5997fdef2cd1>:105\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Got job 19 (sortByKey at <ipython-input-7-5997fdef2cd1>:105) with 5 output partitions\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 783 (sortByKey at <ipython-input-7-5997fdef2cd1>:105)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 782)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Missing parents: List()\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 783 (PythonRDD[445] at sortByKey at <ipython-input-7-5997fdef2cd1>:105), which has no missing parents\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_68 stored as values in memory (estimated size 6.1 KB, free 378.7 KB)\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 3.9 KB, free 382.6 KB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on 10.143.133.36:35578 (size: 3.9 KB, free: 908.9 MB)\n17/02/16 09:03:33 INFO apache.spark.SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 783 (PythonRDD[445] at sortByKey at <ipython-input-7-5997fdef2cd1>:105)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Adding task set 783.0 with 5 tasks\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 783.0 (TID 349, yp-spark-dal09-env5-0044, partition 0,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 783.0 (TID 350, yp-spark-dal09-env5-0047, partition 1,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 783.0 (TID 351, yp-spark-dal09-env5-0034, partition 2,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 783.0 (TID 352, yp-spark-dal09-env5-0031, partition 3,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 3.9 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 3.9 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 3.9 KB, free: 4.2 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_68_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 3.9 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(783)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 783.0 (TID 353, yp-spark-dal09-env5-0044, partition 4,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 783.0 (TID 349) in 9 ms on yp-spark-dal09-env5-0044 (1/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 783.0 (TID 351) in 10 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 783.0 (TID 350) in 10 ms on yp-spark-dal09-env5-0047 (3/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 783.0 (TID 352) in 11 ms on yp-spark-dal09-env5-0031 (4/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 783.0 (TID 353) in 12 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 783.0, whose tasks have all completed, from pool \n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: ResultStage 783 (sortByKey at <ipython-input-7-5997fdef2cd1>:105) finished in 0.022 s\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(783)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Job 19 finished: sortByKey at <ipython-input-7-5997fdef2cd1>:105, took 0.032909 s\n17/02/16 09:03:33 INFO apache.spark.SparkContext: Starting job: collect at <ipython-input-7-5997fdef2cd1>:105\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Registering RDD 447 (sortByKey at <ipython-input-7-5997fdef2cd1>:105)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Got job 20 (collect at <ipython-input-7-5997fdef2cd1>:105) with 5 output partitions\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 830 (collect at <ipython-input-7-5997fdef2cd1>:105)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 829)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 829)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting ShuffleMapStage 829 (PairwiseRDD[447] at sortByKey at <ipython-input-7-5997fdef2cd1>:105), which has no missing parents\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_69 stored as values in memory (estimated size 6.7 KB, free 389.3 KB)\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 4.3 KB, free 393.6 KB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on 10.143.133.36:35578 (size: 4.3 KB, free: 908.9 MB)\n17/02/16 09:03:33 INFO apache.spark.SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 829 (PairwiseRDD[447] at sortByKey at <ipython-input-7-5997fdef2cd1>:105)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Adding task set 829.0 with 5 tasks\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 829.0 (TID 354, yp-spark-dal09-env5-0031, partition 0,NODE_LOCAL, 1883 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 829.0 (TID 355, yp-spark-dal09-env5-0044, partition 1,NODE_LOCAL, 1883 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 829.0 (TID 356, yp-spark-dal09-env5-0047, partition 3,NODE_LOCAL, 1883 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 829.0 (TID 357, yp-spark-dal09-env5-0034, partition 2,NODE_LOCAL, 1883 bytes)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 4.3 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(829)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 4.3 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 4.3 KB, free: 4.2 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_69_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 4.3 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 829.0 (TID 358, yp-spark-dal09-env5-0044, partition 4,NODE_LOCAL, 1883 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 829.0 (TID 355) in 14 ms on yp-spark-dal09-env5-0044 (1/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 829.0 (TID 357) in 15 ms on yp-spark-dal09-env5-0034 (2/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 829.0 (TID 354) in 16 ms on yp-spark-dal09-env5-0031 (3/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 829.0 (TID 356) in 17 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 829.0 (TID 358) in 14 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 829.0, whose tasks have all completed, from pool \n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: ShuffleMapStage 829 (sortByKey at <ipython-input-7-5997fdef2cd1>:105) finished in 0.029 s\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: looking for newly runnable stages\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(829)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: running: Set()\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: waiting: Set(ResultStage 830)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: failed: Set()\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 830 (PythonRDD[450] at collect at <ipython-input-7-5997fdef2cd1>:105), which has no missing parents\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(830)\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_70 stored as values in memory (estimated size 5.6 KB, free 399.2 KB)\n17/02/16 09:03:33 INFO spark.storage.MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 3.5 KB, free 402.7 KB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on 10.143.133.36:35578 (size: 3.5 KB, free: 908.9 MB)\n17/02/16 09:03:33 INFO apache.spark.SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1006\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 830 (PythonRDD[450] at collect at <ipython-input-7-5997fdef2cd1>:105)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Adding task set 830.0 with 5 tasks\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 830.0 (TID 359, yp-spark-dal09-env5-0044, partition 1,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 2.0 in stage 830.0 (TID 360, yp-spark-dal09-env5-0034, partition 2,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 830.0 (TID 361, yp-spark-dal09-env5-0031, partition 0,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 3.0 in stage 830.0 (TID 362, yp-spark-dal09-env5-0047, partition 3,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on yp-spark-dal09-env5-0044:36970 (size: 3.5 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on yp-spark-dal09-env5-0047:34157 (size: 3.5 KB, free: 4.2 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on yp-spark-dal09-env5-0034:45747 (size: 3.5 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO spark.storage.BlockManagerInfo: Added broadcast_70_piece0 in memory on yp-spark-dal09-env5-0031:38585 (size: 3.5 KB, free: 4.3 GB)\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to yp-spark-dal09-env5-0044:43592\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to yp-spark-dal09-env5-0047:48634\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 48 is 315 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMaster: Size of output statuses for shuffle 48 is 315 bytes\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to yp-spark-dal09-env5-0034:58052\n17/02/16 09:03:33 INFO apache.spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 48 to yp-spark-dal09-env5-0031:55418\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Starting task 4.0 in stage 830.0 (TID 363, yp-spark-dal09-env5-0044, partition 4,NODE_LOCAL, 1894 bytes)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 830.0 (TID 359) in 14 ms on yp-spark-dal09-env5-0044 (1/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 830.0 (TID 361) in 16 ms on yp-spark-dal09-env5-0031 (2/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 2.0 in stage 830.0 (TID 360) in 16 ms on yp-spark-dal09-env5-0034 (3/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 3.0 in stage 830.0 (TID 362) in 17 ms on yp-spark-dal09-env5-0047 (4/5)\n17/02/16 09:03:33 INFO spark.scheduler.TaskSetManager: Finished task 4.0 in stage 830.0 (TID 363) in 15 ms on yp-spark-dal09-env5-0044 (5/5)\n17/02/16 09:03:33 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 830.0, whose tasks have all completed, from pool \n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: ResultStage 830 (collect at <ipython-input-7-5997fdef2cd1>:105) finished in 0.031 s\n17/02/16 09:03:33 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(830)\n17/02/16 09:03:33 INFO spark.scheduler.DAGScheduler: Job 20 finished: collect at <ipython-input-7-5997fdef2cd1>:105, took 0.074076 s\n17/02/16 09:03:35 INFO CloudantRecommender: [Saved recommendations to: , recommendationdb_1487257397, 2017-02-16 09:03:35 CST]\n", 
                    "output_type": "stream", 
                    "name": "stdout"
                }
            ], 
            "metadata": {
                "collapsed": false
            }, 
            "source": "# dump the latest kernel log\n! cat $(ls -1 $HOME/logs/notebook/*pyspark* | sort -r | head -1)", 
            "execution_count": 9
        }, 
        {
            "cell_type": "code", 
            "outputs": [
                {
                    "text": "17/02/16 09:00:51 INFO CloudantRecommender: [Starting load from Cloudant: , 2017-02-16 09:00:51 CST]\r\n17/02/16 09:01:51 INFO CloudantRecommender: [Finished load from Cloudant: , 2017-02-16 09:01:51 CST]\r\n17/02/16 09:02:33 INFO CloudantRecommender: [Found, 1000002, records in Cloudant]\r\n17/02/16 09:02:33 INFO CloudantRecommender: [Starting train model: , 2017-02-16 09:02:33 CST]\r\n17/02/16 09:03:12 INFO CloudantRecommender: [Finished train model: , 2017-02-16 09:03:12 CST]\r\n17/02/16 09:03:12 INFO CloudantRecommender: [Starting __get_top_recommendations: , 2017-02-16 09:03:12 CST]\r\n17/02/16 09:03:17 INFO CloudantRecommender: [Finished __get_top_recommendations: , 2017-02-16 09:03:17 CST]\r\n17/02/16 09:03:17 INFO CloudantRecommender: [Created new recommendations db, recommendationdb_1487257397]\r\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 0, 2017-02-16 09:03:19 CST]\r\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 100, 2017-02-16 09:03:19 CST]\r\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 200, 2017-02-16 09:03:19 CST]\r\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 300, 2017-02-16 09:03:19 CST]\r\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 400, 2017-02-16 09:03:19 CST]\r\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 500, 2017-02-16 09:03:19 CST]\r\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 600, 2017-02-16 09:03:19 CST]\r\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 700, 2017-02-16 09:03:19 CST]\r\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 800, 2017-02-16 09:03:19 CST]\r\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 900, 2017-02-16 09:03:19 CST]\r\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 1000, 2017-02-16 09:03:19 CST]\r\n17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 1100, 2017-02-16 09:03:19 CST]\r\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1200, 2017-02-16 09:03:22 CST]\r\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1300, 2017-02-16 09:03:22 CST]\r\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1400, 2017-02-16 09:03:22 CST]\r\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1500, 2017-02-16 09:03:22 CST]\r\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1600, 2017-02-16 09:03:22 CST]\r\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1700, 2017-02-16 09:03:22 CST]\r\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1800, 2017-02-16 09:03:22 CST]\r\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1900, 2017-02-16 09:03:22 CST]\r\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 2000, 2017-02-16 09:03:22 CST]\r\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 2100, 2017-02-16 09:03:22 CST]\r\n17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 2200, 2017-02-16 09:03:22 CST]\r\n17/02/16 09:03:24 INFO CloudantRecommender: [Saved recommendations chunk, 2300, 2017-02-16 09:03:24 CST]\r\n17/02/16 09:03:24 INFO CloudantRecommender: [Saved recommendations chunk, 2400, 2017-02-16 09:03:24 CST]\r\n17/02/16 09:03:24 INFO CloudantRecommender: [Saved recommendations chunk, 2500, 2017-02-16 09:03:24 CST]\r\n17/02/16 09:03:24 INFO CloudantRecommender: [Saved recommendations chunk, 2600, 2017-02-16 09:03:24 CST]\r\n17/02/16 09:03:24 INFO CloudantRecommender: [Saved recommendations chunk, 2700, 2017-02-16 09:03:24 CST]\r\n17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 2800, 2017-02-16 09:03:25 CST]\r\n17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 2900, 2017-02-16 09:03:25 CST]\r\n17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 3000, 2017-02-16 09:03:25 CST]\r\n17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 3100, 2017-02-16 09:03:25 CST]\r\n17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 3200, 2017-02-16 09:03:25 CST]\r\n17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 3300, 2017-02-16 09:03:25 CST]\r\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3400, 2017-02-16 09:03:27 CST]\r\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3500, 2017-02-16 09:03:27 CST]\r\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3600, 2017-02-16 09:03:27 CST]\r\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3700, 2017-02-16 09:03:27 CST]\r\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3800, 2017-02-16 09:03:27 CST]\r\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3900, 2017-02-16 09:03:27 CST]\r\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 4000, 2017-02-16 09:03:27 CST]\r\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 4100, 2017-02-16 09:03:27 CST]\r\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 4200, 2017-02-16 09:03:27 CST]\r\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 4300, 2017-02-16 09:03:27 CST]\r\n17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 4400, 2017-02-16 09:03:27 CST]\r\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 4500, 2017-02-16 09:03:30 CST]\r\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 4600, 2017-02-16 09:03:30 CST]\r\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 4700, 2017-02-16 09:03:30 CST]\r\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 4800, 2017-02-16 09:03:30 CST]\r\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 4900, 2017-02-16 09:03:30 CST]\r\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5000, 2017-02-16 09:03:30 CST]\r\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5100, 2017-02-16 09:03:30 CST]\r\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5200, 2017-02-16 09:03:30 CST]\r\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5300, 2017-02-16 09:03:30 CST]\r\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5400, 2017-02-16 09:03:30 CST]\r\n17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5500, 2017-02-16 09:03:30 CST]\r\n17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendations chunk, 5600, 2017-02-16 09:03:32 CST]\r\n17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendations chunk, 5700, 2017-02-16 09:03:32 CST]\r\n17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendations chunk, 5800, 2017-02-16 09:03:32 CST]\r\n17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendations chunk, 5900, 2017-02-16 09:03:32 CST]\r\n17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendations chunk, 6000, 2017-02-16 09:03:32 CST]\r\n17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendationdb metadata record, {'timestamp_utc': '2017-02-16T15:03:32.780720', '_id': 'recommendation_metadata', 'latest_db': 'recommendationdb_1487257397'}]\r\n17/02/16 09:03:35 INFO CloudantRecommender: [Saved recommendations to: , recommendationdb_1487257397, 2017-02-16 09:03:35 CST]\r\n", 
                    "output_type": "stream", 
                    "name": "stdout"
                }
            ], 
            "metadata": {
                "collapsed": false
            }, 
            "source": "# look for our log output in the latest kernel log file\n! grep 'CloudantRecommender' $(ls -1 $HOME/logs/notebook/*pyspark* | sort -r | head -1)", 
            "execution_count": 10
        }, 
        {
            "cell_type": "code", 
            "outputs": [
                {
                    "text": "/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:00:51 INFO CloudantRecommender: [Starting load from Cloudant: , 2017-02-16 09:00:51 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:01:51 INFO CloudantRecommender: [Finished load from Cloudant: , 2017-02-16 09:01:51 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:02:33 INFO CloudantRecommender: [Found, 1000002, records in Cloudant]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:02:33 INFO CloudantRecommender: [Starting train model: , 2017-02-16 09:02:33 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:12 INFO CloudantRecommender: [Finished train model: , 2017-02-16 09:03:12 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:12 INFO CloudantRecommender: [Starting __get_top_recommendations: , 2017-02-16 09:03:12 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:17 INFO CloudantRecommender: [Finished __get_top_recommendations: , 2017-02-16 09:03:17 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:17 INFO CloudantRecommender: [Created new recommendations db, recommendationdb_1487257397]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 0, 2017-02-16 09:03:19 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 100, 2017-02-16 09:03:19 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 200, 2017-02-16 09:03:19 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 300, 2017-02-16 09:03:19 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 400, 2017-02-16 09:03:19 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 500, 2017-02-16 09:03:19 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 600, 2017-02-16 09:03:19 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 700, 2017-02-16 09:03:19 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 800, 2017-02-16 09:03:19 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 900, 2017-02-16 09:03:19 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 1000, 2017-02-16 09:03:19 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:19 INFO CloudantRecommender: [Saved recommendations chunk, 1100, 2017-02-16 09:03:19 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1200, 2017-02-16 09:03:22 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1300, 2017-02-16 09:03:22 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1400, 2017-02-16 09:03:22 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1500, 2017-02-16 09:03:22 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1600, 2017-02-16 09:03:22 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1700, 2017-02-16 09:03:22 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1800, 2017-02-16 09:03:22 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 1900, 2017-02-16 09:03:22 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 2000, 2017-02-16 09:03:22 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 2100, 2017-02-16 09:03:22 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:22 INFO CloudantRecommender: [Saved recommendations chunk, 2200, 2017-02-16 09:03:22 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:24 INFO CloudantRecommender: [Saved recommendations chunk, 2300, 2017-02-16 09:03:24 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:24 INFO CloudantRecommender: [Saved recommendations chunk, 2400, 2017-02-16 09:03:24 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:24 INFO CloudantRecommender: [Saved recommendations chunk, 2500, 2017-02-16 09:03:24 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:24 INFO CloudantRecommender: [Saved recommendations chunk, 2600, 2017-02-16 09:03:24 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:24 INFO CloudantRecommender: [Saved recommendations chunk, 2700, 2017-02-16 09:03:24 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 2800, 2017-02-16 09:03:25 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 2900, 2017-02-16 09:03:25 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 3000, 2017-02-16 09:03:25 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 3100, 2017-02-16 09:03:25 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 3200, 2017-02-16 09:03:25 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:25 INFO CloudantRecommender: [Saved recommendations chunk, 3300, 2017-02-16 09:03:25 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3400, 2017-02-16 09:03:27 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3500, 2017-02-16 09:03:27 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3600, 2017-02-16 09:03:27 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3700, 2017-02-16 09:03:27 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3800, 2017-02-16 09:03:27 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 3900, 2017-02-16 09:03:27 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 4000, 2017-02-16 09:03:27 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 4100, 2017-02-16 09:03:27 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 4200, 2017-02-16 09:03:27 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 4300, 2017-02-16 09:03:27 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:27 INFO CloudantRecommender: [Saved recommendations chunk, 4400, 2017-02-16 09:03:27 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 4500, 2017-02-16 09:03:30 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 4600, 2017-02-16 09:03:30 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 4700, 2017-02-16 09:03:30 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 4800, 2017-02-16 09:03:30 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 4900, 2017-02-16 09:03:30 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5000, 2017-02-16 09:03:30 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5100, 2017-02-16 09:03:30 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5200, 2017-02-16 09:03:30 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5300, 2017-02-16 09:03:30 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5400, 2017-02-16 09:03:30 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:30 INFO CloudantRecommender: [Saved recommendations chunk, 5500, 2017-02-16 09:03:30 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendations chunk, 5600, 2017-02-16 09:03:32 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendations chunk, 5700, 2017-02-16 09:03:32 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendations chunk, 5800, 2017-02-16 09:03:32 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendations chunk, 5900, 2017-02-16 09:03:32 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendations chunk, 6000, 2017-02-16 09:03:32 CST]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:32 INFO CloudantRecommender: [Saved recommendationdb metadata record, {'timestamp_utc': '2017-02-16T15:03:32.780720', '_id': 'recommendation_metadata', 'latest_db': 'recommendationdb_1487257397'}]\r\n/gpfs/fs01/user/sde1-92e9626d40d0f3-dcc0c4613008/logs/notebook/kernel-pyspark-20170216_145840.log:17/02/16 09:03:35 INFO CloudantRecommender: [Saved recommendations to: , recommendationdb_1487257397, 2017-02-16 09:03:35 CST]\r\n", 
                    "output_type": "stream", 
                    "name": "stdout"
                }
            ], 
            "metadata": {
                "collapsed": false
            }, 
            "source": "# look for our log output in all kernel log files\n! grep 'CloudantRecommender' $HOME/logs/notebook/*pyspark* ", 
            "execution_count": 11
        }, 
        {
            "cell_type": "code", 
            "outputs": [], 
            "metadata": {
                "collapsed": true
            }, 
            "source": "", 
            "execution_count": null
        }
    ], 
    "nbformat": 4, 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2 with Spark 1.6", 
            "name": "python2", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "version": "2.7.11", 
            "file_extension": ".py", 
            "name": "python", 
            "pygments_lexer": "ipython2", 
            "nbconvert_exporter": "python", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat_minor": 0
}